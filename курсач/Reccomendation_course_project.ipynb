{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two level recommendation system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# matrix factorization\n",
    "from implicit import als\n",
    "\n",
    "# Second level model\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# my own function\n",
    "from src.metrics import precision_at_k, recall_at_k\n",
    "from src.utils import prefilter_items_0\n",
    "from src.recommenders import MainRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_recommendation(data, n=5):\n",
    "    \"\"\"Топ-n популярных товаров\"\"\"\n",
    "    \n",
    "    popular = data.groupby('item_id')['sales_value'].sum().reset_index()\n",
    "    popular.sort_values('sales_value', ascending=False, inplace=True)\n",
    "    \n",
    "    recs = popular.head(n).item_id\n",
    "    \n",
    "    return recs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./raw_data/retail_train.csv')\n",
    "item_features = pd.read_csv('./raw_data/product.csv')\n",
    "user_features = pd.read_csv('./raw_data/hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "\n",
    "data = data[data['item_id'] != 999999] #droped all popular items which we marked as 999999\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# Важна схема обучения и валидации!\n",
    "# -- давние покупки -- | -- 6 недель -- | -- 3 недель -- \n",
    "# подобрать размер 2-ого датасета (6 недель) --> learning curve (зависимость метрики recall@k от размера датасета)\n",
    "val_lvl_1_size_weeks = 6\n",
    "val_lvl_2_size_weeks = 3\n",
    "\n",
    "data_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\n",
    "data_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n",
    "\n",
    "data_train_lvl_2 = data_val_lvl_1.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "data_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]\n",
    "\n",
    "data_train_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 83685 to 5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "#decrease our set to 5000 most popular items to provide better speed\n",
    "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
    "data_train_lvl_1 = prefilter_items_0(data_train_lvl_1) \n",
    "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2fa73354304bf3a2c2eaba4da322ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cbbf960b214150b3296143161dc418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recommender = MainRecommender(data_train_lvl_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop those users who are absent in train dataset and vice versa\n",
    "data_val_lvl_1 = data_val_lvl_1[data_val_lvl_1['user_id'].isin(data_train_lvl_1['user_id'])]\n",
    "data_train_lvl_1 = data_train_lvl_1[data_train_lvl_1['user_id'].isin(data_val_lvl_1['user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[853529, 865456, 867607, 872137, 874905, 87524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[15830248, 838136, 839656, 861272, 866211, 870...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [853529, 865456, 867607, 872137, 874905, 87524...\n",
       "1        2  [15830248, 838136, 839656, 861272, 866211, 870..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1 = data_val_lvl_1.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_1.columns=['user_id', 'actual']\n",
    "result_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to offer similar items to user using different approaches. <br>\n",
    "Check the quality on the data_val_lvl_1 dataset. It's next 6 weeks after the train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[899624, 904360, 981760, 923746, 1082185]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_als_recommendations(2375, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1036501, 1079023, 1085983, 907099, 910439]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_own_recommendations(2375, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1073150, 889731, 1055646, 1046545, 981760]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_similar_items_recommendation(2375, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[834103, 888650, 1082990, 1065538, 1124971]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_similar_users_recommendation(2375, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[999999, 6534178, 6533889, 1029743, 6534166]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_recommendation(data_train_lvl_1, n=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[853529, 865456, 867607, 872137, 874905, 87524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[15830248, 838136, 839656, 861272, 866211, 870...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[883932, 970760, 1035676, 1055863, 1097610, 67...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[1024306, 1102949, 6548453, 835394, 940804, 96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[836281, 843306, 845294, 914190, 920456, 93886...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>2496</td>\n",
       "      <td>[831509, 867188, 1013623, 1048851, 5592734, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2497</td>\n",
       "      <td>[820291, 824759, 838797, 859010, 859075, 86077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2498</td>\n",
       "      <td>[865511, 962991, 1076374, 1102358, 5564901, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2499</td>\n",
       "      <td>[861282, 921744, 1050968, 13842089, 828837, 86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2500</td>\n",
       "      <td>[856455, 902192, 903476, 931672, 936634, 95170...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                             actual\n",
       "0           1  [853529, 865456, 867607, 872137, 874905, 87524...\n",
       "1           2  [15830248, 838136, 839656, 861272, 866211, 870...\n",
       "2           4  [883932, 970760, 1035676, 1055863, 1097610, 67...\n",
       "3           6  [1024306, 1102949, 6548453, 835394, 940804, 96...\n",
       "4           7  [836281, 843306, 845294, 914190, 920456, 93886...\n",
       "...       ...                                                ...\n",
       "2148     2496  [831509, 867188, 1013623, 1048851, 5592734, 16...\n",
       "2149     2497  [820291, 824759, 838797, 859010, 859075, 86077...\n",
       "2150     2498  [865511, 962991, 1076374, 1102358, 5564901, 15...\n",
       "2151     2499  [861282, 921744, 1050968, 13842089, 828837, 86...\n",
       "2152     2500  [856455, 902192, 903476, 931672, 936634, 95170...\n",
       "\n",
       "[2153 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally make first level predictions for our users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_recs = popular_recommendation(data_train_lvl_1, n=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_2 = result_lvl_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_1['als'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_als_recommendations(x, N=N))\n",
    "result_lvl_1['own_recommendations'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=N))\n",
    "result_lvl_1['similar_items'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_similar_items_recommendation(x, N=N))\n",
    "result_lvl_1['popular_recommendation'] = result_lvl_1['user_id'].apply(lambda x: popular_recs)\n",
    "#result_lvl_1['similar_user'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_similar_users_recommendation(x, N=N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>als</th>\n",
       "      <th>own_recommendations</th>\n",
       "      <th>similar_items</th>\n",
       "      <th>popular_recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[853529, 865456, 867607, 872137, 874905, 87524...</td>\n",
       "      <td>[1082212, 1094924, 1047619, 1004390, 956609, 1...</td>\n",
       "      <td>[856942, 9297615, 5577022, 1074612, 9655212, 9...</td>\n",
       "      <td>[824758, 999999, 1082185, 864774, 1124432, 940...</td>\n",
       "      <td>[999999, 6534178, 6533889, 1029743, 6534166, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[15830248, 838136, 839656, 861272, 866211, 870...</td>\n",
       "      <td>[5569230, 1041259, 854852, 908846, 951412, 847...</td>\n",
       "      <td>[1076580, 911974, 826784, 1083296, 838136, 820...</td>\n",
       "      <td>[8090509, 1133018, 7025275, 1106523, 985999, 8...</td>\n",
       "      <td>[999999, 6534178, 6533889, 1029743, 6534166, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[883932, 970760, 1035676, 1055863, 1097610, 67...</td>\n",
       "      <td>[891423, 902172, 846550, 1036347, 1058930, 111...</td>\n",
       "      <td>[891423, 910109, 887003, 1121367, 951821, 1115...</td>\n",
       "      <td>[951590, 843450, 1074754, 862732, 1139525, 880...</td>\n",
       "      <td>[999999, 6534178, 6533889, 1029743, 6534166, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[1024306, 1102949, 6548453, 835394, 940804, 96...</td>\n",
       "      <td>[1082185, 878996, 1024306, 965267, 857006, 102...</td>\n",
       "      <td>[13003092, 1119051, 9911484, 8203834, 1108094,...</td>\n",
       "      <td>[999999, 904360, 874149, 845208, 948650, 70252...</td>\n",
       "      <td>[999999, 6534178, 6533889, 1029743, 6534166, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[836281, 843306, 845294, 914190, 920456, 93886...</td>\n",
       "      <td>[1003188, 853643, 938187, 892004, 849843, 1060...</td>\n",
       "      <td>[845814, 1075524, 1097544, 1112957, 9338009, 6...</td>\n",
       "      <td>[999999, 1038985, 1015247, 922307, 836793, 113...</td>\n",
       "      <td>[999999, 6534178, 6533889, 1029743, 6534166, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual  \\\n",
       "0        1  [853529, 865456, 867607, 872137, 874905, 87524...   \n",
       "1        2  [15830248, 838136, 839656, 861272, 866211, 870...   \n",
       "2        4  [883932, 970760, 1035676, 1055863, 1097610, 67...   \n",
       "3        6  [1024306, 1102949, 6548453, 835394, 940804, 96...   \n",
       "4        7  [836281, 843306, 845294, 914190, 920456, 93886...   \n",
       "\n",
       "                                                 als  \\\n",
       "0  [1082212, 1094924, 1047619, 1004390, 956609, 1...   \n",
       "1  [5569230, 1041259, 854852, 908846, 951412, 847...   \n",
       "2  [891423, 902172, 846550, 1036347, 1058930, 111...   \n",
       "3  [1082185, 878996, 1024306, 965267, 857006, 102...   \n",
       "4  [1003188, 853643, 938187, 892004, 849843, 1060...   \n",
       "\n",
       "                                 own_recommendations  \\\n",
       "0  [856942, 9297615, 5577022, 1074612, 9655212, 9...   \n",
       "1  [1076580, 911974, 826784, 1083296, 838136, 820...   \n",
       "2  [891423, 910109, 887003, 1121367, 951821, 1115...   \n",
       "3  [13003092, 1119051, 9911484, 8203834, 1108094,...   \n",
       "4  [845814, 1075524, 1097544, 1112957, 9338009, 6...   \n",
       "\n",
       "                                       similar_items  \\\n",
       "0  [824758, 999999, 1082185, 864774, 1124432, 940...   \n",
       "1  [8090509, 1133018, 7025275, 1106523, 985999, 8...   \n",
       "2  [951590, 843450, 1074754, 862732, 1139525, 880...   \n",
       "3  [999999, 904360, 874149, 845208, 948650, 70252...   \n",
       "4  [999999, 1038985, 1015247, 922307, 836793, 113...   \n",
       "\n",
       "                              popular_recommendation  \n",
       "0  [999999, 6534178, 6533889, 1029743, 6534166, 1...  \n",
       "1  [999999, 6534178, 6533889, 1029743, 6534166, 1...  \n",
       "2  [999999, 6534178, 6533889, 1029743, 6534166, 1...  \n",
       "3  [999999, 6534178, 6533889, 1029743, 6534166, 1...  \n",
       "4  [999999, 6534178, 6533889, 1029743, 6534166, 1...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac, own = result_lvl_1.iloc[0]['actual'], result_lvl_1.iloc[0]['own_recommendations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028254776126099175"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1.apply(lambda row: recall_at_k(row['own_recommendations'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015398197524880447"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1.apply(lambda row: recall_at_k(row['als'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01128091886229823"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1.apply(lambda row: recall_at_k(row['similar_items'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014669071440125525"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1.apply(lambda row: recall_at_k(row['popular_recommendation'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_lvl_1.apply(lambda row: recall_at_k(row['similar_user'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие recall показываают own recommendtions + top-popular лучший"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [5, 10, 20, 50, 100, 200, 500]\n",
    "score = []\n",
    "for k in k_list:\n",
    "    score.append(result_lvl_1.apply(lambda row: recall_at_k(row['own_recommendations'], row['actual'], k=k), axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(k_list, score)\n",
    "plt.title(\"The recall score depending on the number of K\", fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more items we take on the first level predictions the better chance that we will make a better prediction on the second final level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель 2-ого уровня, при этом надо добавить минимум по 2 фичи для юзера, товара и пары юзер-товар"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_lvl_2 = pd.DataFrame(data_train_lvl_2['user_id'].unique())\n",
    "users_lvl_2.columns = ['user_id']\n",
    "\n",
    "# Пока только warm start\n",
    "train_users = data_train_lvl_1['user_id'].unique()\n",
    "users_lvl_2 = users_lvl_2[users_lvl_2['user_id'].isin(train_users)]\n",
    "\n",
    "N = 200\n",
    "users_lvl_2['own_recommendations'] = users_lvl_2['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=N))\n",
    "users_lvl_2['als'] = users_lvl_2['user_id'].apply(lambda x: recommender.get_als_recommendations(x, N=N))\n",
    "users_lvl_2['similar_items'] = users_lvl_2['user_id'].apply(lambda x: recommender.get_similar_items_recommendation(x, N=N))\n",
    "users_lvl_2['popular_recommendation'] = users_lvl_2['user_id'].apply(lambda x: popular_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>own_recommendations</th>\n",
       "      <th>als</th>\n",
       "      <th>similar_items</th>\n",
       "      <th>popular_recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>[834103, 878302, 1119399, 1085604, 13511722, 9...</td>\n",
       "      <td>[1082185, 908531, 981760, 1029743, 1080414, 87...</td>\n",
       "      <td>[1037894, 879755, 949616, 879948, 9526563, 106...</td>\n",
       "      <td>[999999, 6534178, 6533889, 1029743, 6534166, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>[1119454, 1019142, 871279, 835578, 863762, 101...</td>\n",
       "      <td>[896938, 951590, 1037863, 871756, 895930, 8468...</td>\n",
       "      <td>[960318, 883932, 904360, 819255, 12301109, 111...</td>\n",
       "      <td>[999999, 6534178, 6533889, 1029743, 6534166, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                own_recommendations  \\\n",
       "0     2070  [834103, 878302, 1119399, 1085604, 13511722, 9...   \n",
       "1     2021  [1119454, 1019142, 871279, 835578, 863762, 101...   \n",
       "\n",
       "                                                 als  \\\n",
       "0  [1082185, 908531, 981760, 1029743, 1080414, 87...   \n",
       "1  [896938, 951590, 1037863, 871756, 895930, 8468...   \n",
       "\n",
       "                                       similar_items  \\\n",
       "0  [1037894, 879755, 949616, 879948, 9526563, 106...   \n",
       "1  [960318, 883932, 904360, 819255, 12301109, 111...   \n",
       "\n",
       "                              popular_recommendation  \n",
       "0  [999999, 6534178, 6533889, 1029743, 6534166, 1...  \n",
       "1  [999999, 6534178, 6533889, 1029743, 6534166, 1...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_lvl_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_lvl_2['candidates'] = users_lvl_2['own_recommendations'] + users_lvl_2['als'] + users_lvl_2['similar_items'] + users_lvl_2['popular_recommendation']\n",
    "users_lvl_2 = users_lvl_2[['user_id','candidates' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>[834103, 878302, 1119399, 1085604, 13511722, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>[1119454, 1019142, 871279, 835578, 863762, 101...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                         candidates\n",
       "0     2070  [834103, 878302, 1119399, 1085604, 13511722, 9...\n",
       "1     2021  [1119454, 1019142, 871279, 835578, 863762, 101..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_lvl_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>834103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>878302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>1119399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>1085604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  flag\n",
       "0     2070   834103     1\n",
       "0     2070   878302     1\n",
       "0     2070  1119399     1\n",
       "0     2070  1085604     1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = users_lvl_2.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'item_id'\n",
    "\n",
    "users_lvl_2 = users_lvl_2.drop('candidates', axis=1).join(s)\n",
    "users_lvl_2['flag'] = 1\n",
    "\n",
    "users_lvl_2.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2368300"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_lvl_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2153"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_lvl_2['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2 = data_train_lvl_2[['user_id', 'item_id']].copy()\n",
    "targets_lvl_2['target'] = 1  # тут только покупки \n",
    "\n",
    "targets_lvl_2 = users_lvl_2.merge(targets_lvl_2, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "targets_lvl_2['target'].fillna(0, inplace = True)\n",
    "targets_lvl_2.drop('flag', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2_val = data_val_lvl_2[['user_id', 'item_id']].copy()\n",
    "targets_lvl_2_val['target'] = 1  # тут только покупки \n",
    "\n",
    "targets_lvl_2_val = users_lvl_2.merge(targets_lvl_2_val, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "targets_lvl_2_val['target'].fillna(0, inplace = True)\n",
    "targets_lvl_2_val.drop('flag', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>834103</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2070</td>\n",
       "      <td>834103</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  target\n",
       "0     2070   834103     1.0\n",
       "1     2070   834103     1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_lvl_2_val.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(!) For every user there are N={} item_id's candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06060933941246653"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_lvl_2['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25671</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>FRZN ICE</td>\n",
       "      <td>ICE - CRUSHED/CUBED</td>\n",
       "      <td>22 LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26081</td>\n",
       "      <td>2</td>\n",
       "      <td>MISC. TRANS.</td>\n",
       "      <td>National</td>\n",
       "      <td>NO COMMODITY DESCRIPTION</td>\n",
       "      <td>NO SUBCOMMODITY DESCRIPTION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  manufacturer    department     brand            commodity_desc  \\\n",
       "0    25671             2       GROCERY  National                  FRZN ICE   \n",
       "1    26081             2  MISC. TRANS.  National  NO COMMODITY DESCRIPTION   \n",
       "\n",
       "            sub_commodity_desc curr_size_of_product  \n",
       "0          ICE - CRUSHED/CUBED                22 LB  \n",
       "1  NO SUBCOMMODITY DESCRIPTION                       "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65+</td>\n",
       "      <td>A</td>\n",
       "      <td>35-49K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45-54</td>\n",
       "      <td>A</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_desc marital_status_code income_desc homeowner_desc      hh_comp_desc  \\\n",
       "0      65+                   A      35-49K      Homeowner  2 Adults No Kids   \n",
       "1    45-54                   A      50-74K      Homeowner  2 Adults No Kids   \n",
       "\n",
       "  household_size_desc kid_category_desc  user_id  \n",
       "0                   2      None/Unknown        1  \n",
       "1                   2      None/Unknown        7  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2 = targets_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "targets_lvl_2 = targets_lvl_2.merge(user_features, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2_val = targets_lvl_2_val.merge(item_features, on='item_id', how='left')\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(user_features, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature enginering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доп варианты, которые можно добавить:<br>\n",
    "Фичи user_id:\n",
    "\n",
    "- Средняя сумма покупки 1 товара в каждой категории\n",
    "- Кол-во покупок в каждой категории\n",
    "- Долю покупок в выходные\n",
    "- Долю покупок утром/днем/вечером\n",
    "\n",
    "Фичи item_id:\n",
    "\n",
    "- Кол-во покупок в неделю\n",
    "- Среднее ол-во покупок 1 товара в категории в неделю\n",
    "- (Кол-во покупок в неделю) / (Среднее ол-во покупок 1 товара в категории в неделю)\n",
    "\n",
    "Фичи пары user_id - item_id\n",
    "\n",
    "- (Средняя сумма покупки 1 товара в каждой категории (берем категорию item_id)) - (Цена item_id)\n",
    "- (Кол-во покупок юзером конкретной категории в неделю) - (Среднее кол-во покупок всеми юзерами конкретной категории в неделю)\n",
    "- (Кол-во покупок юзером конкретной категории в неделю) / (Среднее кол-во покупок всеми юзерами конкретной категории в неделю)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Средний чек\n",
    "average_basket = data_train_lvl_2.groupby(['user_id','basket_id'])['sales_value'].mean().reset_index()\n",
    "average_basket.columns = ['user_id', 'basket_id', 'average_basket_price']\n",
    "average_basket = average_basket.groupby('user_id')['average_basket_price'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2 = targets_lvl_2.merge(average_basket, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Средний чек\n",
    "average_basket_val = data_val_lvl_2.groupby(['user_id','basket_id'])['sales_value'].mean().reset_index()\n",
    "average_basket_val.columns = ['user_id', 'basket_id', 'average_basket_price']\n",
    "average_basket_val = average_basket_val.groupby('user_id')['average_basket_price'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2_val = targets_lvl_2_val.merge(average_basket_val, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>purchases_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  purchases_per_month\n",
       "0        1                  1.0\n",
       "1        2                  1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Частотность покупок раз/месяц\n",
    "frequency = data_train_lvl_2.copy()\n",
    "frequency['activity_per_month'] = frequency['day']%30\n",
    "frequency.drop_duplicates(subset = \"basket_id\", keep = False, inplace = True) \n",
    "frequency = frequency.groupby(['user_id', 'activity_per_month'])['basket_id'].count().reset_index()\n",
    "frequency = frequency.groupby('user_id')['basket_id'].mean().reset_index()\n",
    "frequency.columns = ['user_id', 'purchases_per_month']\n",
    "frequency.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2 = targets_lvl_2.merge(frequency, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>purchases_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  purchases_per_month\n",
       "0        1                  1.0\n",
       "1        6                  1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Частотность покупок раз/месяц\n",
    "frequency_val = data_val_lvl_2.copy()\n",
    "frequency_val ['activity_per_month'] = frequency_val['day']%30\n",
    "frequency_val.drop_duplicates(subset = \"basket_id\", keep = False, inplace = True) \n",
    "frequency_val = frequency_val.groupby(['user_id', 'activity_per_month'])['basket_id'].count().reset_index()\n",
    "frequency_val = frequency_val.groupby('user_id')['basket_id'].mean().reset_index()\n",
    "frequency_val.columns = ['user_id', 'purchases_per_month']\n",
    "frequency_val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2_val = targets_lvl_2_val.merge(frequency, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Кол-во покупок товара в неделю\n",
    "item_per_week = data_train_lvl_2.groupby(['item_id','week_no'])['quantity'].sum().reset_index()\n",
    "item_per_week = item_per_week.groupby('item_id')['quantity'].mean().reset_index()\n",
    "item_per_week.columns = ['item_id', 'item_per_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2 = targets_lvl_2.merge(item_per_week, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>target</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "      <th>average_basket_price</th>\n",
       "      <th>purchases_per_month</th>\n",
       "      <th>item_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>834103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2224.0</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>SOFT DRINKS</td>\n",
       "      <td>SFT DRNK SNGL SRV BTL CARB (EX</td>\n",
       "      <td>20 OZ</td>\n",
       "      <td>45-54</td>\n",
       "      <td>U</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>2.18786</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>10.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2070</td>\n",
       "      <td>834103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2224.0</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>SOFT DRINKS</td>\n",
       "      <td>SFT DRNK SNGL SRV BTL CARB (EX</td>\n",
       "      <td>20 OZ</td>\n",
       "      <td>45-54</td>\n",
       "      <td>U</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>2.18786</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>10.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  target  manufacturer department     brand commodity_desc  \\\n",
       "0     2070   834103     1.0        2224.0    GROCERY  National    SOFT DRINKS   \n",
       "1     2070   834103     1.0        2224.0    GROCERY  National    SOFT DRINKS   \n",
       "\n",
       "               sub_commodity_desc curr_size_of_product age_desc  \\\n",
       "0  SFT DRNK SNGL SRV BTL CARB (EX                20 OZ    45-54   \n",
       "1  SFT DRNK SNGL SRV BTL CARB (EX                20 OZ    45-54   \n",
       "\n",
       "  marital_status_code income_desc homeowner_desc hh_comp_desc  \\\n",
       "0                   U      50-74K        Unknown      Unknown   \n",
       "1                   U      50-74K        Unknown      Unknown   \n",
       "\n",
       "  household_size_desc kid_category_desc  average_basket_price  \\\n",
       "0                   1      None/Unknown               2.18786   \n",
       "1                   1      None/Unknown               2.18786   \n",
       "\n",
       "   purchases_per_month  item_per_week  \n",
       "0             1.416667      10.166667  \n",
       "1             1.416667      10.166667  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_lvl_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Кол-во покупок товара в неделю\n",
    "item_per_week_val = data_val_lvl_2.groupby(['item_id','week_no'])['quantity'].sum().reset_index()\n",
    "item_per_week_val = item_per_week_val.groupby('item_id')['quantity'].mean().reset_index()\n",
    "item_per_week_val.columns = ['item_id', 'item_per_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2_val = targets_lvl_2_val.merge(item_per_week_val, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split into X & Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = targets_lvl_2.drop('target', axis=1)\n",
    "y_train = targets_lvl_2[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = targets_lvl_2_val.drop('target', axis=1)\n",
    "y_val = targets_lvl_2_val[['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform categorical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = X_train.select_dtypes(['object']).columns.tolist()\n",
    "#fillna in categorical features\n",
    "#X_train[cat_feats]=X_train[cat_feats].fillna(X_train.mode().iloc[0])\n",
    "X_train[cat_feats] = X_train[cat_feats].fillna('unknown') \n",
    "X_train[cat_feats] = X_train[cat_feats].astype('category')\n",
    "\n",
    "X_train['manufacturer'].fillna(X_train['manufacturer'].mode()[0], inplace=True)\n",
    "X_train['manufacturer'] = X_train['manufacturer'].astype('int').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['department',\n",
       " 'brand',\n",
       " 'commodity_desc',\n",
       " 'sub_commodity_desc',\n",
       " 'curr_size_of_product',\n",
       " 'age_desc',\n",
       " 'marital_status_code',\n",
       " 'income_desc',\n",
       " 'homeowner_desc',\n",
       " 'hh_comp_desc',\n",
       " 'household_size_desc',\n",
       " 'kid_category_desc',\n",
       " 'manufacturer']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fillna in categorical features\n",
    "#X_val[cat_feats]=X_val[cat_feats].fillna(X_val.mode().iloc[0])\n",
    "X_val[cat_feats] = X_val[cat_feats].fillna('unknown') \n",
    "X_val[cat_feats] = X_val[cat_feats].astype('category')\n",
    "\n",
    "X_val['manufacturer'].fillna(X_val['manufacturer'].mode()[0], inplace=True)\n",
    "X_val['manufacturer'] = X_val['manufacturer'].astype('int').astype('category')\n",
    "\n",
    "cat_feats.append('manufacturer')\n",
    "cat_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns item_id, user_id because they don't provide any information\n",
    "X_train_ = X_train.drop(columns=['item_id', 'user_id'])\n",
    "X_val_ = X_val.drop(columns=['item_id', 'user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0.060609\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = { \n",
    "    'objective':'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 3000,\n",
    "    'learning_rate': 0.15,\n",
    "    'max_depth': 4,\n",
    "    'categorical_column': cat_feats,\n",
    "    'random_state': 27,\n",
    "    'verbose': 1,\n",
    "    'is_unbalance': True\n",
    "}\n",
    "#'reg_alpha': 0.436193,\n",
    "#'reg_lambda': 0.479169,\n",
    "# \n",
    "#'subsample_for_bin': 240000,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:814: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_error: 0.0606093\ttraining's binary_logloss: 0.253765\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[2]\ttraining's binary_error: 0.0606093\ttraining's binary_logloss: 0.287899\n",
      "[3]\ttraining's binary_error: 0.0644088\ttraining's binary_logloss: 0.320084\n",
      "[4]\ttraining's binary_error: 0.0743081\ttraining's binary_logloss: 0.350004\n",
      "[5]\ttraining's binary_error: 0.0968972\ttraining's binary_logloss: 0.376892\n",
      "[6]\ttraining's binary_error: 0.11729\ttraining's binary_logloss: 0.400825\n",
      "[7]\ttraining's binary_error: 0.127951\ttraining's binary_logloss: 0.422158\n",
      "[8]\ttraining's binary_error: 0.135237\ttraining's binary_logloss: 0.441036\n",
      "[9]\ttraining's binary_error: 0.142881\ttraining's binary_logloss: 0.457727\n",
      "[10]\ttraining's binary_error: 0.150196\ttraining's binary_logloss: 0.472339\n",
      "[11]\ttraining's binary_error: 0.171752\ttraining's binary_logloss: 0.48533\n",
      "[12]\ttraining's binary_error: 0.186892\ttraining's binary_logloss: 0.496329\n",
      "[13]\ttraining's binary_error: 0.198162\ttraining's binary_logloss: 0.505987\n",
      "[14]\ttraining's binary_error: 0.210337\ttraining's binary_logloss: 0.514123\n",
      "[15]\ttraining's binary_error: 0.226818\ttraining's binary_logloss: 0.521199\n",
      "[16]\ttraining's binary_error: 0.233697\ttraining's binary_logloss: 0.527075\n",
      "[17]\ttraining's binary_error: 0.246054\ttraining's binary_logloss: 0.531843\n",
      "[18]\ttraining's binary_error: 0.253629\ttraining's binary_logloss: 0.536028\n",
      "[19]\ttraining's binary_error: 0.260033\ttraining's binary_logloss: 0.539491\n",
      "[20]\ttraining's binary_error: 0.268152\ttraining's binary_logloss: 0.542767\n",
      "[21]\ttraining's binary_error: 0.271277\ttraining's binary_logloss: 0.545174\n",
      "[22]\ttraining's binary_error: 0.273351\ttraining's binary_logloss: 0.546909\n",
      "[23]\ttraining's binary_error: 0.27756\ttraining's binary_logloss: 0.548595\n",
      "[24]\ttraining's binary_error: 0.280107\ttraining's binary_logloss: 0.54981\n",
      "[25]\ttraining's binary_error: 0.280087\ttraining's binary_logloss: 0.55105\n",
      "[26]\ttraining's binary_error: 0.282599\ttraining's binary_logloss: 0.552369\n",
      "[27]\ttraining's binary_error: 0.282846\ttraining's binary_logloss: 0.552879\n",
      "[28]\ttraining's binary_error: 0.2837\ttraining's binary_logloss: 0.553237\n",
      "[29]\ttraining's binary_error: 0.284618\ttraining's binary_logloss: 0.553587\n",
      "[30]\ttraining's binary_error: 0.284933\ttraining's binary_logloss: 0.553807\n",
      "[31]\ttraining's binary_error: 0.285477\ttraining's binary_logloss: 0.553889\n",
      "[32]\ttraining's binary_error: 0.28592\ttraining's binary_logloss: 0.553708\n",
      "[33]\ttraining's binary_error: 0.285968\ttraining's binary_logloss: 0.553386\n",
      "[34]\ttraining's binary_error: 0.286829\ttraining's binary_logloss: 0.553523\n",
      "[35]\ttraining's binary_error: 0.286552\ttraining's binary_logloss: 0.553274\n",
      "[36]\ttraining's binary_error: 0.286787\ttraining's binary_logloss: 0.553175\n",
      "[37]\ttraining's binary_error: 0.286508\ttraining's binary_logloss: 0.552924\n",
      "[38]\ttraining's binary_error: 0.286929\ttraining's binary_logloss: 0.553004\n",
      "[39]\ttraining's binary_error: 0.287677\ttraining's binary_logloss: 0.55274\n",
      "[40]\ttraining's binary_error: 0.287493\ttraining's binary_logloss: 0.552598\n",
      "[41]\ttraining's binary_error: 0.2873\ttraining's binary_logloss: 0.552165\n",
      "[42]\ttraining's binary_error: 0.287433\ttraining's binary_logloss: 0.552165\n",
      "[43]\ttraining's binary_error: 0.286807\ttraining's binary_logloss: 0.551769\n",
      "[44]\ttraining's binary_error: 0.286805\ttraining's binary_logloss: 0.551351\n",
      "[45]\ttraining's binary_error: 0.286448\ttraining's binary_logloss: 0.550856\n",
      "[46]\ttraining's binary_error: 0.286588\ttraining's binary_logloss: 0.550586\n",
      "[47]\ttraining's binary_error: 0.287948\ttraining's binary_logloss: 0.549964\n",
      "[48]\ttraining's binary_error: 0.287788\ttraining's binary_logloss: 0.549693\n",
      "[49]\ttraining's binary_error: 0.287678\ttraining's binary_logloss: 0.549276\n",
      "[50]\ttraining's binary_error: 0.286361\ttraining's binary_logloss: 0.548959\n",
      "[51]\ttraining's binary_error: 0.286065\ttraining's binary_logloss: 0.548575\n",
      "[52]\ttraining's binary_error: 0.285718\ttraining's binary_logloss: 0.548338\n",
      "[53]\ttraining's binary_error: 0.285509\ttraining's binary_logloss: 0.547981\n",
      "[54]\ttraining's binary_error: 0.285495\ttraining's binary_logloss: 0.547811\n",
      "[55]\ttraining's binary_error: 0.285189\ttraining's binary_logloss: 0.547361\n",
      "[56]\ttraining's binary_error: 0.284455\ttraining's binary_logloss: 0.546889\n",
      "[57]\ttraining's binary_error: 0.284095\ttraining's binary_logloss: 0.54654\n",
      "[58]\ttraining's binary_error: 0.284129\ttraining's binary_logloss: 0.546302\n",
      "[59]\ttraining's binary_error: 0.283582\ttraining's binary_logloss: 0.546026\n",
      "[60]\ttraining's binary_error: 0.283595\ttraining's binary_logloss: 0.545516\n",
      "[61]\ttraining's binary_error: 0.283418\ttraining's binary_logloss: 0.545261\n",
      "[62]\ttraining's binary_error: 0.283765\ttraining's binary_logloss: 0.544876\n",
      "[63]\ttraining's binary_error: 0.283651\ttraining's binary_logloss: 0.544711\n",
      "[64]\ttraining's binary_error: 0.283424\ttraining's binary_logloss: 0.544404\n",
      "[65]\ttraining's binary_error: 0.282996\ttraining's binary_logloss: 0.543881\n",
      "[66]\ttraining's binary_error: 0.282067\ttraining's binary_logloss: 0.543401\n",
      "[67]\ttraining's binary_error: 0.282382\ttraining's binary_logloss: 0.543164\n",
      "[68]\ttraining's binary_error: 0.282194\ttraining's binary_logloss: 0.543005\n",
      "[69]\ttraining's binary_error: 0.281706\ttraining's binary_logloss: 0.542723\n",
      "[70]\ttraining's binary_error: 0.281397\ttraining's binary_logloss: 0.542426\n",
      "[71]\ttraining's binary_error: 0.281171\ttraining's binary_logloss: 0.542029\n",
      "[72]\ttraining's binary_error: 0.28105\ttraining's binary_logloss: 0.541798\n",
      "[73]\ttraining's binary_error: 0.28075\ttraining's binary_logloss: 0.541575\n",
      "[74]\ttraining's binary_error: 0.28034\ttraining's binary_logloss: 0.54134\n",
      "[75]\ttraining's binary_error: 0.280178\ttraining's binary_logloss: 0.540845\n",
      "[76]\ttraining's binary_error: 0.279966\ttraining's binary_logloss: 0.540514\n",
      "[77]\ttraining's binary_error: 0.279805\ttraining's binary_logloss: 0.540107\n",
      "[78]\ttraining's binary_error: 0.279506\ttraining's binary_logloss: 0.539731\n",
      "[79]\ttraining's binary_error: 0.279304\ttraining's binary_logloss: 0.539548\n",
      "[80]\ttraining's binary_error: 0.279292\ttraining's binary_logloss: 0.539261\n",
      "[81]\ttraining's binary_error: 0.279135\ttraining's binary_logloss: 0.539035\n",
      "[82]\ttraining's binary_error: 0.278874\ttraining's binary_logloss: 0.538778\n",
      "[83]\ttraining's binary_error: 0.278615\ttraining's binary_logloss: 0.538507\n",
      "[84]\ttraining's binary_error: 0.278323\ttraining's binary_logloss: 0.538319\n",
      "[85]\ttraining's binary_error: 0.278218\ttraining's binary_logloss: 0.538125\n",
      "[86]\ttraining's binary_error: 0.278377\ttraining's binary_logloss: 0.537992\n",
      "[87]\ttraining's binary_error: 0.277851\ttraining's binary_logloss: 0.537397\n",
      "[88]\ttraining's binary_error: 0.27621\ttraining's binary_logloss: 0.536606\n",
      "[89]\ttraining's binary_error: 0.276185\ttraining's binary_logloss: 0.536476\n",
      "[90]\ttraining's binary_error: 0.276012\ttraining's binary_logloss: 0.536196\n",
      "[91]\ttraining's binary_error: 0.276067\ttraining's binary_logloss: 0.536134\n",
      "[92]\ttraining's binary_error: 0.276441\ttraining's binary_logloss: 0.535865\n",
      "[93]\ttraining's binary_error: 0.275987\ttraining's binary_logloss: 0.53541\n",
      "[94]\ttraining's binary_error: 0.275234\ttraining's binary_logloss: 0.535012\n",
      "[95]\ttraining's binary_error: 0.275133\ttraining's binary_logloss: 0.534893\n",
      "[96]\ttraining's binary_error: 0.274842\ttraining's binary_logloss: 0.534446\n",
      "[97]\ttraining's binary_error: 0.274936\ttraining's binary_logloss: 0.533965\n",
      "[98]\ttraining's binary_error: 0.274622\ttraining's binary_logloss: 0.533775\n",
      "[99]\ttraining's binary_error: 0.274553\ttraining's binary_logloss: 0.533641\n",
      "[100]\ttraining's binary_error: 0.274498\ttraining's binary_logloss: 0.533427\n",
      "[101]\ttraining's binary_error: 0.274477\ttraining's binary_logloss: 0.533361\n",
      "[102]\ttraining's binary_error: 0.274171\ttraining's binary_logloss: 0.532973\n",
      "[103]\ttraining's binary_error: 0.274024\ttraining's binary_logloss: 0.532719\n",
      "[104]\ttraining's binary_error: 0.273741\ttraining's binary_logloss: 0.532372\n",
      "[105]\ttraining's binary_error: 0.273688\ttraining's binary_logloss: 0.532219\n",
      "[106]\ttraining's binary_error: 0.273205\ttraining's binary_logloss: 0.53192\n",
      "[107]\ttraining's binary_error: 0.272678\ttraining's binary_logloss: 0.531526\n",
      "[108]\ttraining's binary_error: 0.272629\ttraining's binary_logloss: 0.53139\n",
      "[109]\ttraining's binary_error: 0.272697\ttraining's binary_logloss: 0.530911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110]\ttraining's binary_error: 0.272542\ttraining's binary_logloss: 0.530761\n",
      "[111]\ttraining's binary_error: 0.272491\ttraining's binary_logloss: 0.530678\n",
      "[112]\ttraining's binary_error: 0.272039\ttraining's binary_logloss: 0.530237\n",
      "[113]\ttraining's binary_error: 0.271609\ttraining's binary_logloss: 0.529762\n",
      "[114]\ttraining's binary_error: 0.271444\ttraining's binary_logloss: 0.529574\n",
      "[115]\ttraining's binary_error: 0.270975\ttraining's binary_logloss: 0.529261\n",
      "[116]\ttraining's binary_error: 0.270736\ttraining's binary_logloss: 0.528911\n",
      "[117]\ttraining's binary_error: 0.270727\ttraining's binary_logloss: 0.528738\n",
      "[118]\ttraining's binary_error: 0.270519\ttraining's binary_logloss: 0.528487\n",
      "[119]\ttraining's binary_error: 0.27056\ttraining's binary_logloss: 0.528397\n",
      "[120]\ttraining's binary_error: 0.270521\ttraining's binary_logloss: 0.52828\n",
      "[121]\ttraining's binary_error: 0.270357\ttraining's binary_logloss: 0.528132\n",
      "[122]\ttraining's binary_error: 0.270381\ttraining's binary_logloss: 0.527655\n",
      "[123]\ttraining's binary_error: 0.269831\ttraining's binary_logloss: 0.527194\n",
      "[124]\ttraining's binary_error: 0.269774\ttraining's binary_logloss: 0.527007\n",
      "[125]\ttraining's binary_error: 0.269609\ttraining's binary_logloss: 0.526904\n",
      "[126]\ttraining's binary_error: 0.269475\ttraining's binary_logloss: 0.52677\n",
      "[127]\ttraining's binary_error: 0.269246\ttraining's binary_logloss: 0.526462\n",
      "[128]\ttraining's binary_error: 0.268946\ttraining's binary_logloss: 0.526237\n",
      "[129]\ttraining's binary_error: 0.268983\ttraining's binary_logloss: 0.526163\n",
      "[130]\ttraining's binary_error: 0.268846\ttraining's binary_logloss: 0.525989\n",
      "[131]\ttraining's binary_error: 0.268803\ttraining's binary_logloss: 0.525878\n",
      "[132]\ttraining's binary_error: 0.269108\ttraining's binary_logloss: 0.525766\n",
      "[133]\ttraining's binary_error: 0.268799\ttraining's binary_logloss: 0.525509\n",
      "[134]\ttraining's binary_error: 0.268369\ttraining's binary_logloss: 0.524972\n",
      "[135]\ttraining's binary_error: 0.268063\ttraining's binary_logloss: 0.524668\n",
      "[136]\ttraining's binary_error: 0.267861\ttraining's binary_logloss: 0.524517\n",
      "[137]\ttraining's binary_error: 0.267802\ttraining's binary_logloss: 0.524451\n",
      "[138]\ttraining's binary_error: 0.267805\ttraining's binary_logloss: 0.524344\n",
      "[139]\ttraining's binary_error: 0.267804\ttraining's binary_logloss: 0.5242\n",
      "[140]\ttraining's binary_error: 0.267597\ttraining's binary_logloss: 0.524051\n",
      "[141]\ttraining's binary_error: 0.267623\ttraining's binary_logloss: 0.523922\n",
      "[142]\ttraining's binary_error: 0.267324\ttraining's binary_logloss: 0.523841\n",
      "[143]\ttraining's binary_error: 0.267274\ttraining's binary_logloss: 0.523583\n",
      "[144]\ttraining's binary_error: 0.266853\ttraining's binary_logloss: 0.523204\n",
      "[145]\ttraining's binary_error: 0.266822\ttraining's binary_logloss: 0.522969\n",
      "[146]\ttraining's binary_error: 0.266508\ttraining's binary_logloss: 0.52264\n",
      "[147]\ttraining's binary_error: 0.265846\ttraining's binary_logloss: 0.522258\n",
      "[148]\ttraining's binary_error: 0.265881\ttraining's binary_logloss: 0.522186\n",
      "[149]\ttraining's binary_error: 0.265912\ttraining's binary_logloss: 0.522041\n",
      "[150]\ttraining's binary_error: 0.26578\ttraining's binary_logloss: 0.521716\n",
      "[151]\ttraining's binary_error: 0.265259\ttraining's binary_logloss: 0.521256\n",
      "[152]\ttraining's binary_error: 0.26507\ttraining's binary_logloss: 0.521157\n",
      "[153]\ttraining's binary_error: 0.265052\ttraining's binary_logloss: 0.521088\n",
      "[154]\ttraining's binary_error: 0.264985\ttraining's binary_logloss: 0.520889\n",
      "[155]\ttraining's binary_error: 0.264813\ttraining's binary_logloss: 0.520756\n",
      "[156]\ttraining's binary_error: 0.264692\ttraining's binary_logloss: 0.520641\n",
      "[157]\ttraining's binary_error: 0.264369\ttraining's binary_logloss: 0.520274\n",
      "[158]\ttraining's binary_error: 0.264296\ttraining's binary_logloss: 0.52017\n",
      "[159]\ttraining's binary_error: 0.264215\ttraining's binary_logloss: 0.519812\n",
      "[160]\ttraining's binary_error: 0.263893\ttraining's binary_logloss: 0.519553\n",
      "[161]\ttraining's binary_error: 0.263668\ttraining's binary_logloss: 0.519221\n",
      "[162]\ttraining's binary_error: 0.263221\ttraining's binary_logloss: 0.518676\n",
      "[163]\ttraining's binary_error: 0.263181\ttraining's binary_logloss: 0.518504\n",
      "[164]\ttraining's binary_error: 0.262979\ttraining's binary_logloss: 0.518137\n",
      "[165]\ttraining's binary_error: 0.262692\ttraining's binary_logloss: 0.517931\n",
      "[166]\ttraining's binary_error: 0.262579\ttraining's binary_logloss: 0.517795\n",
      "[167]\ttraining's binary_error: 0.262336\ttraining's binary_logloss: 0.517558\n",
      "[168]\ttraining's binary_error: 0.262333\ttraining's binary_logloss: 0.517373\n",
      "[169]\ttraining's binary_error: 0.262305\ttraining's binary_logloss: 0.517278\n",
      "[170]\ttraining's binary_error: 0.262089\ttraining's binary_logloss: 0.517146\n",
      "[171]\ttraining's binary_error: 0.26203\ttraining's binary_logloss: 0.516975\n",
      "[172]\ttraining's binary_error: 0.2618\ttraining's binary_logloss: 0.516869\n",
      "[173]\ttraining's binary_error: 0.26182\ttraining's binary_logloss: 0.516753\n",
      "[174]\ttraining's binary_error: 0.261876\ttraining's binary_logloss: 0.516706\n",
      "[175]\ttraining's binary_error: 0.261747\ttraining's binary_logloss: 0.516482\n",
      "[176]\ttraining's binary_error: 0.261629\ttraining's binary_logloss: 0.51626\n",
      "[177]\ttraining's binary_error: 0.261433\ttraining's binary_logloss: 0.515907\n",
      "[178]\ttraining's binary_error: 0.261395\ttraining's binary_logloss: 0.515831\n",
      "[179]\ttraining's binary_error: 0.261037\ttraining's binary_logloss: 0.515543\n",
      "[180]\ttraining's binary_error: 0.260703\ttraining's binary_logloss: 0.515179\n",
      "[181]\ttraining's binary_error: 0.260438\ttraining's binary_logloss: 0.51487\n",
      "[182]\ttraining's binary_error: 0.260316\ttraining's binary_logloss: 0.51464\n",
      "[183]\ttraining's binary_error: 0.260244\ttraining's binary_logloss: 0.514546\n",
      "[184]\ttraining's binary_error: 0.259952\ttraining's binary_logloss: 0.514298\n",
      "[185]\ttraining's binary_error: 0.259609\ttraining's binary_logloss: 0.51402\n",
      "[186]\ttraining's binary_error: 0.259521\ttraining's binary_logloss: 0.513753\n",
      "[187]\ttraining's binary_error: 0.259481\ttraining's binary_logloss: 0.51369\n",
      "[188]\ttraining's binary_error: 0.259402\ttraining's binary_logloss: 0.513449\n",
      "[189]\ttraining's binary_error: 0.259334\ttraining's binary_logloss: 0.513301\n",
      "[190]\ttraining's binary_error: 0.259165\ttraining's binary_logloss: 0.513122\n",
      "[191]\ttraining's binary_error: 0.2592\ttraining's binary_logloss: 0.513061\n",
      "[192]\ttraining's binary_error: 0.259086\ttraining's binary_logloss: 0.512985\n",
      "[193]\ttraining's binary_error: 0.258531\ttraining's binary_logloss: 0.512417\n",
      "[194]\ttraining's binary_error: 0.258627\ttraining's binary_logloss: 0.512264\n",
      "[195]\ttraining's binary_error: 0.258588\ttraining's binary_logloss: 0.512196\n",
      "[196]\ttraining's binary_error: 0.258307\ttraining's binary_logloss: 0.511968\n",
      "[197]\ttraining's binary_error: 0.258311\ttraining's binary_logloss: 0.511745\n",
      "[198]\ttraining's binary_error: 0.258261\ttraining's binary_logloss: 0.511641\n",
      "[199]\ttraining's binary_error: 0.257893\ttraining's binary_logloss: 0.511531\n",
      "[200]\ttraining's binary_error: 0.257911\ttraining's binary_logloss: 0.511402\n",
      "[201]\ttraining's binary_error: 0.257806\ttraining's binary_logloss: 0.511306\n",
      "[202]\ttraining's binary_error: 0.257647\ttraining's binary_logloss: 0.511045\n",
      "[203]\ttraining's binary_error: 0.257231\ttraining's binary_logloss: 0.510653\n",
      "[204]\ttraining's binary_error: 0.257116\ttraining's binary_logloss: 0.510525\n",
      "[205]\ttraining's binary_error: 0.256956\ttraining's binary_logloss: 0.510348\n",
      "[206]\ttraining's binary_error: 0.256877\ttraining's binary_logloss: 0.510223\n",
      "[207]\ttraining's binary_error: 0.256863\ttraining's binary_logloss: 0.510173\n",
      "[208]\ttraining's binary_error: 0.256872\ttraining's binary_logloss: 0.510026\n",
      "[209]\ttraining's binary_error: 0.256703\ttraining's binary_logloss: 0.509739\n",
      "[210]\ttraining's binary_error: 0.256651\ttraining's binary_logloss: 0.509523\n",
      "[211]\ttraining's binary_error: 0.256486\ttraining's binary_logloss: 0.509324\n",
      "[212]\ttraining's binary_error: 0.256415\ttraining's binary_logloss: 0.509081\n",
      "[213]\ttraining's binary_error: 0.256033\ttraining's binary_logloss: 0.508657\n",
      "[214]\ttraining's binary_error: 0.255994\ttraining's binary_logloss: 0.508581\n",
      "[215]\ttraining's binary_error: 0.255902\ttraining's binary_logloss: 0.508517\n",
      "[216]\ttraining's binary_error: 0.255828\ttraining's binary_logloss: 0.508447\n",
      "[217]\ttraining's binary_error: 0.255865\ttraining's binary_logloss: 0.508332\n",
      "[218]\ttraining's binary_error: 0.255843\ttraining's binary_logloss: 0.508267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[219]\ttraining's binary_error: 0.255834\ttraining's binary_logloss: 0.508132\n",
      "[220]\ttraining's binary_error: 0.255795\ttraining's binary_logloss: 0.508023\n",
      "[221]\ttraining's binary_error: 0.255522\ttraining's binary_logloss: 0.507763\n",
      "[222]\ttraining's binary_error: 0.25545\ttraining's binary_logloss: 0.507669\n",
      "[223]\ttraining's binary_error: 0.255278\ttraining's binary_logloss: 0.507521\n",
      "[224]\ttraining's binary_error: 0.255141\ttraining's binary_logloss: 0.507416\n",
      "[225]\ttraining's binary_error: 0.255017\ttraining's binary_logloss: 0.507213\n",
      "[226]\ttraining's binary_error: 0.254861\ttraining's binary_logloss: 0.506951\n",
      "[227]\ttraining's binary_error: 0.254751\ttraining's binary_logloss: 0.506849\n",
      "[228]\ttraining's binary_error: 0.254676\ttraining's binary_logloss: 0.506745\n",
      "[229]\ttraining's binary_error: 0.254628\ttraining's binary_logloss: 0.506686\n",
      "[230]\ttraining's binary_error: 0.254198\ttraining's binary_logloss: 0.506108\n",
      "[231]\ttraining's binary_error: 0.253906\ttraining's binary_logloss: 0.505807\n",
      "[232]\ttraining's binary_error: 0.253708\ttraining's binary_logloss: 0.50556\n",
      "[233]\ttraining's binary_error: 0.253341\ttraining's binary_logloss: 0.505159\n",
      "[234]\ttraining's binary_error: 0.2533\ttraining's binary_logloss: 0.504991\n",
      "[235]\ttraining's binary_error: 0.253298\ttraining's binary_logloss: 0.504927\n",
      "[236]\ttraining's binary_error: 0.253183\ttraining's binary_logloss: 0.504793\n",
      "[237]\ttraining's binary_error: 0.253163\ttraining's binary_logloss: 0.504696\n",
      "[238]\ttraining's binary_error: 0.253014\ttraining's binary_logloss: 0.504621\n",
      "[239]\ttraining's binary_error: 0.252785\ttraining's binary_logloss: 0.504353\n",
      "[240]\ttraining's binary_error: 0.252673\ttraining's binary_logloss: 0.504136\n",
      "[241]\ttraining's binary_error: 0.252643\ttraining's binary_logloss: 0.504082\n",
      "[242]\ttraining's binary_error: 0.252525\ttraining's binary_logloss: 0.503971\n",
      "[243]\ttraining's binary_error: 0.252249\ttraining's binary_logloss: 0.503712\n",
      "[244]\ttraining's binary_error: 0.252168\ttraining's binary_logloss: 0.503595\n",
      "[245]\ttraining's binary_error: 0.252144\ttraining's binary_logloss: 0.503456\n",
      "[246]\ttraining's binary_error: 0.252077\ttraining's binary_logloss: 0.503366\n",
      "[247]\ttraining's binary_error: 0.252052\ttraining's binary_logloss: 0.503299\n",
      "[248]\ttraining's binary_error: 0.251808\ttraining's binary_logloss: 0.503064\n",
      "[249]\ttraining's binary_error: 0.251748\ttraining's binary_logloss: 0.503036\n",
      "[250]\ttraining's binary_error: 0.251719\ttraining's binary_logloss: 0.502953\n",
      "[251]\ttraining's binary_error: 0.251617\ttraining's binary_logloss: 0.502907\n",
      "[252]\ttraining's binary_error: 0.251589\ttraining's binary_logloss: 0.502805\n",
      "[253]\ttraining's binary_error: 0.251631\ttraining's binary_logloss: 0.502718\n",
      "[254]\ttraining's binary_error: 0.251729\ttraining's binary_logloss: 0.502539\n",
      "[255]\ttraining's binary_error: 0.251498\ttraining's binary_logloss: 0.502178\n",
      "[256]\ttraining's binary_error: 0.251351\ttraining's binary_logloss: 0.50209\n",
      "[257]\ttraining's binary_error: 0.251146\ttraining's binary_logloss: 0.501856\n",
      "[258]\ttraining's binary_error: 0.251056\ttraining's binary_logloss: 0.501791\n",
      "[259]\ttraining's binary_error: 0.250916\ttraining's binary_logloss: 0.501647\n",
      "[260]\ttraining's binary_error: 0.250846\ttraining's binary_logloss: 0.501464\n",
      "[261]\ttraining's binary_error: 0.25083\ttraining's binary_logloss: 0.50137\n",
      "[262]\ttraining's binary_error: 0.250764\ttraining's binary_logloss: 0.501288\n",
      "[263]\ttraining's binary_error: 0.250739\ttraining's binary_logloss: 0.501164\n",
      "[264]\ttraining's binary_error: 0.250929\ttraining's binary_logloss: 0.501067\n",
      "[265]\ttraining's binary_error: 0.250766\ttraining's binary_logloss: 0.500894\n",
      "[266]\ttraining's binary_error: 0.250462\ttraining's binary_logloss: 0.500597\n",
      "[267]\ttraining's binary_error: 0.250374\ttraining's binary_logloss: 0.500504\n",
      "[268]\ttraining's binary_error: 0.250347\ttraining's binary_logloss: 0.500451\n",
      "[269]\ttraining's binary_error: 0.250198\ttraining's binary_logloss: 0.500282\n",
      "[270]\ttraining's binary_error: 0.250028\ttraining's binary_logloss: 0.500121\n",
      "[271]\ttraining's binary_error: 0.24962\ttraining's binary_logloss: 0.499842\n",
      "[272]\ttraining's binary_error: 0.249451\ttraining's binary_logloss: 0.499697\n",
      "[273]\ttraining's binary_error: 0.249426\ttraining's binary_logloss: 0.499623\n",
      "[274]\ttraining's binary_error: 0.24935\ttraining's binary_logloss: 0.499566\n",
      "[275]\ttraining's binary_error: 0.249196\ttraining's binary_logloss: 0.499377\n",
      "[276]\ttraining's binary_error: 0.249209\ttraining's binary_logloss: 0.499192\n",
      "[277]\ttraining's binary_error: 0.249095\ttraining's binary_logloss: 0.499033\n",
      "[278]\ttraining's binary_error: 0.24903\ttraining's binary_logloss: 0.498947\n",
      "[279]\ttraining's binary_error: 0.248966\ttraining's binary_logloss: 0.49881\n",
      "[280]\ttraining's binary_error: 0.248789\ttraining's binary_logloss: 0.498629\n",
      "[281]\ttraining's binary_error: 0.248613\ttraining's binary_logloss: 0.498523\n",
      "[282]\ttraining's binary_error: 0.248634\ttraining's binary_logloss: 0.498401\n",
      "[283]\ttraining's binary_error: 0.248633\ttraining's binary_logloss: 0.498375\n",
      "[284]\ttraining's binary_error: 0.248581\ttraining's binary_logloss: 0.498291\n",
      "[285]\ttraining's binary_error: 0.248515\ttraining's binary_logloss: 0.498203\n",
      "[286]\ttraining's binary_error: 0.248402\ttraining's binary_logloss: 0.497994\n",
      "[287]\ttraining's binary_error: 0.248261\ttraining's binary_logloss: 0.497764\n",
      "[288]\ttraining's binary_error: 0.248153\ttraining's binary_logloss: 0.497577\n",
      "[289]\ttraining's binary_error: 0.248149\ttraining's binary_logloss: 0.497519\n",
      "[290]\ttraining's binary_error: 0.248114\ttraining's binary_logloss: 0.49749\n",
      "[291]\ttraining's binary_error: 0.248048\ttraining's binary_logloss: 0.497355\n",
      "[292]\ttraining's binary_error: 0.247993\ttraining's binary_logloss: 0.497204\n",
      "[293]\ttraining's binary_error: 0.247905\ttraining's binary_logloss: 0.497015\n",
      "[294]\ttraining's binary_error: 0.247722\ttraining's binary_logloss: 0.496791\n",
      "[295]\ttraining's binary_error: 0.247587\ttraining's binary_logloss: 0.496625\n",
      "[296]\ttraining's binary_error: 0.247478\ttraining's binary_logloss: 0.496575\n",
      "[297]\ttraining's binary_error: 0.247365\ttraining's binary_logloss: 0.496246\n",
      "[298]\ttraining's binary_error: 0.247201\ttraining's binary_logloss: 0.496113\n",
      "[299]\ttraining's binary_error: 0.247025\ttraining's binary_logloss: 0.49596\n",
      "[300]\ttraining's binary_error: 0.246805\ttraining's binary_logloss: 0.495772\n",
      "[301]\ttraining's binary_error: 0.246689\ttraining's binary_logloss: 0.495627\n",
      "[302]\ttraining's binary_error: 0.246605\ttraining's binary_logloss: 0.495355\n",
      "[303]\ttraining's binary_error: 0.246545\ttraining's binary_logloss: 0.495308\n",
      "[304]\ttraining's binary_error: 0.246535\ttraining's binary_logloss: 0.495259\n",
      "[305]\ttraining's binary_error: 0.246492\ttraining's binary_logloss: 0.495037\n",
      "[306]\ttraining's binary_error: 0.246352\ttraining's binary_logloss: 0.4949\n",
      "[307]\ttraining's binary_error: 0.246403\ttraining's binary_logloss: 0.494865\n",
      "[308]\ttraining's binary_error: 0.246116\ttraining's binary_logloss: 0.4946\n",
      "[309]\ttraining's binary_error: 0.245866\ttraining's binary_logloss: 0.494296\n",
      "[310]\ttraining's binary_error: 0.245694\ttraining's binary_logloss: 0.49413\n",
      "[311]\ttraining's binary_error: 0.245655\ttraining's binary_logloss: 0.49405\n",
      "[312]\ttraining's binary_error: 0.245588\ttraining's binary_logloss: 0.493993\n",
      "[313]\ttraining's binary_error: 0.24546\ttraining's binary_logloss: 0.493849\n",
      "[314]\ttraining's binary_error: 0.245458\ttraining's binary_logloss: 0.493767\n",
      "[315]\ttraining's binary_error: 0.245382\ttraining's binary_logloss: 0.493673\n",
      "[316]\ttraining's binary_error: 0.245353\ttraining's binary_logloss: 0.493594\n",
      "[317]\ttraining's binary_error: 0.245354\ttraining's binary_logloss: 0.493483\n",
      "[318]\ttraining's binary_error: 0.245228\ttraining's binary_logloss: 0.493335\n",
      "[319]\ttraining's binary_error: 0.245255\ttraining's binary_logloss: 0.493283\n",
      "[320]\ttraining's binary_error: 0.245183\ttraining's binary_logloss: 0.493183\n",
      "[321]\ttraining's binary_error: 0.24495\ttraining's binary_logloss: 0.492927\n",
      "[322]\ttraining's binary_error: 0.244911\ttraining's binary_logloss: 0.492803\n",
      "[323]\ttraining's binary_error: 0.244778\ttraining's binary_logloss: 0.492724\n",
      "[324]\ttraining's binary_error: 0.244758\ttraining's binary_logloss: 0.492677\n",
      "[325]\ttraining's binary_error: 0.244758\ttraining's binary_logloss: 0.492601\n",
      "[326]\ttraining's binary_error: 0.244717\ttraining's binary_logloss: 0.492502\n",
      "[327]\ttraining's binary_error: 0.244676\ttraining's binary_logloss: 0.492414\n",
      "[328]\ttraining's binary_error: 0.244589\ttraining's binary_logloss: 0.492347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329]\ttraining's binary_error: 0.244662\ttraining's binary_logloss: 0.492245\n",
      "[330]\ttraining's binary_error: 0.244479\ttraining's binary_logloss: 0.492063\n",
      "[331]\ttraining's binary_error: 0.24405\ttraining's binary_logloss: 0.491718\n",
      "[332]\ttraining's binary_error: 0.244126\ttraining's binary_logloss: 0.491658\n",
      "[333]\ttraining's binary_error: 0.243892\ttraining's binary_logloss: 0.491413\n",
      "[334]\ttraining's binary_error: 0.243789\ttraining's binary_logloss: 0.491355\n",
      "[335]\ttraining's binary_error: 0.2438\ttraining's binary_logloss: 0.491281\n",
      "[336]\ttraining's binary_error: 0.243577\ttraining's binary_logloss: 0.49111\n",
      "[337]\ttraining's binary_error: 0.243505\ttraining's binary_logloss: 0.491069\n",
      "[338]\ttraining's binary_error: 0.243452\ttraining's binary_logloss: 0.490941\n",
      "[339]\ttraining's binary_error: 0.243404\ttraining's binary_logloss: 0.490885\n",
      "[340]\ttraining's binary_error: 0.243312\ttraining's binary_logloss: 0.490843\n",
      "[341]\ttraining's binary_error: 0.243241\ttraining's binary_logloss: 0.49075\n",
      "[342]\ttraining's binary_error: 0.243093\ttraining's binary_logloss: 0.490451\n",
      "[343]\ttraining's binary_error: 0.242944\ttraining's binary_logloss: 0.490247\n",
      "[344]\ttraining's binary_error: 0.242618\ttraining's binary_logloss: 0.490079\n",
      "[345]\ttraining's binary_error: 0.24257\ttraining's binary_logloss: 0.490032\n",
      "[346]\ttraining's binary_error: 0.242497\ttraining's binary_logloss: 0.489937\n",
      "[347]\ttraining's binary_error: 0.242237\ttraining's binary_logloss: 0.489674\n",
      "[348]\ttraining's binary_error: 0.242068\ttraining's binary_logloss: 0.489494\n",
      "[349]\ttraining's binary_error: 0.241973\ttraining's binary_logloss: 0.489341\n",
      "[350]\ttraining's binary_error: 0.241721\ttraining's binary_logloss: 0.48923\n",
      "[351]\ttraining's binary_error: 0.241689\ttraining's binary_logloss: 0.489074\n",
      "[352]\ttraining's binary_error: 0.241601\ttraining's binary_logloss: 0.488958\n",
      "[353]\ttraining's binary_error: 0.241566\ttraining's binary_logloss: 0.488921\n",
      "[354]\ttraining's binary_error: 0.241556\ttraining's binary_logloss: 0.488877\n",
      "[355]\ttraining's binary_error: 0.241527\ttraining's binary_logloss: 0.488752\n",
      "[356]\ttraining's binary_error: 0.241417\ttraining's binary_logloss: 0.488595\n",
      "[357]\ttraining's binary_error: 0.241106\ttraining's binary_logloss: 0.488274\n",
      "[358]\ttraining's binary_error: 0.240993\ttraining's binary_logloss: 0.48822\n",
      "[359]\ttraining's binary_error: 0.241018\ttraining's binary_logloss: 0.488122\n",
      "[360]\ttraining's binary_error: 0.240976\ttraining's binary_logloss: 0.48807\n",
      "[361]\ttraining's binary_error: 0.24087\ttraining's binary_logloss: 0.487852\n",
      "[362]\ttraining's binary_error: 0.240835\ttraining's binary_logloss: 0.487733\n",
      "[363]\ttraining's binary_error: 0.240787\ttraining's binary_logloss: 0.487666\n",
      "[364]\ttraining's binary_error: 0.240678\ttraining's binary_logloss: 0.487543\n",
      "[365]\ttraining's binary_error: 0.240649\ttraining's binary_logloss: 0.487471\n",
      "[366]\ttraining's binary_error: 0.240556\ttraining's binary_logloss: 0.487313\n",
      "[367]\ttraining's binary_error: 0.240415\ttraining's binary_logloss: 0.487226\n",
      "[368]\ttraining's binary_error: 0.240337\ttraining's binary_logloss: 0.487124\n",
      "[369]\ttraining's binary_error: 0.240336\ttraining's binary_logloss: 0.487054\n",
      "[370]\ttraining's binary_error: 0.240295\ttraining's binary_logloss: 0.486999\n",
      "[371]\ttraining's binary_error: 0.240225\ttraining's binary_logloss: 0.486819\n",
      "[372]\ttraining's binary_error: 0.240086\ttraining's binary_logloss: 0.486663\n",
      "[373]\ttraining's binary_error: 0.239991\ttraining's binary_logloss: 0.486537\n",
      "[374]\ttraining's binary_error: 0.239837\ttraining's binary_logloss: 0.486351\n",
      "[375]\ttraining's binary_error: 0.239736\ttraining's binary_logloss: 0.48621\n",
      "[376]\ttraining's binary_error: 0.239753\ttraining's binary_logloss: 0.486163\n",
      "[377]\ttraining's binary_error: 0.239657\ttraining's binary_logloss: 0.486062\n",
      "[378]\ttraining's binary_error: 0.23953\ttraining's binary_logloss: 0.48595\n",
      "[379]\ttraining's binary_error: 0.239124\ttraining's binary_logloss: 0.485814\n",
      "[380]\ttraining's binary_error: 0.239003\ttraining's binary_logloss: 0.485737\n",
      "[381]\ttraining's binary_error: 0.238982\ttraining's binary_logloss: 0.485622\n",
      "[382]\ttraining's binary_error: 0.239008\ttraining's binary_logloss: 0.485598\n",
      "[383]\ttraining's binary_error: 0.238998\ttraining's binary_logloss: 0.485512\n",
      "[384]\ttraining's binary_error: 0.238932\ttraining's binary_logloss: 0.485384\n",
      "[385]\ttraining's binary_error: 0.238682\ttraining's binary_logloss: 0.485098\n",
      "[386]\ttraining's binary_error: 0.238667\ttraining's binary_logloss: 0.485051\n",
      "[387]\ttraining's binary_error: 0.238615\ttraining's binary_logloss: 0.48493\n",
      "[388]\ttraining's binary_error: 0.238504\ttraining's binary_logloss: 0.484887\n",
      "[389]\ttraining's binary_error: 0.238469\ttraining's binary_logloss: 0.484824\n",
      "[390]\ttraining's binary_error: 0.238412\ttraining's binary_logloss: 0.484682\n",
      "[391]\ttraining's binary_error: 0.238227\ttraining's binary_logloss: 0.484587\n",
      "[392]\ttraining's binary_error: 0.238167\ttraining's binary_logloss: 0.484477\n",
      "[393]\ttraining's binary_error: 0.238053\ttraining's binary_logloss: 0.484364\n",
      "[394]\ttraining's binary_error: 0.238067\ttraining's binary_logloss: 0.484219\n",
      "[395]\ttraining's binary_error: 0.237989\ttraining's binary_logloss: 0.484113\n",
      "[396]\ttraining's binary_error: 0.237903\ttraining's binary_logloss: 0.483974\n",
      "[397]\ttraining's binary_error: 0.237803\ttraining's binary_logloss: 0.483873\n",
      "[398]\ttraining's binary_error: 0.237803\ttraining's binary_logloss: 0.483812\n",
      "[399]\ttraining's binary_error: 0.237718\ttraining's binary_logloss: 0.483727\n",
      "[400]\ttraining's binary_error: 0.237563\ttraining's binary_logloss: 0.483624\n",
      "[401]\ttraining's binary_error: 0.237547\ttraining's binary_logloss: 0.483587\n",
      "[402]\ttraining's binary_error: 0.23752\ttraining's binary_logloss: 0.483571\n",
      "[403]\ttraining's binary_error: 0.23741\ttraining's binary_logloss: 0.483416\n",
      "[404]\ttraining's binary_error: 0.23737\ttraining's binary_logloss: 0.483371\n",
      "[405]\ttraining's binary_error: 0.237182\ttraining's binary_logloss: 0.482956\n",
      "[406]\ttraining's binary_error: 0.23716\ttraining's binary_logloss: 0.482915\n",
      "[407]\ttraining's binary_error: 0.237048\ttraining's binary_logloss: 0.482833\n",
      "[408]\ttraining's binary_error: 0.236999\ttraining's binary_logloss: 0.482774\n",
      "[409]\ttraining's binary_error: 0.236859\ttraining's binary_logloss: 0.482671\n",
      "[410]\ttraining's binary_error: 0.236848\ttraining's binary_logloss: 0.48263\n",
      "[411]\ttraining's binary_error: 0.236758\ttraining's binary_logloss: 0.482404\n",
      "[412]\ttraining's binary_error: 0.236721\ttraining's binary_logloss: 0.482323\n",
      "[413]\ttraining's binary_error: 0.236673\ttraining's binary_logloss: 0.482257\n",
      "[414]\ttraining's binary_error: 0.236665\ttraining's binary_logloss: 0.482209\n",
      "[415]\ttraining's binary_error: 0.236657\ttraining's binary_logloss: 0.482104\n",
      "[416]\ttraining's binary_error: 0.236533\ttraining's binary_logloss: 0.481929\n",
      "[417]\ttraining's binary_error: 0.23649\ttraining's binary_logloss: 0.481878\n",
      "[418]\ttraining's binary_error: 0.236426\ttraining's binary_logloss: 0.481675\n",
      "[419]\ttraining's binary_error: 0.23635\ttraining's binary_logloss: 0.481587\n",
      "[420]\ttraining's binary_error: 0.236351\ttraining's binary_logloss: 0.481533\n",
      "[421]\ttraining's binary_error: 0.23619\ttraining's binary_logloss: 0.481485\n",
      "[422]\ttraining's binary_error: 0.23614\ttraining's binary_logloss: 0.481445\n",
      "[423]\ttraining's binary_error: 0.236124\ttraining's binary_logloss: 0.481358\n",
      "[424]\ttraining's binary_error: 0.236044\ttraining's binary_logloss: 0.481178\n",
      "[425]\ttraining's binary_error: 0.23602\ttraining's binary_logloss: 0.481041\n",
      "[426]\ttraining's binary_error: 0.236048\ttraining's binary_logloss: 0.480949\n",
      "[427]\ttraining's binary_error: 0.236006\ttraining's binary_logloss: 0.480872\n",
      "[428]\ttraining's binary_error: 0.23596\ttraining's binary_logloss: 0.48077\n",
      "[429]\ttraining's binary_error: 0.235831\ttraining's binary_logloss: 0.480641\n",
      "[430]\ttraining's binary_error: 0.23582\ttraining's binary_logloss: 0.48057\n",
      "[431]\ttraining's binary_error: 0.235776\ttraining's binary_logloss: 0.480513\n",
      "[432]\ttraining's binary_error: 0.235757\ttraining's binary_logloss: 0.480485\n",
      "[433]\ttraining's binary_error: 0.235601\ttraining's binary_logloss: 0.480289\n",
      "[434]\ttraining's binary_error: 0.235562\ttraining's binary_logloss: 0.480218\n",
      "[435]\ttraining's binary_error: 0.235568\ttraining's binary_logloss: 0.480177\n",
      "[436]\ttraining's binary_error: 0.235433\ttraining's binary_logloss: 0.479958\n",
      "[437]\ttraining's binary_error: 0.235415\ttraining's binary_logloss: 0.479896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[438]\ttraining's binary_error: 0.235383\ttraining's binary_logloss: 0.479826\n",
      "[439]\ttraining's binary_error: 0.23527\ttraining's binary_logloss: 0.479678\n",
      "[440]\ttraining's binary_error: 0.235159\ttraining's binary_logloss: 0.479553\n",
      "[441]\ttraining's binary_error: 0.235031\ttraining's binary_logloss: 0.479405\n",
      "[442]\ttraining's binary_error: 0.234991\ttraining's binary_logloss: 0.479312\n",
      "[443]\ttraining's binary_error: 0.234852\ttraining's binary_logloss: 0.479158\n",
      "[444]\ttraining's binary_error: 0.234672\ttraining's binary_logloss: 0.479049\n",
      "[445]\ttraining's binary_error: 0.234665\ttraining's binary_logloss: 0.479003\n",
      "[446]\ttraining's binary_error: 0.234631\ttraining's binary_logloss: 0.478952\n",
      "[447]\ttraining's binary_error: 0.234581\ttraining's binary_logloss: 0.478848\n",
      "[448]\ttraining's binary_error: 0.234509\ttraining's binary_logloss: 0.478792\n",
      "[449]\ttraining's binary_error: 0.234448\ttraining's binary_logloss: 0.478732\n",
      "[450]\ttraining's binary_error: 0.234373\ttraining's binary_logloss: 0.478604\n",
      "[451]\ttraining's binary_error: 0.234357\ttraining's binary_logloss: 0.47858\n",
      "[452]\ttraining's binary_error: 0.23423\ttraining's binary_logloss: 0.478374\n",
      "[453]\ttraining's binary_error: 0.234108\ttraining's binary_logloss: 0.478193\n",
      "[454]\ttraining's binary_error: 0.234123\ttraining's binary_logloss: 0.478072\n",
      "[455]\ttraining's binary_error: 0.233744\ttraining's binary_logloss: 0.477766\n",
      "[456]\ttraining's binary_error: 0.233711\ttraining's binary_logloss: 0.477629\n",
      "[457]\ttraining's binary_error: 0.233723\ttraining's binary_logloss: 0.477554\n",
      "[458]\ttraining's binary_error: 0.233651\ttraining's binary_logloss: 0.477496\n",
      "[459]\ttraining's binary_error: 0.233572\ttraining's binary_logloss: 0.477361\n",
      "[460]\ttraining's binary_error: 0.233492\ttraining's binary_logloss: 0.477294\n",
      "[461]\ttraining's binary_error: 0.233413\ttraining's binary_logloss: 0.477234\n",
      "[462]\ttraining's binary_error: 0.233307\ttraining's binary_logloss: 0.477128\n",
      "[463]\ttraining's binary_error: 0.233144\ttraining's binary_logloss: 0.477055\n",
      "[464]\ttraining's binary_error: 0.2331\ttraining's binary_logloss: 0.476942\n",
      "[465]\ttraining's binary_error: 0.23311\ttraining's binary_logloss: 0.476896\n",
      "[466]\ttraining's binary_error: 0.233068\ttraining's binary_logloss: 0.476821\n",
      "[467]\ttraining's binary_error: 0.233028\ttraining's binary_logloss: 0.476729\n",
      "[468]\ttraining's binary_error: 0.232913\ttraining's binary_logloss: 0.476637\n",
      "[469]\ttraining's binary_error: 0.232876\ttraining's binary_logloss: 0.476559\n",
      "[470]\ttraining's binary_error: 0.232895\ttraining's binary_logloss: 0.476502\n",
      "[471]\ttraining's binary_error: 0.232842\ttraining's binary_logloss: 0.476433\n",
      "[472]\ttraining's binary_error: 0.232856\ttraining's binary_logloss: 0.476379\n",
      "[473]\ttraining's binary_error: 0.232791\ttraining's binary_logloss: 0.476278\n",
      "[474]\ttraining's binary_error: 0.232783\ttraining's binary_logloss: 0.476147\n",
      "[475]\ttraining's binary_error: 0.232702\ttraining's binary_logloss: 0.476046\n",
      "[476]\ttraining's binary_error: 0.232635\ttraining's binary_logloss: 0.475905\n",
      "[477]\ttraining's binary_error: 0.232508\ttraining's binary_logloss: 0.475768\n",
      "[478]\ttraining's binary_error: 0.232448\ttraining's binary_logloss: 0.475708\n",
      "[479]\ttraining's binary_error: 0.232414\ttraining's binary_logloss: 0.475598\n",
      "[480]\ttraining's binary_error: 0.232405\ttraining's binary_logloss: 0.475576\n",
      "[481]\ttraining's binary_error: 0.232211\ttraining's binary_logloss: 0.475354\n",
      "[482]\ttraining's binary_error: 0.232038\ttraining's binary_logloss: 0.475138\n",
      "[483]\ttraining's binary_error: 0.23189\ttraining's binary_logloss: 0.474997\n",
      "[484]\ttraining's binary_error: 0.231861\ttraining's binary_logloss: 0.474846\n",
      "[485]\ttraining's binary_error: 0.231861\ttraining's binary_logloss: 0.474782\n",
      "[486]\ttraining's binary_error: 0.231752\ttraining's binary_logloss: 0.474603\n",
      "[487]\ttraining's binary_error: 0.231548\ttraining's binary_logloss: 0.474327\n",
      "[488]\ttraining's binary_error: 0.23153\ttraining's binary_logloss: 0.47429\n",
      "[489]\ttraining's binary_error: 0.231456\ttraining's binary_logloss: 0.474157\n",
      "[490]\ttraining's binary_error: 0.231401\ttraining's binary_logloss: 0.474088\n",
      "[491]\ttraining's binary_error: 0.231354\ttraining's binary_logloss: 0.474022\n",
      "[492]\ttraining's binary_error: 0.231306\ttraining's binary_logloss: 0.473984\n",
      "[493]\ttraining's binary_error: 0.231239\ttraining's binary_logloss: 0.473814\n",
      "[494]\ttraining's binary_error: 0.231204\ttraining's binary_logloss: 0.473703\n",
      "[495]\ttraining's binary_error: 0.231127\ttraining's binary_logloss: 0.473594\n",
      "[496]\ttraining's binary_error: 0.231031\ttraining's binary_logloss: 0.473502\n",
      "[497]\ttraining's binary_error: 0.231019\ttraining's binary_logloss: 0.473325\n",
      "[498]\ttraining's binary_error: 0.230874\ttraining's binary_logloss: 0.473229\n",
      "[499]\ttraining's binary_error: 0.230736\ttraining's binary_logloss: 0.47307\n",
      "[500]\ttraining's binary_error: 0.230512\ttraining's binary_logloss: 0.472856\n",
      "[501]\ttraining's binary_error: 0.230476\ttraining's binary_logloss: 0.472816\n",
      "[502]\ttraining's binary_error: 0.230408\ttraining's binary_logloss: 0.472752\n",
      "[503]\ttraining's binary_error: 0.230324\ttraining's binary_logloss: 0.472649\n",
      "[504]\ttraining's binary_error: 0.230277\ttraining's binary_logloss: 0.472569\n",
      "[505]\ttraining's binary_error: 0.230281\ttraining's binary_logloss: 0.4725\n",
      "[506]\ttraining's binary_error: 0.23017\ttraining's binary_logloss: 0.472331\n",
      "[507]\ttraining's binary_error: 0.230085\ttraining's binary_logloss: 0.472226\n",
      "[508]\ttraining's binary_error: 0.23005\ttraining's binary_logloss: 0.472122\n",
      "[509]\ttraining's binary_error: 0.22992\ttraining's binary_logloss: 0.471963\n",
      "[510]\ttraining's binary_error: 0.229865\ttraining's binary_logloss: 0.47185\n",
      "[511]\ttraining's binary_error: 0.229704\ttraining's binary_logloss: 0.471777\n",
      "[512]\ttraining's binary_error: 0.22962\ttraining's binary_logloss: 0.471694\n",
      "[513]\ttraining's binary_error: 0.229564\ttraining's binary_logloss: 0.471635\n",
      "[514]\ttraining's binary_error: 0.229489\ttraining's binary_logloss: 0.471531\n",
      "[515]\ttraining's binary_error: 0.229473\ttraining's binary_logloss: 0.471442\n",
      "[516]\ttraining's binary_error: 0.229417\ttraining's binary_logloss: 0.471387\n",
      "[517]\ttraining's binary_error: 0.229248\ttraining's binary_logloss: 0.471229\n",
      "[518]\ttraining's binary_error: 0.229056\ttraining's binary_logloss: 0.471092\n",
      "[519]\ttraining's binary_error: 0.228926\ttraining's binary_logloss: 0.470947\n",
      "[520]\ttraining's binary_error: 0.228875\ttraining's binary_logloss: 0.470906\n",
      "[521]\ttraining's binary_error: 0.22882\ttraining's binary_logloss: 0.470821\n",
      "[522]\ttraining's binary_error: 0.2288\ttraining's binary_logloss: 0.470688\n",
      "[523]\ttraining's binary_error: 0.228756\ttraining's binary_logloss: 0.470572\n",
      "[524]\ttraining's binary_error: 0.228751\ttraining's binary_logloss: 0.470485\n",
      "[525]\ttraining's binary_error: 0.228755\ttraining's binary_logloss: 0.470428\n",
      "[526]\ttraining's binary_error: 0.228674\ttraining's binary_logloss: 0.470375\n",
      "[527]\ttraining's binary_error: 0.228635\ttraining's binary_logloss: 0.470301\n",
      "[528]\ttraining's binary_error: 0.228526\ttraining's binary_logloss: 0.470227\n",
      "[529]\ttraining's binary_error: 0.22846\ttraining's binary_logloss: 0.470172\n",
      "[530]\ttraining's binary_error: 0.228396\ttraining's binary_logloss: 0.470112\n",
      "[531]\ttraining's binary_error: 0.228245\ttraining's binary_logloss: 0.470044\n",
      "[532]\ttraining's binary_error: 0.228237\ttraining's binary_logloss: 0.469966\n",
      "[533]\ttraining's binary_error: 0.228198\ttraining's binary_logloss: 0.469921\n",
      "[534]\ttraining's binary_error: 0.228185\ttraining's binary_logloss: 0.469872\n",
      "[535]\ttraining's binary_error: 0.228114\ttraining's binary_logloss: 0.469788\n",
      "[536]\ttraining's binary_error: 0.228041\ttraining's binary_logloss: 0.469761\n",
      "[537]\ttraining's binary_error: 0.227989\ttraining's binary_logloss: 0.469719\n",
      "[538]\ttraining's binary_error: 0.227811\ttraining's binary_logloss: 0.469525\n",
      "[539]\ttraining's binary_error: 0.227726\ttraining's binary_logloss: 0.469385\n",
      "[540]\ttraining's binary_error: 0.22764\ttraining's binary_logloss: 0.469256\n",
      "[541]\ttraining's binary_error: 0.227564\ttraining's binary_logloss: 0.469138\n",
      "[542]\ttraining's binary_error: 0.227449\ttraining's binary_logloss: 0.46902\n",
      "[543]\ttraining's binary_error: 0.227373\ttraining's binary_logloss: 0.46896\n",
      "[544]\ttraining's binary_error: 0.227398\ttraining's binary_logloss: 0.468788\n",
      "[545]\ttraining's binary_error: 0.227193\ttraining's binary_logloss: 0.468564\n",
      "[546]\ttraining's binary_error: 0.227127\ttraining's binary_logloss: 0.468458\n",
      "[547]\ttraining's binary_error: 0.227089\ttraining's binary_logloss: 0.468417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[548]\ttraining's binary_error: 0.227069\ttraining's binary_logloss: 0.468328\n",
      "[549]\ttraining's binary_error: 0.226963\ttraining's binary_logloss: 0.468222\n",
      "[550]\ttraining's binary_error: 0.226876\ttraining's binary_logloss: 0.468043\n",
      "[551]\ttraining's binary_error: 0.226787\ttraining's binary_logloss: 0.467945\n",
      "[552]\ttraining's binary_error: 0.226749\ttraining's binary_logloss: 0.467897\n",
      "[553]\ttraining's binary_error: 0.226604\ttraining's binary_logloss: 0.46775\n",
      "[554]\ttraining's binary_error: 0.226541\ttraining's binary_logloss: 0.467578\n",
      "[555]\ttraining's binary_error: 0.226467\ttraining's binary_logloss: 0.467512\n",
      "[556]\ttraining's binary_error: 0.226397\ttraining's binary_logloss: 0.467423\n",
      "[557]\ttraining's binary_error: 0.226343\ttraining's binary_logloss: 0.467321\n",
      "[558]\ttraining's binary_error: 0.226331\ttraining's binary_logloss: 0.46726\n",
      "[559]\ttraining's binary_error: 0.2263\ttraining's binary_logloss: 0.467154\n",
      "[560]\ttraining's binary_error: 0.226202\ttraining's binary_logloss: 0.467069\n",
      "[561]\ttraining's binary_error: 0.226123\ttraining's binary_logloss: 0.46693\n",
      "[562]\ttraining's binary_error: 0.226073\ttraining's binary_logloss: 0.466746\n",
      "[563]\ttraining's binary_error: 0.225981\ttraining's binary_logloss: 0.466635\n",
      "[564]\ttraining's binary_error: 0.225853\ttraining's binary_logloss: 0.466536\n",
      "[565]\ttraining's binary_error: 0.225845\ttraining's binary_logloss: 0.46645\n",
      "[566]\ttraining's binary_error: 0.225776\ttraining's binary_logloss: 0.466401\n",
      "[567]\ttraining's binary_error: 0.22574\ttraining's binary_logloss: 0.466355\n",
      "[568]\ttraining's binary_error: 0.225578\ttraining's binary_logloss: 0.466241\n",
      "[569]\ttraining's binary_error: 0.225561\ttraining's binary_logloss: 0.466208\n",
      "[570]\ttraining's binary_error: 0.225528\ttraining's binary_logloss: 0.466116\n",
      "[571]\ttraining's binary_error: 0.225395\ttraining's binary_logloss: 0.46594\n",
      "[572]\ttraining's binary_error: 0.225183\ttraining's binary_logloss: 0.465791\n",
      "[573]\ttraining's binary_error: 0.225067\ttraining's binary_logloss: 0.465668\n",
      "[574]\ttraining's binary_error: 0.224966\ttraining's binary_logloss: 0.465558\n",
      "[575]\ttraining's binary_error: 0.224923\ttraining's binary_logloss: 0.465511\n",
      "[576]\ttraining's binary_error: 0.224874\ttraining's binary_logloss: 0.465415\n",
      "[577]\ttraining's binary_error: 0.224753\ttraining's binary_logloss: 0.465221\n",
      "[578]\ttraining's binary_error: 0.224706\ttraining's binary_logloss: 0.465151\n",
      "[579]\ttraining's binary_error: 0.224624\ttraining's binary_logloss: 0.465107\n",
      "[580]\ttraining's binary_error: 0.224641\ttraining's binary_logloss: 0.465018\n",
      "[581]\ttraining's binary_error: 0.22456\ttraining's binary_logloss: 0.464957\n",
      "[582]\ttraining's binary_error: 0.224475\ttraining's binary_logloss: 0.464814\n",
      "[583]\ttraining's binary_error: 0.224432\ttraining's binary_logloss: 0.464743\n",
      "[584]\ttraining's binary_error: 0.224401\ttraining's binary_logloss: 0.464718\n",
      "[585]\ttraining's binary_error: 0.224344\ttraining's binary_logloss: 0.464645\n",
      "[586]\ttraining's binary_error: 0.224357\ttraining's binary_logloss: 0.464551\n",
      "[587]\ttraining's binary_error: 0.224314\ttraining's binary_logloss: 0.464491\n",
      "[588]\ttraining's binary_error: 0.224306\ttraining's binary_logloss: 0.464445\n",
      "[589]\ttraining's binary_error: 0.224281\ttraining's binary_logloss: 0.464404\n",
      "[590]\ttraining's binary_error: 0.224268\ttraining's binary_logloss: 0.464307\n",
      "[591]\ttraining's binary_error: 0.224122\ttraining's binary_logloss: 0.464249\n",
      "[592]\ttraining's binary_error: 0.22414\ttraining's binary_logloss: 0.464221\n",
      "[593]\ttraining's binary_error: 0.224091\ttraining's binary_logloss: 0.464172\n",
      "[594]\ttraining's binary_error: 0.223802\ttraining's binary_logloss: 0.463874\n",
      "[595]\ttraining's binary_error: 0.223792\ttraining's binary_logloss: 0.463823\n",
      "[596]\ttraining's binary_error: 0.223758\ttraining's binary_logloss: 0.463761\n",
      "[597]\ttraining's binary_error: 0.223835\ttraining's binary_logloss: 0.463711\n",
      "[598]\ttraining's binary_error: 0.223799\ttraining's binary_logloss: 0.46366\n",
      "[599]\ttraining's binary_error: 0.223782\ttraining's binary_logloss: 0.463578\n",
      "[600]\ttraining's binary_error: 0.22382\ttraining's binary_logloss: 0.463508\n",
      "[601]\ttraining's binary_error: 0.223749\ttraining's binary_logloss: 0.463382\n",
      "[602]\ttraining's binary_error: 0.223709\ttraining's binary_logloss: 0.463275\n",
      "[603]\ttraining's binary_error: 0.223608\ttraining's binary_logloss: 0.46311\n",
      "[604]\ttraining's binary_error: 0.223525\ttraining's binary_logloss: 0.463071\n",
      "[605]\ttraining's binary_error: 0.223436\ttraining's binary_logloss: 0.462966\n",
      "[606]\ttraining's binary_error: 0.223391\ttraining's binary_logloss: 0.462937\n",
      "[607]\ttraining's binary_error: 0.223378\ttraining's binary_logloss: 0.462884\n",
      "[608]\ttraining's binary_error: 0.223243\ttraining's binary_logloss: 0.462769\n",
      "[609]\ttraining's binary_error: 0.223157\ttraining's binary_logloss: 0.462697\n",
      "[610]\ttraining's binary_error: 0.223108\ttraining's binary_logloss: 0.462584\n",
      "[611]\ttraining's binary_error: 0.223131\ttraining's binary_logloss: 0.462517\n",
      "[612]\ttraining's binary_error: 0.223094\ttraining's binary_logloss: 0.462428\n",
      "[613]\ttraining's binary_error: 0.222907\ttraining's binary_logloss: 0.462176\n",
      "[614]\ttraining's binary_error: 0.222839\ttraining's binary_logloss: 0.462128\n",
      "[615]\ttraining's binary_error: 0.222823\ttraining's binary_logloss: 0.462075\n",
      "[616]\ttraining's binary_error: 0.2227\ttraining's binary_logloss: 0.461917\n",
      "[617]\ttraining's binary_error: 0.222661\ttraining's binary_logloss: 0.461829\n",
      "[618]\ttraining's binary_error: 0.22258\ttraining's binary_logloss: 0.461703\n",
      "[619]\ttraining's binary_error: 0.222502\ttraining's binary_logloss: 0.461623\n",
      "[620]\ttraining's binary_error: 0.222512\ttraining's binary_logloss: 0.461593\n",
      "[621]\ttraining's binary_error: 0.222502\ttraining's binary_logloss: 0.461547\n",
      "[622]\ttraining's binary_error: 0.222433\ttraining's binary_logloss: 0.461462\n",
      "[623]\ttraining's binary_error: 0.222383\ttraining's binary_logloss: 0.461386\n",
      "[624]\ttraining's binary_error: 0.222324\ttraining's binary_logloss: 0.461346\n",
      "[625]\ttraining's binary_error: 0.222186\ttraining's binary_logloss: 0.461176\n",
      "[626]\ttraining's binary_error: 0.22214\ttraining's binary_logloss: 0.461098\n",
      "[627]\ttraining's binary_error: 0.222116\ttraining's binary_logloss: 0.460995\n",
      "[628]\ttraining's binary_error: 0.222086\ttraining's binary_logloss: 0.460917\n",
      "[629]\ttraining's binary_error: 0.221945\ttraining's binary_logloss: 0.460751\n",
      "[630]\ttraining's binary_error: 0.221921\ttraining's binary_logloss: 0.460706\n",
      "[631]\ttraining's binary_error: 0.221908\ttraining's binary_logloss: 0.460658\n",
      "[632]\ttraining's binary_error: 0.221752\ttraining's binary_logloss: 0.460473\n",
      "[633]\ttraining's binary_error: 0.221687\ttraining's binary_logloss: 0.460437\n",
      "[634]\ttraining's binary_error: 0.221627\ttraining's binary_logloss: 0.460342\n",
      "[635]\ttraining's binary_error: 0.221624\ttraining's binary_logloss: 0.46029\n",
      "[636]\ttraining's binary_error: 0.221509\ttraining's binary_logloss: 0.460147\n",
      "[637]\ttraining's binary_error: 0.221412\ttraining's binary_logloss: 0.460054\n",
      "[638]\ttraining's binary_error: 0.221305\ttraining's binary_logloss: 0.459953\n",
      "[639]\ttraining's binary_error: 0.221224\ttraining's binary_logloss: 0.459849\n",
      "[640]\ttraining's binary_error: 0.221081\ttraining's binary_logloss: 0.459692\n",
      "[641]\ttraining's binary_error: 0.221044\ttraining's binary_logloss: 0.459621\n",
      "[642]\ttraining's binary_error: 0.220945\ttraining's binary_logloss: 0.4595\n",
      "[643]\ttraining's binary_error: 0.220915\ttraining's binary_logloss: 0.459395\n",
      "[644]\ttraining's binary_error: 0.220879\ttraining's binary_logloss: 0.459308\n",
      "[645]\ttraining's binary_error: 0.220864\ttraining's binary_logloss: 0.459273\n",
      "[646]\ttraining's binary_error: 0.220747\ttraining's binary_logloss: 0.459098\n",
      "[647]\ttraining's binary_error: 0.220723\ttraining's binary_logloss: 0.459029\n",
      "[648]\ttraining's binary_error: 0.220649\ttraining's binary_logloss: 0.458952\n",
      "[649]\ttraining's binary_error: 0.220579\ttraining's binary_logloss: 0.458897\n",
      "[650]\ttraining's binary_error: 0.22048\ttraining's binary_logloss: 0.458845\n",
      "[651]\ttraining's binary_error: 0.220439\ttraining's binary_logloss: 0.458767\n",
      "[652]\ttraining's binary_error: 0.220313\ttraining's binary_logloss: 0.458652\n",
      "[653]\ttraining's binary_error: 0.220213\ttraining's binary_logloss: 0.458562\n",
      "[654]\ttraining's binary_error: 0.220174\ttraining's binary_logloss: 0.458491\n",
      "[655]\ttraining's binary_error: 0.220138\ttraining's binary_logloss: 0.458446\n",
      "[656]\ttraining's binary_error: 0.220094\ttraining's binary_logloss: 0.458402\n",
      "[657]\ttraining's binary_error: 0.219914\ttraining's binary_logloss: 0.458198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[658]\ttraining's binary_error: 0.219817\ttraining's binary_logloss: 0.458107\n",
      "[659]\ttraining's binary_error: 0.219717\ttraining's binary_logloss: 0.457982\n",
      "[660]\ttraining's binary_error: 0.219664\ttraining's binary_logloss: 0.457906\n",
      "[661]\ttraining's binary_error: 0.219631\ttraining's binary_logloss: 0.457869\n",
      "[662]\ttraining's binary_error: 0.219583\ttraining's binary_logloss: 0.457745\n",
      "[663]\ttraining's binary_error: 0.219542\ttraining's binary_logloss: 0.457709\n",
      "[664]\ttraining's binary_error: 0.219535\ttraining's binary_logloss: 0.457654\n",
      "[665]\ttraining's binary_error: 0.21935\ttraining's binary_logloss: 0.457528\n",
      "[666]\ttraining's binary_error: 0.219408\ttraining's binary_logloss: 0.45743\n",
      "[667]\ttraining's binary_error: 0.219367\ttraining's binary_logloss: 0.457379\n",
      "[668]\ttraining's binary_error: 0.219311\ttraining's binary_logloss: 0.457335\n",
      "[669]\ttraining's binary_error: 0.219299\ttraining's binary_logloss: 0.457256\n",
      "[670]\ttraining's binary_error: 0.21926\ttraining's binary_logloss: 0.457228\n",
      "[671]\ttraining's binary_error: 0.219237\ttraining's binary_logloss: 0.457162\n",
      "[672]\ttraining's binary_error: 0.219189\ttraining's binary_logloss: 0.457117\n",
      "[673]\ttraining's binary_error: 0.219175\ttraining's binary_logloss: 0.457098\n",
      "[674]\ttraining's binary_error: 0.219137\ttraining's binary_logloss: 0.457024\n",
      "[675]\ttraining's binary_error: 0.219113\ttraining's binary_logloss: 0.457005\n",
      "[676]\ttraining's binary_error: 0.219003\ttraining's binary_logloss: 0.456898\n",
      "[677]\ttraining's binary_error: 0.218953\ttraining's binary_logloss: 0.456857\n",
      "[678]\ttraining's binary_error: 0.218966\ttraining's binary_logloss: 0.456822\n",
      "[679]\ttraining's binary_error: 0.218879\ttraining's binary_logloss: 0.456705\n",
      "[680]\ttraining's binary_error: 0.218848\ttraining's binary_logloss: 0.456685\n",
      "[681]\ttraining's binary_error: 0.218797\ttraining's binary_logloss: 0.456594\n",
      "[682]\ttraining's binary_error: 0.218824\ttraining's binary_logloss: 0.456554\n",
      "[683]\ttraining's binary_error: 0.218804\ttraining's binary_logloss: 0.456543\n",
      "[684]\ttraining's binary_error: 0.218813\ttraining's binary_logloss: 0.456509\n",
      "[685]\ttraining's binary_error: 0.218802\ttraining's binary_logloss: 0.456481\n",
      "[686]\ttraining's binary_error: 0.218743\ttraining's binary_logloss: 0.456445\n",
      "[687]\ttraining's binary_error: 0.218678\ttraining's binary_logloss: 0.456388\n",
      "[688]\ttraining's binary_error: 0.21859\ttraining's binary_logloss: 0.456291\n",
      "[689]\ttraining's binary_error: 0.218548\ttraining's binary_logloss: 0.45616\n",
      "[690]\ttraining's binary_error: 0.218298\ttraining's binary_logloss: 0.455872\n",
      "[691]\ttraining's binary_error: 0.218161\ttraining's binary_logloss: 0.455755\n",
      "[692]\ttraining's binary_error: 0.218133\ttraining's binary_logloss: 0.455697\n",
      "[693]\ttraining's binary_error: 0.21808\ttraining's binary_logloss: 0.455626\n",
      "[694]\ttraining's binary_error: 0.217948\ttraining's binary_logloss: 0.45544\n",
      "[695]\ttraining's binary_error: 0.217914\ttraining's binary_logloss: 0.455333\n",
      "[696]\ttraining's binary_error: 0.217879\ttraining's binary_logloss: 0.455239\n",
      "[697]\ttraining's binary_error: 0.217879\ttraining's binary_logloss: 0.455201\n",
      "[698]\ttraining's binary_error: 0.217817\ttraining's binary_logloss: 0.455132\n",
      "[699]\ttraining's binary_error: 0.217716\ttraining's binary_logloss: 0.455038\n",
      "[700]\ttraining's binary_error: 0.217734\ttraining's binary_logloss: 0.455\n",
      "[701]\ttraining's binary_error: 0.217623\ttraining's binary_logloss: 0.454924\n",
      "[702]\ttraining's binary_error: 0.217528\ttraining's binary_logloss: 0.45486\n",
      "[703]\ttraining's binary_error: 0.21747\ttraining's binary_logloss: 0.454801\n",
      "[704]\ttraining's binary_error: 0.217447\ttraining's binary_logloss: 0.45472\n",
      "[705]\ttraining's binary_error: 0.217423\ttraining's binary_logloss: 0.454687\n",
      "[706]\ttraining's binary_error: 0.217373\ttraining's binary_logloss: 0.454613\n",
      "[707]\ttraining's binary_error: 0.217332\ttraining's binary_logloss: 0.454552\n",
      "[708]\ttraining's binary_error: 0.217352\ttraining's binary_logloss: 0.454536\n",
      "[709]\ttraining's binary_error: 0.21734\ttraining's binary_logloss: 0.454518\n",
      "[710]\ttraining's binary_error: 0.217283\ttraining's binary_logloss: 0.454451\n",
      "[711]\ttraining's binary_error: 0.217263\ttraining's binary_logloss: 0.454394\n",
      "[712]\ttraining's binary_error: 0.217179\ttraining's binary_logloss: 0.454331\n",
      "[713]\ttraining's binary_error: 0.217133\ttraining's binary_logloss: 0.454258\n",
      "[714]\ttraining's binary_error: 0.21712\ttraining's binary_logloss: 0.454215\n",
      "[715]\ttraining's binary_error: 0.217069\ttraining's binary_logloss: 0.454171\n",
      "[716]\ttraining's binary_error: 0.217018\ttraining's binary_logloss: 0.454111\n",
      "[717]\ttraining's binary_error: 0.216913\ttraining's binary_logloss: 0.453977\n",
      "[718]\ttraining's binary_error: 0.216901\ttraining's binary_logloss: 0.453872\n",
      "[719]\ttraining's binary_error: 0.216885\ttraining's binary_logloss: 0.453806\n",
      "[720]\ttraining's binary_error: 0.216851\ttraining's binary_logloss: 0.453734\n",
      "[721]\ttraining's binary_error: 0.216817\ttraining's binary_logloss: 0.453694\n",
      "[722]\ttraining's binary_error: 0.216708\ttraining's binary_logloss: 0.453607\n",
      "[723]\ttraining's binary_error: 0.216656\ttraining's binary_logloss: 0.453545\n",
      "[724]\ttraining's binary_error: 0.216568\ttraining's binary_logloss: 0.453432\n",
      "[725]\ttraining's binary_error: 0.21648\ttraining's binary_logloss: 0.453297\n",
      "[726]\ttraining's binary_error: 0.216465\ttraining's binary_logloss: 0.453253\n",
      "[727]\ttraining's binary_error: 0.216414\ttraining's binary_logloss: 0.453202\n",
      "[728]\ttraining's binary_error: 0.216437\ttraining's binary_logloss: 0.453174\n",
      "[729]\ttraining's binary_error: 0.2164\ttraining's binary_logloss: 0.453134\n",
      "[730]\ttraining's binary_error: 0.21636\ttraining's binary_logloss: 0.453093\n",
      "[731]\ttraining's binary_error: 0.216347\ttraining's binary_logloss: 0.453052\n",
      "[732]\ttraining's binary_error: 0.216294\ttraining's binary_logloss: 0.452955\n",
      "[733]\ttraining's binary_error: 0.216323\ttraining's binary_logloss: 0.452919\n",
      "[734]\ttraining's binary_error: 0.216242\ttraining's binary_logloss: 0.452882\n",
      "[735]\ttraining's binary_error: 0.216236\ttraining's binary_logloss: 0.452827\n",
      "[736]\ttraining's binary_error: 0.216214\ttraining's binary_logloss: 0.452791\n",
      "[737]\ttraining's binary_error: 0.216111\ttraining's binary_logloss: 0.452694\n",
      "[738]\ttraining's binary_error: 0.215995\ttraining's binary_logloss: 0.4526\n",
      "[739]\ttraining's binary_error: 0.215883\ttraining's binary_logloss: 0.452444\n",
      "[740]\ttraining's binary_error: 0.215824\ttraining's binary_logloss: 0.452352\n",
      "[741]\ttraining's binary_error: 0.215781\ttraining's binary_logloss: 0.4523\n",
      "[742]\ttraining's binary_error: 0.215633\ttraining's binary_logloss: 0.452119\n",
      "[743]\ttraining's binary_error: 0.215604\ttraining's binary_logloss: 0.452055\n",
      "[744]\ttraining's binary_error: 0.21552\ttraining's binary_logloss: 0.451967\n",
      "[745]\ttraining's binary_error: 0.215418\ttraining's binary_logloss: 0.451858\n",
      "[746]\ttraining's binary_error: 0.215416\ttraining's binary_logloss: 0.451836\n",
      "[747]\ttraining's binary_error: 0.215283\ttraining's binary_logloss: 0.451752\n",
      "[748]\ttraining's binary_error: 0.215244\ttraining's binary_logloss: 0.451708\n",
      "[749]\ttraining's binary_error: 0.215199\ttraining's binary_logloss: 0.451569\n",
      "[750]\ttraining's binary_error: 0.215148\ttraining's binary_logloss: 0.451508\n",
      "[751]\ttraining's binary_error: 0.215148\ttraining's binary_logloss: 0.451495\n",
      "[752]\ttraining's binary_error: 0.215118\ttraining's binary_logloss: 0.451462\n",
      "[753]\ttraining's binary_error: 0.214981\ttraining's binary_logloss: 0.45133\n",
      "[754]\ttraining's binary_error: 0.214957\ttraining's binary_logloss: 0.451295\n",
      "[755]\ttraining's binary_error: 0.214951\ttraining's binary_logloss: 0.451242\n",
      "[756]\ttraining's binary_error: 0.214943\ttraining's binary_logloss: 0.451202\n",
      "[757]\ttraining's binary_error: 0.214857\ttraining's binary_logloss: 0.451091\n",
      "[758]\ttraining's binary_error: 0.214844\ttraining's binary_logloss: 0.451069\n",
      "[759]\ttraining's binary_error: 0.214747\ttraining's binary_logloss: 0.450949\n",
      "[760]\ttraining's binary_error: 0.21459\ttraining's binary_logloss: 0.450769\n",
      "[761]\ttraining's binary_error: 0.214547\ttraining's binary_logloss: 0.450735\n",
      "[762]\ttraining's binary_error: 0.214497\ttraining's binary_logloss: 0.450643\n",
      "[763]\ttraining's binary_error: 0.214466\ttraining's binary_logloss: 0.450626\n",
      "[764]\ttraining's binary_error: 0.21439\ttraining's binary_logloss: 0.450505\n",
      "[765]\ttraining's binary_error: 0.214358\ttraining's binary_logloss: 0.450454\n",
      "[766]\ttraining's binary_error: 0.214356\ttraining's binary_logloss: 0.450422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[767]\ttraining's binary_error: 0.214388\ttraining's binary_logloss: 0.450365\n",
      "[768]\ttraining's binary_error: 0.214405\ttraining's binary_logloss: 0.450335\n",
      "[769]\ttraining's binary_error: 0.214379\ttraining's binary_logloss: 0.450271\n",
      "[770]\ttraining's binary_error: 0.214376\ttraining's binary_logloss: 0.450238\n",
      "[771]\ttraining's binary_error: 0.214358\ttraining's binary_logloss: 0.450183\n",
      "[772]\ttraining's binary_error: 0.214333\ttraining's binary_logloss: 0.450123\n",
      "[773]\ttraining's binary_error: 0.214331\ttraining's binary_logloss: 0.450096\n",
      "[774]\ttraining's binary_error: 0.214231\ttraining's binary_logloss: 0.450021\n",
      "[775]\ttraining's binary_error: 0.214228\ttraining's binary_logloss: 0.449925\n",
      "[776]\ttraining's binary_error: 0.214188\ttraining's binary_logloss: 0.449883\n",
      "[777]\ttraining's binary_error: 0.21414\ttraining's binary_logloss: 0.44973\n",
      "[778]\ttraining's binary_error: 0.214124\ttraining's binary_logloss: 0.449674\n",
      "[779]\ttraining's binary_error: 0.214055\ttraining's binary_logloss: 0.449597\n",
      "[780]\ttraining's binary_error: 0.214001\ttraining's binary_logloss: 0.449515\n",
      "[781]\ttraining's binary_error: 0.213982\ttraining's binary_logloss: 0.449411\n",
      "[782]\ttraining's binary_error: 0.213919\ttraining's binary_logloss: 0.449342\n",
      "[783]\ttraining's binary_error: 0.213819\ttraining's binary_logloss: 0.449251\n",
      "[784]\ttraining's binary_error: 0.213799\ttraining's binary_logloss: 0.449073\n",
      "[785]\ttraining's binary_error: 0.213715\ttraining's binary_logloss: 0.449021\n",
      "[786]\ttraining's binary_error: 0.213701\ttraining's binary_logloss: 0.448963\n",
      "[787]\ttraining's binary_error: 0.213668\ttraining's binary_logloss: 0.448939\n",
      "[788]\ttraining's binary_error: 0.213629\ttraining's binary_logloss: 0.448903\n",
      "[789]\ttraining's binary_error: 0.213603\ttraining's binary_logloss: 0.448838\n",
      "[790]\ttraining's binary_error: 0.213583\ttraining's binary_logloss: 0.448791\n",
      "[791]\ttraining's binary_error: 0.2135\ttraining's binary_logloss: 0.448715\n",
      "[792]\ttraining's binary_error: 0.213454\ttraining's binary_logloss: 0.448666\n",
      "[793]\ttraining's binary_error: 0.213411\ttraining's binary_logloss: 0.448566\n",
      "[794]\ttraining's binary_error: 0.213419\ttraining's binary_logloss: 0.448528\n",
      "[795]\ttraining's binary_error: 0.213426\ttraining's binary_logloss: 0.448464\n",
      "[796]\ttraining's binary_error: 0.213414\ttraining's binary_logloss: 0.448401\n",
      "[797]\ttraining's binary_error: 0.213333\ttraining's binary_logloss: 0.448358\n",
      "[798]\ttraining's binary_error: 0.213285\ttraining's binary_logloss: 0.448293\n",
      "[799]\ttraining's binary_error: 0.213254\ttraining's binary_logloss: 0.448237\n",
      "[800]\ttraining's binary_error: 0.213135\ttraining's binary_logloss: 0.44815\n",
      "[801]\ttraining's binary_error: 0.213052\ttraining's binary_logloss: 0.448076\n",
      "[802]\ttraining's binary_error: 0.213011\ttraining's binary_logloss: 0.448038\n",
      "[803]\ttraining's binary_error: 0.212976\ttraining's binary_logloss: 0.447997\n",
      "[804]\ttraining's binary_error: 0.212909\ttraining's binary_logloss: 0.447932\n",
      "[805]\ttraining's binary_error: 0.212854\ttraining's binary_logloss: 0.447868\n",
      "[806]\ttraining's binary_error: 0.212756\ttraining's binary_logloss: 0.447826\n",
      "[807]\ttraining's binary_error: 0.212734\ttraining's binary_logloss: 0.447804\n",
      "[808]\ttraining's binary_error: 0.21266\ttraining's binary_logloss: 0.447686\n",
      "[809]\ttraining's binary_error: 0.212705\ttraining's binary_logloss: 0.447665\n",
      "[810]\ttraining's binary_error: 0.212642\ttraining's binary_logloss: 0.447544\n",
      "[811]\ttraining's binary_error: 0.212588\ttraining's binary_logloss: 0.447514\n",
      "[812]\ttraining's binary_error: 0.212602\ttraining's binary_logloss: 0.44748\n",
      "[813]\ttraining's binary_error: 0.212581\ttraining's binary_logloss: 0.447409\n",
      "[814]\ttraining's binary_error: 0.212501\ttraining's binary_logloss: 0.447287\n",
      "[815]\ttraining's binary_error: 0.21247\ttraining's binary_logloss: 0.447207\n",
      "[816]\ttraining's binary_error: 0.212401\ttraining's binary_logloss: 0.447125\n",
      "[817]\ttraining's binary_error: 0.212398\ttraining's binary_logloss: 0.447088\n",
      "[818]\ttraining's binary_error: 0.212326\ttraining's binary_logloss: 0.447064\n",
      "[819]\ttraining's binary_error: 0.212277\ttraining's binary_logloss: 0.447034\n",
      "[820]\ttraining's binary_error: 0.212241\ttraining's binary_logloss: 0.447002\n",
      "[821]\ttraining's binary_error: 0.212198\ttraining's binary_logloss: 0.446902\n",
      "[822]\ttraining's binary_error: 0.212137\ttraining's binary_logloss: 0.446781\n",
      "[823]\ttraining's binary_error: 0.211999\ttraining's binary_logloss: 0.446673\n",
      "[824]\ttraining's binary_error: 0.211989\ttraining's binary_logloss: 0.446623\n",
      "[825]\ttraining's binary_error: 0.211879\ttraining's binary_logloss: 0.446492\n",
      "[826]\ttraining's binary_error: 0.21181\ttraining's binary_logloss: 0.446415\n",
      "[827]\ttraining's binary_error: 0.211788\ttraining's binary_logloss: 0.446338\n",
      "[828]\ttraining's binary_error: 0.211739\ttraining's binary_logloss: 0.446241\n",
      "[829]\ttraining's binary_error: 0.211728\ttraining's binary_logloss: 0.4462\n",
      "[830]\ttraining's binary_error: 0.211707\ttraining's binary_logloss: 0.446139\n",
      "[831]\ttraining's binary_error: 0.211675\ttraining's binary_logloss: 0.446046\n",
      "[832]\ttraining's binary_error: 0.211586\ttraining's binary_logloss: 0.446005\n",
      "[833]\ttraining's binary_error: 0.211592\ttraining's binary_logloss: 0.445973\n",
      "[834]\ttraining's binary_error: 0.211565\ttraining's binary_logloss: 0.445919\n",
      "[835]\ttraining's binary_error: 0.211422\ttraining's binary_logloss: 0.445761\n",
      "[836]\ttraining's binary_error: 0.211317\ttraining's binary_logloss: 0.445655\n",
      "[837]\ttraining's binary_error: 0.211337\ttraining's binary_logloss: 0.445619\n",
      "[838]\ttraining's binary_error: 0.211389\ttraining's binary_logloss: 0.445535\n",
      "[839]\ttraining's binary_error: 0.211346\ttraining's binary_logloss: 0.445495\n",
      "[840]\ttraining's binary_error: 0.211313\ttraining's binary_logloss: 0.445444\n",
      "[841]\ttraining's binary_error: 0.211259\ttraining's binary_logloss: 0.445424\n",
      "[842]\ttraining's binary_error: 0.211139\ttraining's binary_logloss: 0.445351\n",
      "[843]\ttraining's binary_error: 0.211072\ttraining's binary_logloss: 0.445263\n",
      "[844]\ttraining's binary_error: 0.211065\ttraining's binary_logloss: 0.445198\n",
      "[845]\ttraining's binary_error: 0.210963\ttraining's binary_logloss: 0.445021\n",
      "[846]\ttraining's binary_error: 0.210905\ttraining's binary_logloss: 0.444969\n",
      "[847]\ttraining's binary_error: 0.210937\ttraining's binary_logloss: 0.444875\n",
      "[848]\ttraining's binary_error: 0.210868\ttraining's binary_logloss: 0.444837\n",
      "[849]\ttraining's binary_error: 0.210851\ttraining's binary_logloss: 0.444784\n",
      "[850]\ttraining's binary_error: 0.210771\ttraining's binary_logloss: 0.444666\n",
      "[851]\ttraining's binary_error: 0.210703\ttraining's binary_logloss: 0.444529\n",
      "[852]\ttraining's binary_error: 0.210658\ttraining's binary_logloss: 0.444467\n",
      "[853]\ttraining's binary_error: 0.210667\ttraining's binary_logloss: 0.444438\n",
      "[854]\ttraining's binary_error: 0.210623\ttraining's binary_logloss: 0.444387\n",
      "[855]\ttraining's binary_error: 0.210495\ttraining's binary_logloss: 0.444301\n",
      "[856]\ttraining's binary_error: 0.21039\ttraining's binary_logloss: 0.444178\n",
      "[857]\ttraining's binary_error: 0.210429\ttraining's binary_logloss: 0.44413\n",
      "[858]\ttraining's binary_error: 0.210398\ttraining's binary_logloss: 0.444079\n",
      "[859]\ttraining's binary_error: 0.2104\ttraining's binary_logloss: 0.444021\n",
      "[860]\ttraining's binary_error: 0.210326\ttraining's binary_logloss: 0.443957\n",
      "[861]\ttraining's binary_error: 0.210332\ttraining's binary_logloss: 0.443884\n",
      "[862]\ttraining's binary_error: 0.210342\ttraining's binary_logloss: 0.443857\n",
      "[863]\ttraining's binary_error: 0.210309\ttraining's binary_logloss: 0.443809\n",
      "[864]\ttraining's binary_error: 0.210299\ttraining's binary_logloss: 0.443765\n",
      "[865]\ttraining's binary_error: 0.210294\ttraining's binary_logloss: 0.443739\n",
      "[866]\ttraining's binary_error: 0.210278\ttraining's binary_logloss: 0.443708\n",
      "[867]\ttraining's binary_error: 0.21023\ttraining's binary_logloss: 0.443673\n",
      "[868]\ttraining's binary_error: 0.210224\ttraining's binary_logloss: 0.443635\n",
      "[869]\ttraining's binary_error: 0.210101\ttraining's binary_logloss: 0.443546\n",
      "[870]\ttraining's binary_error: 0.210079\ttraining's binary_logloss: 0.443492\n",
      "[871]\ttraining's binary_error: 0.210068\ttraining's binary_logloss: 0.443466\n",
      "[872]\ttraining's binary_error: 0.21\ttraining's binary_logloss: 0.443375\n",
      "[873]\ttraining's binary_error: 0.209785\ttraining's binary_logloss: 0.443193\n",
      "[874]\ttraining's binary_error: 0.209746\ttraining's binary_logloss: 0.443095\n",
      "[875]\ttraining's binary_error: 0.209631\ttraining's binary_logloss: 0.443005\n",
      "[876]\ttraining's binary_error: 0.209517\ttraining's binary_logloss: 0.442872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[877]\ttraining's binary_error: 0.209484\ttraining's binary_logloss: 0.442829\n",
      "[878]\ttraining's binary_error: 0.209466\ttraining's binary_logloss: 0.442799\n",
      "[879]\ttraining's binary_error: 0.20941\ttraining's binary_logloss: 0.442749\n",
      "[880]\ttraining's binary_error: 0.209378\ttraining's binary_logloss: 0.442704\n",
      "[881]\ttraining's binary_error: 0.209395\ttraining's binary_logloss: 0.442669\n",
      "[882]\ttraining's binary_error: 0.209346\ttraining's binary_logloss: 0.442592\n",
      "[883]\ttraining's binary_error: 0.209261\ttraining's binary_logloss: 0.442481\n",
      "[884]\ttraining's binary_error: 0.209199\ttraining's binary_logloss: 0.442395\n",
      "[885]\ttraining's binary_error: 0.209143\ttraining's binary_logloss: 0.442358\n",
      "[886]\ttraining's binary_error: 0.209167\ttraining's binary_logloss: 0.442314\n",
      "[887]\ttraining's binary_error: 0.209145\ttraining's binary_logloss: 0.442277\n",
      "[888]\ttraining's binary_error: 0.209171\ttraining's binary_logloss: 0.442238\n",
      "[889]\ttraining's binary_error: 0.20916\ttraining's binary_logloss: 0.442207\n",
      "[890]\ttraining's binary_error: 0.209049\ttraining's binary_logloss: 0.442085\n",
      "[891]\ttraining's binary_error: 0.209034\ttraining's binary_logloss: 0.442053\n",
      "[892]\ttraining's binary_error: 0.208991\ttraining's binary_logloss: 0.442019\n",
      "[893]\ttraining's binary_error: 0.208883\ttraining's binary_logloss: 0.441851\n",
      "[894]\ttraining's binary_error: 0.20885\ttraining's binary_logloss: 0.441771\n",
      "[895]\ttraining's binary_error: 0.208823\ttraining's binary_logloss: 0.441732\n",
      "[896]\ttraining's binary_error: 0.208704\ttraining's binary_logloss: 0.44167\n",
      "[897]\ttraining's binary_error: 0.208684\ttraining's binary_logloss: 0.441632\n",
      "[898]\ttraining's binary_error: 0.208619\ttraining's binary_logloss: 0.441588\n",
      "[899]\ttraining's binary_error: 0.208675\ttraining's binary_logloss: 0.441553\n",
      "[900]\ttraining's binary_error: 0.208655\ttraining's binary_logloss: 0.441526\n",
      "[901]\ttraining's binary_error: 0.208665\ttraining's binary_logloss: 0.441501\n",
      "[902]\ttraining's binary_error: 0.208631\ttraining's binary_logloss: 0.441464\n",
      "[903]\ttraining's binary_error: 0.208568\ttraining's binary_logloss: 0.441348\n",
      "[904]\ttraining's binary_error: 0.208498\ttraining's binary_logloss: 0.441292\n",
      "[905]\ttraining's binary_error: 0.208461\ttraining's binary_logloss: 0.441247\n",
      "[906]\ttraining's binary_error: 0.208444\ttraining's binary_logloss: 0.441221\n",
      "[907]\ttraining's binary_error: 0.208309\ttraining's binary_logloss: 0.441043\n",
      "[908]\ttraining's binary_error: 0.208301\ttraining's binary_logloss: 0.441017\n",
      "[909]\ttraining's binary_error: 0.208259\ttraining's binary_logloss: 0.440971\n",
      "[910]\ttraining's binary_error: 0.208116\ttraining's binary_logloss: 0.440809\n",
      "[911]\ttraining's binary_error: 0.207999\ttraining's binary_logloss: 0.440746\n",
      "[912]\ttraining's binary_error: 0.207924\ttraining's binary_logloss: 0.440679\n",
      "[913]\ttraining's binary_error: 0.207883\ttraining's binary_logloss: 0.440644\n",
      "[914]\ttraining's binary_error: 0.207863\ttraining's binary_logloss: 0.4406\n",
      "[915]\ttraining's binary_error: 0.207772\ttraining's binary_logloss: 0.440544\n",
      "[916]\ttraining's binary_error: 0.207753\ttraining's binary_logloss: 0.440492\n",
      "[917]\ttraining's binary_error: 0.207736\ttraining's binary_logloss: 0.440468\n",
      "[918]\ttraining's binary_error: 0.207729\ttraining's binary_logloss: 0.440449\n",
      "[919]\ttraining's binary_error: 0.207713\ttraining's binary_logloss: 0.440396\n",
      "[920]\ttraining's binary_error: 0.207655\ttraining's binary_logloss: 0.440296\n",
      "[921]\ttraining's binary_error: 0.207647\ttraining's binary_logloss: 0.440278\n",
      "[922]\ttraining's binary_error: 0.20759\ttraining's binary_logloss: 0.440184\n",
      "[923]\ttraining's binary_error: 0.207544\ttraining's binary_logloss: 0.440163\n",
      "[924]\ttraining's binary_error: 0.207556\ttraining's binary_logloss: 0.440068\n",
      "[925]\ttraining's binary_error: 0.20751\ttraining's binary_logloss: 0.440034\n",
      "[926]\ttraining's binary_error: 0.207472\ttraining's binary_logloss: 0.439995\n",
      "[927]\ttraining's binary_error: 0.207414\ttraining's binary_logloss: 0.43994\n",
      "[928]\ttraining's binary_error: 0.20728\ttraining's binary_logloss: 0.439762\n",
      "[929]\ttraining's binary_error: 0.207224\ttraining's binary_logloss: 0.439715\n",
      "[930]\ttraining's binary_error: 0.207222\ttraining's binary_logloss: 0.439683\n",
      "[931]\ttraining's binary_error: 0.207167\ttraining's binary_logloss: 0.439633\n",
      "[932]\ttraining's binary_error: 0.207035\ttraining's binary_logloss: 0.439478\n",
      "[933]\ttraining's binary_error: 0.207011\ttraining's binary_logloss: 0.439385\n",
      "[934]\ttraining's binary_error: 0.206975\ttraining's binary_logloss: 0.439354\n",
      "[935]\ttraining's binary_error: 0.206972\ttraining's binary_logloss: 0.439287\n",
      "[936]\ttraining's binary_error: 0.206862\ttraining's binary_logloss: 0.439197\n",
      "[937]\ttraining's binary_error: 0.206859\ttraining's binary_logloss: 0.439169\n",
      "[938]\ttraining's binary_error: 0.206841\ttraining's binary_logloss: 0.439119\n",
      "[939]\ttraining's binary_error: 0.206826\ttraining's binary_logloss: 0.439087\n",
      "[940]\ttraining's binary_error: 0.206787\ttraining's binary_logloss: 0.43905\n",
      "[941]\ttraining's binary_error: 0.206727\ttraining's binary_logloss: 0.438958\n",
      "[942]\ttraining's binary_error: 0.206711\ttraining's binary_logloss: 0.438934\n",
      "[943]\ttraining's binary_error: 0.206666\ttraining's binary_logloss: 0.438867\n",
      "[944]\ttraining's binary_error: 0.206662\ttraining's binary_logloss: 0.438846\n",
      "[945]\ttraining's binary_error: 0.206577\ttraining's binary_logloss: 0.438737\n",
      "[946]\ttraining's binary_error: 0.206492\ttraining's binary_logloss: 0.438688\n",
      "[947]\ttraining's binary_error: 0.206567\ttraining's binary_logloss: 0.438624\n",
      "[948]\ttraining's binary_error: 0.206535\ttraining's binary_logloss: 0.438573\n",
      "[949]\ttraining's binary_error: 0.206447\ttraining's binary_logloss: 0.438479\n",
      "[950]\ttraining's binary_error: 0.206435\ttraining's binary_logloss: 0.438437\n",
      "[951]\ttraining's binary_error: 0.206297\ttraining's binary_logloss: 0.438328\n",
      "[952]\ttraining's binary_error: 0.206234\ttraining's binary_logloss: 0.438223\n",
      "[953]\ttraining's binary_error: 0.206165\ttraining's binary_logloss: 0.438187\n",
      "[954]\ttraining's binary_error: 0.206188\ttraining's binary_logloss: 0.438154\n",
      "[955]\ttraining's binary_error: 0.206089\ttraining's binary_logloss: 0.43799\n",
      "[956]\ttraining's binary_error: 0.206016\ttraining's binary_logloss: 0.437909\n",
      "[957]\ttraining's binary_error: 0.206001\ttraining's binary_logloss: 0.437887\n",
      "[958]\ttraining's binary_error: 0.20595\ttraining's binary_logloss: 0.437849\n",
      "[959]\ttraining's binary_error: 0.205936\ttraining's binary_logloss: 0.437817\n",
      "[960]\ttraining's binary_error: 0.205838\ttraining's binary_logloss: 0.437776\n",
      "[961]\ttraining's binary_error: 0.205813\ttraining's binary_logloss: 0.437695\n",
      "[962]\ttraining's binary_error: 0.205825\ttraining's binary_logloss: 0.437667\n",
      "[963]\ttraining's binary_error: 0.205773\ttraining's binary_logloss: 0.437619\n",
      "[964]\ttraining's binary_error: 0.205746\ttraining's binary_logloss: 0.437587\n",
      "[965]\ttraining's binary_error: 0.205752\ttraining's binary_logloss: 0.437551\n",
      "[966]\ttraining's binary_error: 0.205722\ttraining's binary_logloss: 0.437501\n",
      "[967]\ttraining's binary_error: 0.205694\ttraining's binary_logloss: 0.437452\n",
      "[968]\ttraining's binary_error: 0.205667\ttraining's binary_logloss: 0.437435\n",
      "[969]\ttraining's binary_error: 0.205651\ttraining's binary_logloss: 0.43741\n",
      "[970]\ttraining's binary_error: 0.205641\ttraining's binary_logloss: 0.437366\n",
      "[971]\ttraining's binary_error: 0.205611\ttraining's binary_logloss: 0.437339\n",
      "[972]\ttraining's binary_error: 0.205631\ttraining's binary_logloss: 0.437313\n",
      "[973]\ttraining's binary_error: 0.205618\ttraining's binary_logloss: 0.437291\n",
      "[974]\ttraining's binary_error: 0.205572\ttraining's binary_logloss: 0.437193\n",
      "[975]\ttraining's binary_error: 0.205524\ttraining's binary_logloss: 0.437131\n",
      "[976]\ttraining's binary_error: 0.20546\ttraining's binary_logloss: 0.437063\n",
      "[977]\ttraining's binary_error: 0.205465\ttraining's binary_logloss: 0.437038\n",
      "[978]\ttraining's binary_error: 0.205433\ttraining's binary_logloss: 0.436989\n",
      "[979]\ttraining's binary_error: 0.205424\ttraining's binary_logloss: 0.436894\n",
      "[980]\ttraining's binary_error: 0.205408\ttraining's binary_logloss: 0.436875\n",
      "[981]\ttraining's binary_error: 0.205385\ttraining's binary_logloss: 0.436808\n",
      "[982]\ttraining's binary_error: 0.205355\ttraining's binary_logloss: 0.436789\n",
      "[983]\ttraining's binary_error: 0.205261\ttraining's binary_logloss: 0.436609\n",
      "[984]\ttraining's binary_error: 0.205203\ttraining's binary_logloss: 0.436566\n",
      "[985]\ttraining's binary_error: 0.20519\ttraining's binary_logloss: 0.436481\n",
      "[986]\ttraining's binary_error: 0.205168\ttraining's binary_logloss: 0.436455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[987]\ttraining's binary_error: 0.205172\ttraining's binary_logloss: 0.436391\n",
      "[988]\ttraining's binary_error: 0.205141\ttraining's binary_logloss: 0.436371\n",
      "[989]\ttraining's binary_error: 0.205121\ttraining's binary_logloss: 0.436346\n",
      "[990]\ttraining's binary_error: 0.205085\ttraining's binary_logloss: 0.436297\n",
      "[991]\ttraining's binary_error: 0.205004\ttraining's binary_logloss: 0.436222\n",
      "[992]\ttraining's binary_error: 0.204994\ttraining's binary_logloss: 0.436177\n",
      "[993]\ttraining's binary_error: 0.204967\ttraining's binary_logloss: 0.436104\n",
      "[994]\ttraining's binary_error: 0.204939\ttraining's binary_logloss: 0.436081\n",
      "[995]\ttraining's binary_error: 0.204948\ttraining's binary_logloss: 0.43605\n",
      "[996]\ttraining's binary_error: 0.204903\ttraining's binary_logloss: 0.435991\n",
      "[997]\ttraining's binary_error: 0.204834\ttraining's binary_logloss: 0.435935\n",
      "[998]\ttraining's binary_error: 0.204671\ttraining's binary_logloss: 0.435792\n",
      "[999]\ttraining's binary_error: 0.204604\ttraining's binary_logloss: 0.435696\n",
      "[1000]\ttraining's binary_error: 0.204602\ttraining's binary_logloss: 0.435672\n",
      "[1001]\ttraining's binary_error: 0.204555\ttraining's binary_logloss: 0.435626\n",
      "[1002]\ttraining's binary_error: 0.204535\ttraining's binary_logloss: 0.435592\n",
      "[1003]\ttraining's binary_error: 0.204512\ttraining's binary_logloss: 0.435485\n",
      "[1004]\ttraining's binary_error: 0.20442\ttraining's binary_logloss: 0.435396\n",
      "[1005]\ttraining's binary_error: 0.204396\ttraining's binary_logloss: 0.435332\n",
      "[1006]\ttraining's binary_error: 0.204353\ttraining's binary_logloss: 0.435296\n",
      "[1007]\ttraining's binary_error: 0.204312\ttraining's binary_logloss: 0.435253\n",
      "[1008]\ttraining's binary_error: 0.204286\ttraining's binary_logloss: 0.435204\n",
      "[1009]\ttraining's binary_error: 0.20425\ttraining's binary_logloss: 0.435153\n",
      "[1010]\ttraining's binary_error: 0.204199\ttraining's binary_logloss: 0.435016\n",
      "[1011]\ttraining's binary_error: 0.204194\ttraining's binary_logloss: 0.434989\n",
      "[1012]\ttraining's binary_error: 0.204146\ttraining's binary_logloss: 0.434933\n",
      "[1013]\ttraining's binary_error: 0.204115\ttraining's binary_logloss: 0.434872\n",
      "[1014]\ttraining's binary_error: 0.204127\ttraining's binary_logloss: 0.434783\n",
      "[1015]\ttraining's binary_error: 0.204104\ttraining's binary_logloss: 0.434753\n",
      "[1016]\ttraining's binary_error: 0.204085\ttraining's binary_logloss: 0.434645\n",
      "[1017]\ttraining's binary_error: 0.203946\ttraining's binary_logloss: 0.434498\n",
      "[1018]\ttraining's binary_error: 0.203904\ttraining's binary_logloss: 0.434453\n",
      "[1019]\ttraining's binary_error: 0.20388\ttraining's binary_logloss: 0.434425\n",
      "[1020]\ttraining's binary_error: 0.203847\ttraining's binary_logloss: 0.434391\n",
      "[1021]\ttraining's binary_error: 0.203791\ttraining's binary_logloss: 0.434348\n",
      "[1022]\ttraining's binary_error: 0.203746\ttraining's binary_logloss: 0.434258\n",
      "[1023]\ttraining's binary_error: 0.203737\ttraining's binary_logloss: 0.434219\n",
      "[1024]\ttraining's binary_error: 0.203714\ttraining's binary_logloss: 0.434194\n",
      "[1025]\ttraining's binary_error: 0.203722\ttraining's binary_logloss: 0.434179\n",
      "[1026]\ttraining's binary_error: 0.203599\ttraining's binary_logloss: 0.434035\n",
      "[1027]\ttraining's binary_error: 0.203538\ttraining's binary_logloss: 0.433984\n",
      "[1028]\ttraining's binary_error: 0.203519\ttraining's binary_logloss: 0.433929\n",
      "[1029]\ttraining's binary_error: 0.203493\ttraining's binary_logloss: 0.433896\n",
      "[1030]\ttraining's binary_error: 0.203481\ttraining's binary_logloss: 0.433819\n",
      "[1031]\ttraining's binary_error: 0.203476\ttraining's binary_logloss: 0.433767\n",
      "[1032]\ttraining's binary_error: 0.203437\ttraining's binary_logloss: 0.433692\n",
      "[1033]\ttraining's binary_error: 0.20343\ttraining's binary_logloss: 0.433639\n",
      "[1034]\ttraining's binary_error: 0.203332\ttraining's binary_logloss: 0.433503\n",
      "[1035]\ttraining's binary_error: 0.203304\ttraining's binary_logloss: 0.433447\n",
      "[1036]\ttraining's binary_error: 0.203297\ttraining's binary_logloss: 0.433421\n",
      "[1037]\ttraining's binary_error: 0.203241\ttraining's binary_logloss: 0.433385\n",
      "[1038]\ttraining's binary_error: 0.203173\ttraining's binary_logloss: 0.433279\n",
      "[1039]\ttraining's binary_error: 0.203155\ttraining's binary_logloss: 0.433257\n",
      "[1040]\ttraining's binary_error: 0.203145\ttraining's binary_logloss: 0.433244\n",
      "[1041]\ttraining's binary_error: 0.203036\ttraining's binary_logloss: 0.433113\n",
      "[1042]\ttraining's binary_error: 0.203026\ttraining's binary_logloss: 0.433068\n",
      "[1043]\ttraining's binary_error: 0.202991\ttraining's binary_logloss: 0.432993\n",
      "[1044]\ttraining's binary_error: 0.202997\ttraining's binary_logloss: 0.432939\n",
      "[1045]\ttraining's binary_error: 0.202928\ttraining's binary_logloss: 0.432913\n",
      "[1046]\ttraining's binary_error: 0.202933\ttraining's binary_logloss: 0.432889\n",
      "[1047]\ttraining's binary_error: 0.202899\ttraining's binary_logloss: 0.432864\n",
      "[1048]\ttraining's binary_error: 0.202856\ttraining's binary_logloss: 0.432835\n",
      "[1049]\ttraining's binary_error: 0.202843\ttraining's binary_logloss: 0.432784\n",
      "[1050]\ttraining's binary_error: 0.202773\ttraining's binary_logloss: 0.43269\n",
      "[1051]\ttraining's binary_error: 0.202788\ttraining's binary_logloss: 0.432637\n",
      "[1052]\ttraining's binary_error: 0.20273\ttraining's binary_logloss: 0.432511\n",
      "[1053]\ttraining's binary_error: 0.202732\ttraining's binary_logloss: 0.432459\n",
      "[1054]\ttraining's binary_error: 0.202744\ttraining's binary_logloss: 0.432423\n",
      "[1055]\ttraining's binary_error: 0.202746\ttraining's binary_logloss: 0.432357\n",
      "[1056]\ttraining's binary_error: 0.202587\ttraining's binary_logloss: 0.432204\n",
      "[1057]\ttraining's binary_error: 0.202413\ttraining's binary_logloss: 0.432053\n",
      "[1058]\ttraining's binary_error: 0.202284\ttraining's binary_logloss: 0.431931\n",
      "[1059]\ttraining's binary_error: 0.20225\ttraining's binary_logloss: 0.431845\n",
      "[1060]\ttraining's binary_error: 0.202212\ttraining's binary_logloss: 0.431774\n",
      "[1061]\ttraining's binary_error: 0.202188\ttraining's binary_logloss: 0.431698\n",
      "[1062]\ttraining's binary_error: 0.202097\ttraining's binary_logloss: 0.431611\n",
      "[1063]\ttraining's binary_error: 0.202109\ttraining's binary_logloss: 0.431588\n",
      "[1064]\ttraining's binary_error: 0.202123\ttraining's binary_logloss: 0.431565\n",
      "[1065]\ttraining's binary_error: 0.201933\ttraining's binary_logloss: 0.431397\n",
      "[1066]\ttraining's binary_error: 0.201892\ttraining's binary_logloss: 0.431353\n",
      "[1067]\ttraining's binary_error: 0.201768\ttraining's binary_logloss: 0.431224\n",
      "[1068]\ttraining's binary_error: 0.201752\ttraining's binary_logloss: 0.431191\n",
      "[1069]\ttraining's binary_error: 0.201721\ttraining's binary_logloss: 0.431113\n",
      "[1070]\ttraining's binary_error: 0.201716\ttraining's binary_logloss: 0.431064\n",
      "[1071]\ttraining's binary_error: 0.201696\ttraining's binary_logloss: 0.431037\n",
      "[1072]\ttraining's binary_error: 0.201687\ttraining's binary_logloss: 0.431008\n",
      "[1073]\ttraining's binary_error: 0.20167\ttraining's binary_logloss: 0.43096\n",
      "[1074]\ttraining's binary_error: 0.201561\ttraining's binary_logloss: 0.430908\n",
      "[1075]\ttraining's binary_error: 0.201547\ttraining's binary_logloss: 0.430836\n",
      "[1076]\ttraining's binary_error: 0.201517\ttraining's binary_logloss: 0.430765\n",
      "[1077]\ttraining's binary_error: 0.201461\ttraining's binary_logloss: 0.430675\n",
      "[1078]\ttraining's binary_error: 0.201457\ttraining's binary_logloss: 0.430659\n",
      "[1079]\ttraining's binary_error: 0.201234\ttraining's binary_logloss: 0.430426\n",
      "[1080]\ttraining's binary_error: 0.201239\ttraining's binary_logloss: 0.430392\n",
      "[1081]\ttraining's binary_error: 0.201164\ttraining's binary_logloss: 0.430278\n",
      "[1082]\ttraining's binary_error: 0.201169\ttraining's binary_logloss: 0.430242\n",
      "[1083]\ttraining's binary_error: 0.201145\ttraining's binary_logloss: 0.430211\n",
      "[1084]\ttraining's binary_error: 0.201132\ttraining's binary_logloss: 0.430183\n",
      "[1085]\ttraining's binary_error: 0.201025\ttraining's binary_logloss: 0.430113\n",
      "[1086]\ttraining's binary_error: 0.201016\ttraining's binary_logloss: 0.430085\n",
      "[1087]\ttraining's binary_error: 0.200996\ttraining's binary_logloss: 0.430069\n",
      "[1088]\ttraining's binary_error: 0.200913\ttraining's binary_logloss: 0.429968\n",
      "[1089]\ttraining's binary_error: 0.200823\ttraining's binary_logloss: 0.429899\n",
      "[1090]\ttraining's binary_error: 0.200786\ttraining's binary_logloss: 0.42986\n",
      "[1091]\ttraining's binary_error: 0.200784\ttraining's binary_logloss: 0.429843\n",
      "[1092]\ttraining's binary_error: 0.200775\ttraining's binary_logloss: 0.429826\n",
      "[1093]\ttraining's binary_error: 0.200761\ttraining's binary_logloss: 0.429811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1094]\ttraining's binary_error: 0.200664\ttraining's binary_logloss: 0.429676\n",
      "[1095]\ttraining's binary_error: 0.20063\ttraining's binary_logloss: 0.429625\n",
      "[1096]\ttraining's binary_error: 0.200612\ttraining's binary_logloss: 0.429588\n",
      "[1097]\ttraining's binary_error: 0.200622\ttraining's binary_logloss: 0.429544\n",
      "[1098]\ttraining's binary_error: 0.200628\ttraining's binary_logloss: 0.42952\n",
      "[1099]\ttraining's binary_error: 0.200558\ttraining's binary_logloss: 0.42943\n",
      "[1100]\ttraining's binary_error: 0.200569\ttraining's binary_logloss: 0.429386\n",
      "[1101]\ttraining's binary_error: 0.200543\ttraining's binary_logloss: 0.42934\n",
      "[1102]\ttraining's binary_error: 0.200542\ttraining's binary_logloss: 0.429298\n",
      "[1103]\ttraining's binary_error: 0.200511\ttraining's binary_logloss: 0.429246\n",
      "[1104]\ttraining's binary_error: 0.200443\ttraining's binary_logloss: 0.42918\n",
      "[1105]\ttraining's binary_error: 0.200431\ttraining's binary_logloss: 0.429135\n",
      "[1106]\ttraining's binary_error: 0.200282\ttraining's binary_logloss: 0.429031\n",
      "[1107]\ttraining's binary_error: 0.200277\ttraining's binary_logloss: 0.428949\n",
      "[1108]\ttraining's binary_error: 0.200232\ttraining's binary_logloss: 0.428857\n",
      "[1109]\ttraining's binary_error: 0.200141\ttraining's binary_logloss: 0.428697\n",
      "[1110]\ttraining's binary_error: 0.200099\ttraining's binary_logloss: 0.428645\n",
      "[1111]\ttraining's binary_error: 0.200023\ttraining's binary_logloss: 0.42861\n",
      "[1112]\ttraining's binary_error: 0.200028\ttraining's binary_logloss: 0.428572\n",
      "[1113]\ttraining's binary_error: 0.199977\ttraining's binary_logloss: 0.428535\n",
      "[1114]\ttraining's binary_error: 0.199985\ttraining's binary_logloss: 0.428468\n",
      "[1115]\ttraining's binary_error: 0.199975\ttraining's binary_logloss: 0.428434\n",
      "[1116]\ttraining's binary_error: 0.199934\ttraining's binary_logloss: 0.428407\n",
      "[1117]\ttraining's binary_error: 0.199915\ttraining's binary_logloss: 0.428378\n",
      "[1118]\ttraining's binary_error: 0.199919\ttraining's binary_logloss: 0.42836\n",
      "[1119]\ttraining's binary_error: 0.199919\ttraining's binary_logloss: 0.428342\n",
      "[1120]\ttraining's binary_error: 0.199849\ttraining's binary_logloss: 0.428261\n",
      "[1121]\ttraining's binary_error: 0.199832\ttraining's binary_logloss: 0.428237\n",
      "[1122]\ttraining's binary_error: 0.199794\ttraining's binary_logloss: 0.428213\n",
      "[1123]\ttraining's binary_error: 0.199867\ttraining's binary_logloss: 0.428138\n",
      "[1124]\ttraining's binary_error: 0.199808\ttraining's binary_logloss: 0.428073\n",
      "[1125]\ttraining's binary_error: 0.19978\ttraining's binary_logloss: 0.42801\n",
      "[1126]\ttraining's binary_error: 0.199764\ttraining's binary_logloss: 0.427972\n",
      "[1127]\ttraining's binary_error: 0.199738\ttraining's binary_logloss: 0.427956\n",
      "[1128]\ttraining's binary_error: 0.199721\ttraining's binary_logloss: 0.427911\n",
      "[1129]\ttraining's binary_error: 0.199674\ttraining's binary_logloss: 0.427854\n",
      "[1130]\ttraining's binary_error: 0.199639\ttraining's binary_logloss: 0.427826\n",
      "[1131]\ttraining's binary_error: 0.199542\ttraining's binary_logloss: 0.427653\n",
      "[1132]\ttraining's binary_error: 0.199531\ttraining's binary_logloss: 0.427619\n",
      "[1133]\ttraining's binary_error: 0.199502\ttraining's binary_logloss: 0.427596\n",
      "[1134]\ttraining's binary_error: 0.199459\ttraining's binary_logloss: 0.427525\n",
      "[1135]\ttraining's binary_error: 0.199394\ttraining's binary_logloss: 0.427452\n",
      "[1136]\ttraining's binary_error: 0.199371\ttraining's binary_logloss: 0.427429\n",
      "[1137]\ttraining's binary_error: 0.199358\ttraining's binary_logloss: 0.427407\n",
      "[1138]\ttraining's binary_error: 0.199364\ttraining's binary_logloss: 0.427382\n",
      "[1139]\ttraining's binary_error: 0.19933\ttraining's binary_logloss: 0.427347\n",
      "[1140]\ttraining's binary_error: 0.1993\ttraining's binary_logloss: 0.427327\n",
      "[1141]\ttraining's binary_error: 0.199281\ttraining's binary_logloss: 0.427282\n",
      "[1142]\ttraining's binary_error: 0.199237\ttraining's binary_logloss: 0.427174\n",
      "[1143]\ttraining's binary_error: 0.199204\ttraining's binary_logloss: 0.427128\n",
      "[1144]\ttraining's binary_error: 0.199147\ttraining's binary_logloss: 0.427065\n",
      "[1145]\ttraining's binary_error: 0.199121\ttraining's binary_logloss: 0.426993\n",
      "[1146]\ttraining's binary_error: 0.199071\ttraining's binary_logloss: 0.42693\n",
      "[1147]\ttraining's binary_error: 0.198985\ttraining's binary_logloss: 0.426783\n",
      "[1148]\ttraining's binary_error: 0.198939\ttraining's binary_logloss: 0.426746\n",
      "[1149]\ttraining's binary_error: 0.198886\ttraining's binary_logloss: 0.426627\n",
      "[1150]\ttraining's binary_error: 0.198828\ttraining's binary_logloss: 0.426536\n",
      "[1151]\ttraining's binary_error: 0.198772\ttraining's binary_logloss: 0.426471\n",
      "[1152]\ttraining's binary_error: 0.198772\ttraining's binary_logloss: 0.426408\n",
      "[1153]\ttraining's binary_error: 0.198759\ttraining's binary_logloss: 0.426389\n",
      "[1154]\ttraining's binary_error: 0.198751\ttraining's binary_logloss: 0.42637\n",
      "[1155]\ttraining's binary_error: 0.198773\ttraining's binary_logloss: 0.426334\n",
      "[1156]\ttraining's binary_error: 0.198723\ttraining's binary_logloss: 0.426304\n",
      "[1157]\ttraining's binary_error: 0.198712\ttraining's binary_logloss: 0.426283\n",
      "[1158]\ttraining's binary_error: 0.198644\ttraining's binary_logloss: 0.426238\n",
      "[1159]\ttraining's binary_error: 0.198572\ttraining's binary_logloss: 0.426196\n",
      "[1160]\ttraining's binary_error: 0.198551\ttraining's binary_logloss: 0.426174\n",
      "[1161]\ttraining's binary_error: 0.198516\ttraining's binary_logloss: 0.426155\n",
      "[1162]\ttraining's binary_error: 0.198456\ttraining's binary_logloss: 0.426069\n",
      "[1163]\ttraining's binary_error: 0.198404\ttraining's binary_logloss: 0.42598\n",
      "[1164]\ttraining's binary_error: 0.198398\ttraining's binary_logloss: 0.425964\n",
      "[1165]\ttraining's binary_error: 0.198389\ttraining's binary_logloss: 0.425946\n",
      "[1166]\ttraining's binary_error: 0.198393\ttraining's binary_logloss: 0.425916\n",
      "[1167]\ttraining's binary_error: 0.198358\ttraining's binary_logloss: 0.425891\n",
      "[1168]\ttraining's binary_error: 0.198329\ttraining's binary_logloss: 0.42586\n",
      "[1169]\ttraining's binary_error: 0.198301\ttraining's binary_logloss: 0.425843\n",
      "[1170]\ttraining's binary_error: 0.198284\ttraining's binary_logloss: 0.425821\n",
      "[1171]\ttraining's binary_error: 0.198249\ttraining's binary_logloss: 0.425774\n",
      "[1172]\ttraining's binary_error: 0.198226\ttraining's binary_logloss: 0.425695\n",
      "[1173]\ttraining's binary_error: 0.198214\ttraining's binary_logloss: 0.425682\n",
      "[1174]\ttraining's binary_error: 0.198153\ttraining's binary_logloss: 0.425583\n",
      "[1175]\ttraining's binary_error: 0.19814\ttraining's binary_logloss: 0.425544\n",
      "[1176]\ttraining's binary_error: 0.198185\ttraining's binary_logloss: 0.425512\n",
      "[1177]\ttraining's binary_error: 0.198169\ttraining's binary_logloss: 0.425486\n",
      "[1178]\ttraining's binary_error: 0.198175\ttraining's binary_logloss: 0.425437\n",
      "[1179]\ttraining's binary_error: 0.198174\ttraining's binary_logloss: 0.425421\n",
      "[1180]\ttraining's binary_error: 0.198134\ttraining's binary_logloss: 0.425384\n",
      "[1181]\ttraining's binary_error: 0.198145\ttraining's binary_logloss: 0.425345\n",
      "[1182]\ttraining's binary_error: 0.19812\ttraining's binary_logloss: 0.425332\n",
      "[1183]\ttraining's binary_error: 0.1981\ttraining's binary_logloss: 0.425304\n",
      "[1184]\ttraining's binary_error: 0.19804\ttraining's binary_logloss: 0.42525\n",
      "[1185]\ttraining's binary_error: 0.197987\ttraining's binary_logloss: 0.425214\n",
      "[1186]\ttraining's binary_error: 0.197979\ttraining's binary_logloss: 0.425165\n",
      "[1187]\ttraining's binary_error: 0.197969\ttraining's binary_logloss: 0.425153\n",
      "[1188]\ttraining's binary_error: 0.197951\ttraining's binary_logloss: 0.425096\n",
      "[1189]\ttraining's binary_error: 0.197942\ttraining's binary_logloss: 0.425056\n",
      "[1190]\ttraining's binary_error: 0.197885\ttraining's binary_logloss: 0.425025\n",
      "[1191]\ttraining's binary_error: 0.197853\ttraining's binary_logloss: 0.424993\n",
      "[1192]\ttraining's binary_error: 0.197852\ttraining's binary_logloss: 0.424966\n",
      "[1193]\ttraining's binary_error: 0.197836\ttraining's binary_logloss: 0.424947\n",
      "[1194]\ttraining's binary_error: 0.197787\ttraining's binary_logloss: 0.424914\n",
      "[1195]\ttraining's binary_error: 0.197766\ttraining's binary_logloss: 0.42488\n",
      "[1196]\ttraining's binary_error: 0.197751\ttraining's binary_logloss: 0.424855\n",
      "[1197]\ttraining's binary_error: 0.197711\ttraining's binary_logloss: 0.42481\n",
      "[1198]\ttraining's binary_error: 0.197641\ttraining's binary_logloss: 0.424759\n",
      "[1199]\ttraining's binary_error: 0.197554\ttraining's binary_logloss: 0.424696\n",
      "[1200]\ttraining's binary_error: 0.197547\ttraining's binary_logloss: 0.424658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1201]\ttraining's binary_error: 0.197532\ttraining's binary_logloss: 0.424627\n",
      "[1202]\ttraining's binary_error: 0.197518\ttraining's binary_logloss: 0.424594\n",
      "[1203]\ttraining's binary_error: 0.197496\ttraining's binary_logloss: 0.42449\n",
      "[1204]\ttraining's binary_error: 0.197473\ttraining's binary_logloss: 0.424462\n",
      "[1205]\ttraining's binary_error: 0.197433\ttraining's binary_logloss: 0.424427\n",
      "[1206]\ttraining's binary_error: 0.197368\ttraining's binary_logloss: 0.424402\n",
      "[1207]\ttraining's binary_error: 0.197365\ttraining's binary_logloss: 0.424354\n",
      "[1208]\ttraining's binary_error: 0.197322\ttraining's binary_logloss: 0.424334\n",
      "[1209]\ttraining's binary_error: 0.19727\ttraining's binary_logloss: 0.424303\n",
      "[1210]\ttraining's binary_error: 0.197274\ttraining's binary_logloss: 0.424288\n",
      "[1211]\ttraining's binary_error: 0.197189\ttraining's binary_logloss: 0.424241\n",
      "[1212]\ttraining's binary_error: 0.197135\ttraining's binary_logloss: 0.424085\n",
      "[1213]\ttraining's binary_error: 0.197103\ttraining's binary_logloss: 0.423969\n",
      "[1214]\ttraining's binary_error: 0.197047\ttraining's binary_logloss: 0.423918\n",
      "[1215]\ttraining's binary_error: 0.196975\ttraining's binary_logloss: 0.423806\n",
      "[1216]\ttraining's binary_error: 0.196974\ttraining's binary_logloss: 0.423722\n",
      "[1217]\ttraining's binary_error: 0.196936\ttraining's binary_logloss: 0.423692\n",
      "[1218]\ttraining's binary_error: 0.196923\ttraining's binary_logloss: 0.423668\n",
      "[1219]\ttraining's binary_error: 0.196906\ttraining's binary_logloss: 0.423646\n",
      "[1220]\ttraining's binary_error: 0.196908\ttraining's binary_logloss: 0.423623\n",
      "[1221]\ttraining's binary_error: 0.196872\ttraining's binary_logloss: 0.4236\n",
      "[1222]\ttraining's binary_error: 0.196787\ttraining's binary_logloss: 0.423515\n",
      "[1223]\ttraining's binary_error: 0.196773\ttraining's binary_logloss: 0.423491\n",
      "[1224]\ttraining's binary_error: 0.196689\ttraining's binary_logloss: 0.423406\n",
      "[1225]\ttraining's binary_error: 0.196649\ttraining's binary_logloss: 0.423332\n",
      "[1226]\ttraining's binary_error: 0.196632\ttraining's binary_logloss: 0.423275\n",
      "[1227]\ttraining's binary_error: 0.196661\ttraining's binary_logloss: 0.423236\n",
      "[1228]\ttraining's binary_error: 0.196599\ttraining's binary_logloss: 0.423198\n",
      "[1229]\ttraining's binary_error: 0.196556\ttraining's binary_logloss: 0.423166\n",
      "[1230]\ttraining's binary_error: 0.196519\ttraining's binary_logloss: 0.423107\n",
      "[1231]\ttraining's binary_error: 0.196496\ttraining's binary_logloss: 0.42308\n",
      "[1232]\ttraining's binary_error: 0.1965\ttraining's binary_logloss: 0.423023\n",
      "[1233]\ttraining's binary_error: 0.196509\ttraining's binary_logloss: 0.423002\n",
      "[1234]\ttraining's binary_error: 0.196457\ttraining's binary_logloss: 0.422934\n",
      "[1235]\ttraining's binary_error: 0.196424\ttraining's binary_logloss: 0.42288\n",
      "[1236]\ttraining's binary_error: 0.196404\ttraining's binary_logloss: 0.422865\n",
      "[1237]\ttraining's binary_error: 0.196371\ttraining's binary_logloss: 0.42283\n",
      "[1238]\ttraining's binary_error: 0.196329\ttraining's binary_logloss: 0.422771\n",
      "[1239]\ttraining's binary_error: 0.196277\ttraining's binary_logloss: 0.422736\n",
      "[1240]\ttraining's binary_error: 0.196195\ttraining's binary_logloss: 0.422669\n",
      "[1241]\ttraining's binary_error: 0.196182\ttraining's binary_logloss: 0.422652\n",
      "[1242]\ttraining's binary_error: 0.196167\ttraining's binary_logloss: 0.422638\n",
      "[1243]\ttraining's binary_error: 0.196141\ttraining's binary_logloss: 0.422591\n",
      "[1244]\ttraining's binary_error: 0.19606\ttraining's binary_logloss: 0.422479\n",
      "[1245]\ttraining's binary_error: 0.196002\ttraining's binary_logloss: 0.422402\n",
      "[1246]\ttraining's binary_error: 0.195993\ttraining's binary_logloss: 0.422392\n",
      "[1247]\ttraining's binary_error: 0.195949\ttraining's binary_logloss: 0.422297\n",
      "[1248]\ttraining's binary_error: 0.196003\ttraining's binary_logloss: 0.422261\n",
      "[1249]\ttraining's binary_error: 0.196019\ttraining's binary_logloss: 0.422235\n",
      "[1250]\ttraining's binary_error: 0.196029\ttraining's binary_logloss: 0.422202\n",
      "[1251]\ttraining's binary_error: 0.195901\ttraining's binary_logloss: 0.422155\n",
      "[1252]\ttraining's binary_error: 0.195833\ttraining's binary_logloss: 0.42207\n",
      "[1253]\ttraining's binary_error: 0.195754\ttraining's binary_logloss: 0.421913\n",
      "[1254]\ttraining's binary_error: 0.195714\ttraining's binary_logloss: 0.421834\n",
      "[1255]\ttraining's binary_error: 0.195684\ttraining's binary_logloss: 0.421798\n",
      "[1256]\ttraining's binary_error: 0.195662\ttraining's binary_logloss: 0.421758\n",
      "[1257]\ttraining's binary_error: 0.195604\ttraining's binary_logloss: 0.421716\n",
      "[1258]\ttraining's binary_error: 0.195497\ttraining's binary_logloss: 0.421579\n",
      "[1259]\ttraining's binary_error: 0.195519\ttraining's binary_logloss: 0.421539\n",
      "[1260]\ttraining's binary_error: 0.195414\ttraining's binary_logloss: 0.421446\n",
      "[1261]\ttraining's binary_error: 0.195401\ttraining's binary_logloss: 0.421408\n",
      "[1262]\ttraining's binary_error: 0.195373\ttraining's binary_logloss: 0.421366\n",
      "[1263]\ttraining's binary_error: 0.195349\ttraining's binary_logloss: 0.421321\n",
      "[1264]\ttraining's binary_error: 0.195299\ttraining's binary_logloss: 0.421294\n",
      "[1265]\ttraining's binary_error: 0.195235\ttraining's binary_logloss: 0.421254\n",
      "[1266]\ttraining's binary_error: 0.195251\ttraining's binary_logloss: 0.421235\n",
      "[1267]\ttraining's binary_error: 0.195221\ttraining's binary_logloss: 0.421198\n",
      "[1268]\ttraining's binary_error: 0.195235\ttraining's binary_logloss: 0.42115\n",
      "[1269]\ttraining's binary_error: 0.195208\ttraining's binary_logloss: 0.421121\n",
      "[1270]\ttraining's binary_error: 0.195128\ttraining's binary_logloss: 0.421053\n",
      "[1271]\ttraining's binary_error: 0.195078\ttraining's binary_logloss: 0.420985\n",
      "[1272]\ttraining's binary_error: 0.195054\ttraining's binary_logloss: 0.420946\n",
      "[1273]\ttraining's binary_error: 0.19502\ttraining's binary_logloss: 0.420899\n",
      "[1274]\ttraining's binary_error: 0.195005\ttraining's binary_logloss: 0.42088\n",
      "[1275]\ttraining's binary_error: 0.194981\ttraining's binary_logloss: 0.420855\n",
      "[1276]\ttraining's binary_error: 0.194968\ttraining's binary_logloss: 0.420818\n",
      "[1277]\ttraining's binary_error: 0.194902\ttraining's binary_logloss: 0.420776\n",
      "[1278]\ttraining's binary_error: 0.194881\ttraining's binary_logloss: 0.420745\n",
      "[1279]\ttraining's binary_error: 0.194844\ttraining's binary_logloss: 0.420692\n",
      "[1280]\ttraining's binary_error: 0.19481\ttraining's binary_logloss: 0.420613\n",
      "[1281]\ttraining's binary_error: 0.194808\ttraining's binary_logloss: 0.420579\n",
      "[1282]\ttraining's binary_error: 0.19474\ttraining's binary_logloss: 0.4205\n",
      "[1283]\ttraining's binary_error: 0.194686\ttraining's binary_logloss: 0.420448\n",
      "[1284]\ttraining's binary_error: 0.194669\ttraining's binary_logloss: 0.420419\n",
      "[1285]\ttraining's binary_error: 0.194628\ttraining's binary_logloss: 0.420353\n",
      "[1286]\ttraining's binary_error: 0.194516\ttraining's binary_logloss: 0.420269\n",
      "[1287]\ttraining's binary_error: 0.19447\ttraining's binary_logloss: 0.420245\n",
      "[1288]\ttraining's binary_error: 0.194508\ttraining's binary_logloss: 0.420187\n",
      "[1289]\ttraining's binary_error: 0.194465\ttraining's binary_logloss: 0.420144\n",
      "[1290]\ttraining's binary_error: 0.194449\ttraining's binary_logloss: 0.420122\n",
      "[1291]\ttraining's binary_error: 0.194424\ttraining's binary_logloss: 0.420099\n",
      "[1292]\ttraining's binary_error: 0.194396\ttraining's binary_logloss: 0.420054\n",
      "[1293]\ttraining's binary_error: 0.194366\ttraining's binary_logloss: 0.420031\n",
      "[1294]\ttraining's binary_error: 0.194339\ttraining's binary_logloss: 0.419956\n",
      "[1295]\ttraining's binary_error: 0.194287\ttraining's binary_logloss: 0.419875\n",
      "[1296]\ttraining's binary_error: 0.194267\ttraining's binary_logloss: 0.41985\n",
      "[1297]\ttraining's binary_error: 0.194254\ttraining's binary_logloss: 0.419803\n",
      "[1298]\ttraining's binary_error: 0.194235\ttraining's binary_logloss: 0.419783\n",
      "[1299]\ttraining's binary_error: 0.194196\ttraining's binary_logloss: 0.419755\n",
      "[1300]\ttraining's binary_error: 0.194192\ttraining's binary_logloss: 0.419727\n",
      "[1301]\ttraining's binary_error: 0.194195\ttraining's binary_logloss: 0.419711\n",
      "[1302]\ttraining's binary_error: 0.194136\ttraining's binary_logloss: 0.41966\n",
      "[1303]\ttraining's binary_error: 0.194076\ttraining's binary_logloss: 0.419566\n",
      "[1304]\ttraining's binary_error: 0.194088\ttraining's binary_logloss: 0.419519\n",
      "[1305]\ttraining's binary_error: 0.194052\ttraining's binary_logloss: 0.419478\n",
      "[1306]\ttraining's binary_error: 0.194054\ttraining's binary_logloss: 0.419455\n",
      "[1307]\ttraining's binary_error: 0.194034\ttraining's binary_logloss: 0.419434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1308]\ttraining's binary_error: 0.194077\ttraining's binary_logloss: 0.419423\n",
      "[1309]\ttraining's binary_error: 0.193943\ttraining's binary_logloss: 0.419283\n",
      "[1310]\ttraining's binary_error: 0.19391\ttraining's binary_logloss: 0.419186\n",
      "[1311]\ttraining's binary_error: 0.193897\ttraining's binary_logloss: 0.41917\n",
      "[1312]\ttraining's binary_error: 0.193871\ttraining's binary_logloss: 0.41914\n",
      "[1313]\ttraining's binary_error: 0.193841\ttraining's binary_logloss: 0.419121\n",
      "[1314]\ttraining's binary_error: 0.193832\ttraining's binary_logloss: 0.419101\n",
      "[1315]\ttraining's binary_error: 0.193829\ttraining's binary_logloss: 0.419053\n",
      "[1316]\ttraining's binary_error: 0.193812\ttraining's binary_logloss: 0.419012\n",
      "[1317]\ttraining's binary_error: 0.193798\ttraining's binary_logloss: 0.418984\n",
      "[1318]\ttraining's binary_error: 0.193798\ttraining's binary_logloss: 0.418955\n",
      "[1319]\ttraining's binary_error: 0.193767\ttraining's binary_logloss: 0.41893\n",
      "[1320]\ttraining's binary_error: 0.193714\ttraining's binary_logloss: 0.418893\n",
      "[1321]\ttraining's binary_error: 0.19366\ttraining's binary_logloss: 0.418831\n",
      "[1322]\ttraining's binary_error: 0.193634\ttraining's binary_logloss: 0.418795\n",
      "[1323]\ttraining's binary_error: 0.193622\ttraining's binary_logloss: 0.418781\n",
      "[1324]\ttraining's binary_error: 0.193632\ttraining's binary_logloss: 0.418763\n",
      "[1325]\ttraining's binary_error: 0.193595\ttraining's binary_logloss: 0.418719\n",
      "[1326]\ttraining's binary_error: 0.193594\ttraining's binary_logloss: 0.418685\n",
      "[1327]\ttraining's binary_error: 0.193577\ttraining's binary_logloss: 0.418661\n",
      "[1328]\ttraining's binary_error: 0.193553\ttraining's binary_logloss: 0.418609\n",
      "[1329]\ttraining's binary_error: 0.193527\ttraining's binary_logloss: 0.418576\n",
      "[1330]\ttraining's binary_error: 0.193456\ttraining's binary_logloss: 0.41852\n",
      "[1331]\ttraining's binary_error: 0.193466\ttraining's binary_logloss: 0.418503\n",
      "[1332]\ttraining's binary_error: 0.193462\ttraining's binary_logloss: 0.418475\n",
      "[1333]\ttraining's binary_error: 0.193483\ttraining's binary_logloss: 0.418435\n",
      "[1334]\ttraining's binary_error: 0.19345\ttraining's binary_logloss: 0.418307\n",
      "[1335]\ttraining's binary_error: 0.193393\ttraining's binary_logloss: 0.418202\n",
      "[1336]\ttraining's binary_error: 0.193382\ttraining's binary_logloss: 0.418191\n",
      "[1337]\ttraining's binary_error: 0.193362\ttraining's binary_logloss: 0.418152\n",
      "[1338]\ttraining's binary_error: 0.193351\ttraining's binary_logloss: 0.418134\n",
      "[1339]\ttraining's binary_error: 0.193329\ttraining's binary_logloss: 0.418072\n",
      "[1340]\ttraining's binary_error: 0.193311\ttraining's binary_logloss: 0.418052\n",
      "[1341]\ttraining's binary_error: 0.193324\ttraining's binary_logloss: 0.418032\n",
      "[1342]\ttraining's binary_error: 0.193331\ttraining's binary_logloss: 0.418015\n",
      "[1343]\ttraining's binary_error: 0.193315\ttraining's binary_logloss: 0.417997\n",
      "[1344]\ttraining's binary_error: 0.193297\ttraining's binary_logloss: 0.417982\n",
      "[1345]\ttraining's binary_error: 0.193311\ttraining's binary_logloss: 0.417929\n",
      "[1346]\ttraining's binary_error: 0.19327\ttraining's binary_logloss: 0.417884\n",
      "[1347]\ttraining's binary_error: 0.193241\ttraining's binary_logloss: 0.41787\n",
      "[1348]\ttraining's binary_error: 0.193235\ttraining's binary_logloss: 0.417833\n",
      "[1349]\ttraining's binary_error: 0.193223\ttraining's binary_logloss: 0.417803\n",
      "[1350]\ttraining's binary_error: 0.193211\ttraining's binary_logloss: 0.417783\n",
      "[1351]\ttraining's binary_error: 0.193109\ttraining's binary_logloss: 0.417673\n",
      "[1352]\ttraining's binary_error: 0.193019\ttraining's binary_logloss: 0.417602\n",
      "[1353]\ttraining's binary_error: 0.192949\ttraining's binary_logloss: 0.417495\n",
      "[1354]\ttraining's binary_error: 0.192933\ttraining's binary_logloss: 0.41747\n",
      "[1355]\ttraining's binary_error: 0.192916\ttraining's binary_logloss: 0.417455\n",
      "[1356]\ttraining's binary_error: 0.192892\ttraining's binary_logloss: 0.41743\n",
      "[1357]\ttraining's binary_error: 0.19288\ttraining's binary_logloss: 0.417396\n",
      "[1358]\ttraining's binary_error: 0.192842\ttraining's binary_logloss: 0.41734\n",
      "[1359]\ttraining's binary_error: 0.192782\ttraining's binary_logloss: 0.417286\n",
      "[1360]\ttraining's binary_error: 0.19274\ttraining's binary_logloss: 0.417243\n",
      "[1361]\ttraining's binary_error: 0.192701\ttraining's binary_logloss: 0.417201\n",
      "[1362]\ttraining's binary_error: 0.192677\ttraining's binary_logloss: 0.417177\n",
      "[1363]\ttraining's binary_error: 0.192678\ttraining's binary_logloss: 0.417137\n",
      "[1364]\ttraining's binary_error: 0.192624\ttraining's binary_logloss: 0.417073\n",
      "[1365]\ttraining's binary_error: 0.192598\ttraining's binary_logloss: 0.417039\n",
      "[1366]\ttraining's binary_error: 0.192554\ttraining's binary_logloss: 0.416959\n",
      "[1367]\ttraining's binary_error: 0.192515\ttraining's binary_logloss: 0.416869\n",
      "[1368]\ttraining's binary_error: 0.192493\ttraining's binary_logloss: 0.416843\n",
      "[1369]\ttraining's binary_error: 0.192485\ttraining's binary_logloss: 0.416805\n",
      "[1370]\ttraining's binary_error: 0.192469\ttraining's binary_logloss: 0.416787\n",
      "[1371]\ttraining's binary_error: 0.192415\ttraining's binary_logloss: 0.416692\n",
      "[1372]\ttraining's binary_error: 0.192405\ttraining's binary_logloss: 0.416623\n",
      "[1373]\ttraining's binary_error: 0.192255\ttraining's binary_logloss: 0.416446\n",
      "[1374]\ttraining's binary_error: 0.192192\ttraining's binary_logloss: 0.416384\n",
      "[1375]\ttraining's binary_error: 0.192158\ttraining's binary_logloss: 0.416322\n",
      "[1376]\ttraining's binary_error: 0.192146\ttraining's binary_logloss: 0.416295\n",
      "[1377]\ttraining's binary_error: 0.192132\ttraining's binary_logloss: 0.416242\n",
      "[1378]\ttraining's binary_error: 0.192092\ttraining's binary_logloss: 0.416192\n",
      "[1379]\ttraining's binary_error: 0.192047\ttraining's binary_logloss: 0.416105\n",
      "[1380]\ttraining's binary_error: 0.192026\ttraining's binary_logloss: 0.416052\n",
      "[1381]\ttraining's binary_error: 0.191968\ttraining's binary_logloss: 0.415972\n",
      "[1382]\ttraining's binary_error: 0.191912\ttraining's binary_logloss: 0.415926\n",
      "[1383]\ttraining's binary_error: 0.191889\ttraining's binary_logloss: 0.415909\n",
      "[1384]\ttraining's binary_error: 0.191869\ttraining's binary_logloss: 0.415867\n",
      "[1385]\ttraining's binary_error: 0.191862\ttraining's binary_logloss: 0.415823\n",
      "[1386]\ttraining's binary_error: 0.191848\ttraining's binary_logloss: 0.4158\n",
      "[1387]\ttraining's binary_error: 0.191843\ttraining's binary_logloss: 0.415778\n",
      "[1388]\ttraining's binary_error: 0.191793\ttraining's binary_logloss: 0.415681\n",
      "[1389]\ttraining's binary_error: 0.191761\ttraining's binary_logloss: 0.415646\n",
      "[1390]\ttraining's binary_error: 0.191676\ttraining's binary_logloss: 0.415581\n",
      "[1391]\ttraining's binary_error: 0.191655\ttraining's binary_logloss: 0.415563\n",
      "[1392]\ttraining's binary_error: 0.191656\ttraining's binary_logloss: 0.415546\n",
      "[1393]\ttraining's binary_error: 0.191615\ttraining's binary_logloss: 0.41546\n",
      "[1394]\ttraining's binary_error: 0.191572\ttraining's binary_logloss: 0.415393\n",
      "[1395]\ttraining's binary_error: 0.191537\ttraining's binary_logloss: 0.415366\n",
      "[1396]\ttraining's binary_error: 0.191466\ttraining's binary_logloss: 0.415265\n",
      "[1397]\ttraining's binary_error: 0.191452\ttraining's binary_logloss: 0.415237\n",
      "[1398]\ttraining's binary_error: 0.19136\ttraining's binary_logloss: 0.415149\n",
      "[1399]\ttraining's binary_error: 0.19136\ttraining's binary_logloss: 0.415134\n",
      "[1400]\ttraining's binary_error: 0.191341\ttraining's binary_logloss: 0.415107\n",
      "[1401]\ttraining's binary_error: 0.191266\ttraining's binary_logloss: 0.415022\n",
      "[1402]\ttraining's binary_error: 0.191254\ttraining's binary_logloss: 0.415004\n",
      "[1403]\ttraining's binary_error: 0.191192\ttraining's binary_logloss: 0.414924\n",
      "[1404]\ttraining's binary_error: 0.191157\ttraining's binary_logloss: 0.414881\n",
      "[1405]\ttraining's binary_error: 0.191097\ttraining's binary_logloss: 0.414803\n",
      "[1406]\ttraining's binary_error: 0.191042\ttraining's binary_logloss: 0.414722\n",
      "[1407]\ttraining's binary_error: 0.190988\ttraining's binary_logloss: 0.414644\n",
      "[1408]\ttraining's binary_error: 0.190975\ttraining's binary_logloss: 0.414615\n",
      "[1409]\ttraining's binary_error: 0.190979\ttraining's binary_logloss: 0.414595\n",
      "[1410]\ttraining's binary_error: 0.190945\ttraining's binary_logloss: 0.414529\n",
      "[1411]\ttraining's binary_error: 0.190932\ttraining's binary_logloss: 0.414508\n",
      "[1412]\ttraining's binary_error: 0.190872\ttraining's binary_logloss: 0.414439\n",
      "[1413]\ttraining's binary_error: 0.19084\ttraining's binary_logloss: 0.414415\n",
      "[1414]\ttraining's binary_error: 0.190831\ttraining's binary_logloss: 0.414399\n",
      "[1415]\ttraining's binary_error: 0.190771\ttraining's binary_logloss: 0.414248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1416]\ttraining's binary_error: 0.190766\ttraining's binary_logloss: 0.41424\n",
      "[1417]\ttraining's binary_error: 0.190736\ttraining's binary_logloss: 0.4142\n",
      "[1418]\ttraining's binary_error: 0.190742\ttraining's binary_logloss: 0.414181\n",
      "[1419]\ttraining's binary_error: 0.190738\ttraining's binary_logloss: 0.414161\n",
      "[1420]\ttraining's binary_error: 0.190717\ttraining's binary_logloss: 0.4141\n",
      "[1421]\ttraining's binary_error: 0.190665\ttraining's binary_logloss: 0.413995\n",
      "[1422]\ttraining's binary_error: 0.190628\ttraining's binary_logloss: 0.413957\n",
      "[1423]\ttraining's binary_error: 0.190614\ttraining's binary_logloss: 0.413922\n",
      "[1424]\ttraining's binary_error: 0.190598\ttraining's binary_logloss: 0.41389\n",
      "[1425]\ttraining's binary_error: 0.190593\ttraining's binary_logloss: 0.413857\n",
      "[1426]\ttraining's binary_error: 0.190526\ttraining's binary_logloss: 0.413743\n",
      "[1427]\ttraining's binary_error: 0.190506\ttraining's binary_logloss: 0.413692\n",
      "[1428]\ttraining's binary_error: 0.190485\ttraining's binary_logloss: 0.41363\n",
      "[1429]\ttraining's binary_error: 0.190475\ttraining's binary_logloss: 0.413617\n",
      "[1430]\ttraining's binary_error: 0.190454\ttraining's binary_logloss: 0.413584\n",
      "[1431]\ttraining's binary_error: 0.190384\ttraining's binary_logloss: 0.413535\n",
      "[1432]\ttraining's binary_error: 0.190359\ttraining's binary_logloss: 0.413513\n",
      "[1433]\ttraining's binary_error: 0.190373\ttraining's binary_logloss: 0.413472\n",
      "[1434]\ttraining's binary_error: 0.190315\ttraining's binary_logloss: 0.413411\n",
      "[1435]\ttraining's binary_error: 0.190304\ttraining's binary_logloss: 0.413378\n",
      "[1436]\ttraining's binary_error: 0.190273\ttraining's binary_logloss: 0.413341\n",
      "[1437]\ttraining's binary_error: 0.19022\ttraining's binary_logloss: 0.413238\n",
      "[1438]\ttraining's binary_error: 0.190192\ttraining's binary_logloss: 0.413209\n",
      "[1439]\ttraining's binary_error: 0.190154\ttraining's binary_logloss: 0.413184\n",
      "[1440]\ttraining's binary_error: 0.190095\ttraining's binary_logloss: 0.413106\n",
      "[1441]\ttraining's binary_error: 0.190081\ttraining's binary_logloss: 0.413093\n",
      "[1442]\ttraining's binary_error: 0.190065\ttraining's binary_logloss: 0.413068\n",
      "[1443]\ttraining's binary_error: 0.190025\ttraining's binary_logloss: 0.413028\n",
      "[1444]\ttraining's binary_error: 0.19002\ttraining's binary_logloss: 0.412998\n",
      "[1445]\ttraining's binary_error: 0.190007\ttraining's binary_logloss: 0.412957\n",
      "[1446]\ttraining's binary_error: 0.189958\ttraining's binary_logloss: 0.412858\n",
      "[1447]\ttraining's binary_error: 0.189998\ttraining's binary_logloss: 0.4128\n",
      "[1448]\ttraining's binary_error: 0.189962\ttraining's binary_logloss: 0.412766\n",
      "[1449]\ttraining's binary_error: 0.189942\ttraining's binary_logloss: 0.412722\n",
      "[1450]\ttraining's binary_error: 0.189909\ttraining's binary_logloss: 0.412621\n",
      "[1451]\ttraining's binary_error: 0.1899\ttraining's binary_logloss: 0.412605\n",
      "[1452]\ttraining's binary_error: 0.1899\ttraining's binary_logloss: 0.412572\n",
      "[1453]\ttraining's binary_error: 0.189859\ttraining's binary_logloss: 0.412543\n",
      "[1454]\ttraining's binary_error: 0.189813\ttraining's binary_logloss: 0.412507\n",
      "[1455]\ttraining's binary_error: 0.189749\ttraining's binary_logloss: 0.412412\n",
      "[1456]\ttraining's binary_error: 0.189695\ttraining's binary_logloss: 0.412362\n",
      "[1457]\ttraining's binary_error: 0.189715\ttraining's binary_logloss: 0.412321\n",
      "[1458]\ttraining's binary_error: 0.18971\ttraining's binary_logloss: 0.412289\n",
      "[1459]\ttraining's binary_error: 0.189621\ttraining's binary_logloss: 0.412226\n",
      "[1460]\ttraining's binary_error: 0.189567\ttraining's binary_logloss: 0.412199\n",
      "[1461]\ttraining's binary_error: 0.189522\ttraining's binary_logloss: 0.412148\n",
      "[1462]\ttraining's binary_error: 0.189548\ttraining's binary_logloss: 0.412101\n",
      "[1463]\ttraining's binary_error: 0.189548\ttraining's binary_logloss: 0.412085\n",
      "[1464]\ttraining's binary_error: 0.189487\ttraining's binary_logloss: 0.412021\n",
      "[1465]\ttraining's binary_error: 0.189442\ttraining's binary_logloss: 0.411969\n",
      "[1466]\ttraining's binary_error: 0.189398\ttraining's binary_logloss: 0.411902\n",
      "[1467]\ttraining's binary_error: 0.189369\ttraining's binary_logloss: 0.411834\n",
      "[1468]\ttraining's binary_error: 0.189401\ttraining's binary_logloss: 0.411786\n",
      "[1469]\ttraining's binary_error: 0.189371\ttraining's binary_logloss: 0.411761\n",
      "[1470]\ttraining's binary_error: 0.189308\ttraining's binary_logloss: 0.411704\n",
      "[1471]\ttraining's binary_error: 0.189279\ttraining's binary_logloss: 0.411649\n",
      "[1472]\ttraining's binary_error: 0.189225\ttraining's binary_logloss: 0.411592\n",
      "[1473]\ttraining's binary_error: 0.189216\ttraining's binary_logloss: 0.411566\n",
      "[1474]\ttraining's binary_error: 0.189177\ttraining's binary_logloss: 0.411488\n",
      "[1475]\ttraining's binary_error: 0.189168\ttraining's binary_logloss: 0.411465\n",
      "[1476]\ttraining's binary_error: 0.189159\ttraining's binary_logloss: 0.411442\n",
      "[1477]\ttraining's binary_error: 0.18914\ttraining's binary_logloss: 0.41141\n",
      "[1478]\ttraining's binary_error: 0.189137\ttraining's binary_logloss: 0.411388\n",
      "[1479]\ttraining's binary_error: 0.189147\ttraining's binary_logloss: 0.411355\n",
      "[1480]\ttraining's binary_error: 0.189133\ttraining's binary_logloss: 0.411336\n",
      "[1481]\ttraining's binary_error: 0.189118\ttraining's binary_logloss: 0.411322\n",
      "[1482]\ttraining's binary_error: 0.189097\ttraining's binary_logloss: 0.411293\n",
      "[1483]\ttraining's binary_error: 0.189064\ttraining's binary_logloss: 0.411268\n",
      "[1484]\ttraining's binary_error: 0.189021\ttraining's binary_logloss: 0.411193\n",
      "[1485]\ttraining's binary_error: 0.189016\ttraining's binary_logloss: 0.411175\n",
      "[1486]\ttraining's binary_error: 0.18897\ttraining's binary_logloss: 0.411134\n",
      "[1487]\ttraining's binary_error: 0.188979\ttraining's binary_logloss: 0.411121\n",
      "[1488]\ttraining's binary_error: 0.188967\ttraining's binary_logloss: 0.4111\n",
      "[1489]\ttraining's binary_error: 0.188957\ttraining's binary_logloss: 0.411068\n",
      "[1490]\ttraining's binary_error: 0.188968\ttraining's binary_logloss: 0.411043\n",
      "[1491]\ttraining's binary_error: 0.188902\ttraining's binary_logloss: 0.410989\n",
      "[1492]\ttraining's binary_error: 0.188888\ttraining's binary_logloss: 0.410974\n",
      "[1493]\ttraining's binary_error: 0.188879\ttraining's binary_logloss: 0.41096\n",
      "[1494]\ttraining's binary_error: 0.188847\ttraining's binary_logloss: 0.410915\n",
      "[1495]\ttraining's binary_error: 0.188859\ttraining's binary_logloss: 0.410874\n",
      "[1496]\ttraining's binary_error: 0.188843\ttraining's binary_logloss: 0.410845\n",
      "[1497]\ttraining's binary_error: 0.188861\ttraining's binary_logloss: 0.410818\n",
      "[1498]\ttraining's binary_error: 0.188891\ttraining's binary_logloss: 0.410785\n",
      "[1499]\ttraining's binary_error: 0.188878\ttraining's binary_logloss: 0.410772\n",
      "[1500]\ttraining's binary_error: 0.188867\ttraining's binary_logloss: 0.410747\n",
      "[1501]\ttraining's binary_error: 0.188803\ttraining's binary_logloss: 0.41068\n",
      "[1502]\ttraining's binary_error: 0.188788\ttraining's binary_logloss: 0.410652\n",
      "[1503]\ttraining's binary_error: 0.188769\ttraining's binary_logloss: 0.410567\n",
      "[1504]\ttraining's binary_error: 0.188767\ttraining's binary_logloss: 0.410555\n",
      "[1505]\ttraining's binary_error: 0.188756\ttraining's binary_logloss: 0.410539\n",
      "[1506]\ttraining's binary_error: 0.188761\ttraining's binary_logloss: 0.410504\n",
      "[1507]\ttraining's binary_error: 0.18869\ttraining's binary_logloss: 0.410397\n",
      "[1508]\ttraining's binary_error: 0.188685\ttraining's binary_logloss: 0.410381\n",
      "[1509]\ttraining's binary_error: 0.188633\ttraining's binary_logloss: 0.410355\n",
      "[1510]\ttraining's binary_error: 0.188631\ttraining's binary_logloss: 0.410331\n",
      "[1511]\ttraining's binary_error: 0.188631\ttraining's binary_logloss: 0.410302\n",
      "[1512]\ttraining's binary_error: 0.188604\ttraining's binary_logloss: 0.41027\n",
      "[1513]\ttraining's binary_error: 0.188639\ttraining's binary_logloss: 0.410251\n",
      "[1514]\ttraining's binary_error: 0.188534\ttraining's binary_logloss: 0.410149\n",
      "[1515]\ttraining's binary_error: 0.188517\ttraining's binary_logloss: 0.410097\n",
      "[1516]\ttraining's binary_error: 0.188503\ttraining's binary_logloss: 0.410056\n",
      "[1517]\ttraining's binary_error: 0.188481\ttraining's binary_logloss: 0.410021\n",
      "[1518]\ttraining's binary_error: 0.188393\ttraining's binary_logloss: 0.409948\n",
      "[1519]\ttraining's binary_error: 0.188279\ttraining's binary_logloss: 0.409818\n",
      "[1520]\ttraining's binary_error: 0.188262\ttraining's binary_logloss: 0.409796\n",
      "[1521]\ttraining's binary_error: 0.18828\ttraining's binary_logloss: 0.409751\n",
      "[1522]\ttraining's binary_error: 0.188263\ttraining's binary_logloss: 0.409728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1523]\ttraining's binary_error: 0.188202\ttraining's binary_logloss: 0.409661\n",
      "[1524]\ttraining's binary_error: 0.188194\ttraining's binary_logloss: 0.409643\n",
      "[1525]\ttraining's binary_error: 0.188189\ttraining's binary_logloss: 0.409626\n",
      "[1526]\ttraining's binary_error: 0.18815\ttraining's binary_logloss: 0.409564\n",
      "[1527]\ttraining's binary_error: 0.188117\ttraining's binary_logloss: 0.409538\n",
      "[1528]\ttraining's binary_error: 0.188107\ttraining's binary_logloss: 0.409523\n",
      "[1529]\ttraining's binary_error: 0.188035\ttraining's binary_logloss: 0.409429\n",
      "[1530]\ttraining's binary_error: 0.188014\ttraining's binary_logloss: 0.40941\n",
      "[1531]\ttraining's binary_error: 0.188022\ttraining's binary_logloss: 0.409338\n",
      "[1532]\ttraining's binary_error: 0.188003\ttraining's binary_logloss: 0.40932\n",
      "[1533]\ttraining's binary_error: 0.187995\ttraining's binary_logloss: 0.409276\n",
      "[1534]\ttraining's binary_error: 0.187997\ttraining's binary_logloss: 0.409262\n",
      "[1535]\ttraining's binary_error: 0.188025\ttraining's binary_logloss: 0.40925\n",
      "[1536]\ttraining's binary_error: 0.188015\ttraining's binary_logloss: 0.409236\n",
      "[1537]\ttraining's binary_error: 0.188021\ttraining's binary_logloss: 0.409215\n",
      "[1538]\ttraining's binary_error: 0.187974\ttraining's binary_logloss: 0.40914\n",
      "[1539]\ttraining's binary_error: 0.187895\ttraining's binary_logloss: 0.409071\n",
      "[1540]\ttraining's binary_error: 0.18788\ttraining's binary_logloss: 0.40905\n",
      "[1541]\ttraining's binary_error: 0.18786\ttraining's binary_logloss: 0.409024\n",
      "[1542]\ttraining's binary_error: 0.187843\ttraining's binary_logloss: 0.408997\n",
      "[1543]\ttraining's binary_error: 0.187854\ttraining's binary_logloss: 0.408942\n",
      "[1544]\ttraining's binary_error: 0.187866\ttraining's binary_logloss: 0.408917\n",
      "[1545]\ttraining's binary_error: 0.187857\ttraining's binary_logloss: 0.408896\n",
      "[1546]\ttraining's binary_error: 0.187779\ttraining's binary_logloss: 0.408816\n",
      "[1547]\ttraining's binary_error: 0.187762\ttraining's binary_logloss: 0.408799\n",
      "[1548]\ttraining's binary_error: 0.187734\ttraining's binary_logloss: 0.408771\n",
      "[1549]\ttraining's binary_error: 0.187703\ttraining's binary_logloss: 0.408752\n",
      "[1550]\ttraining's binary_error: 0.187693\ttraining's binary_logloss: 0.40874\n",
      "[1551]\ttraining's binary_error: 0.187677\ttraining's binary_logloss: 0.408693\n",
      "[1552]\ttraining's binary_error: 0.187715\ttraining's binary_logloss: 0.40865\n",
      "[1553]\ttraining's binary_error: 0.187684\ttraining's binary_logloss: 0.408613\n",
      "[1554]\ttraining's binary_error: 0.187611\ttraining's binary_logloss: 0.408557\n",
      "[1555]\ttraining's binary_error: 0.18755\ttraining's binary_logloss: 0.408522\n",
      "[1556]\ttraining's binary_error: 0.187541\ttraining's binary_logloss: 0.408473\n",
      "[1557]\ttraining's binary_error: 0.187515\ttraining's binary_logloss: 0.40844\n",
      "[1558]\ttraining's binary_error: 0.187508\ttraining's binary_logloss: 0.408399\n",
      "[1559]\ttraining's binary_error: 0.187475\ttraining's binary_logloss: 0.40838\n",
      "[1560]\ttraining's binary_error: 0.187464\ttraining's binary_logloss: 0.408345\n",
      "[1561]\ttraining's binary_error: 0.187431\ttraining's binary_logloss: 0.408316\n",
      "[1562]\ttraining's binary_error: 0.187414\ttraining's binary_logloss: 0.408291\n",
      "[1563]\ttraining's binary_error: 0.187413\ttraining's binary_logloss: 0.40827\n",
      "[1564]\ttraining's binary_error: 0.187406\ttraining's binary_logloss: 0.408253\n",
      "[1565]\ttraining's binary_error: 0.187399\ttraining's binary_logloss: 0.408217\n",
      "[1566]\ttraining's binary_error: 0.187401\ttraining's binary_logloss: 0.408195\n",
      "[1567]\ttraining's binary_error: 0.187405\ttraining's binary_logloss: 0.408164\n",
      "[1568]\ttraining's binary_error: 0.187402\ttraining's binary_logloss: 0.408142\n",
      "[1569]\ttraining's binary_error: 0.1874\ttraining's binary_logloss: 0.408127\n",
      "[1570]\ttraining's binary_error: 0.187363\ttraining's binary_logloss: 0.408098\n",
      "[1571]\ttraining's binary_error: 0.187375\ttraining's binary_logloss: 0.408077\n",
      "[1572]\ttraining's binary_error: 0.187367\ttraining's binary_logloss: 0.408055\n",
      "[1573]\ttraining's binary_error: 0.187328\ttraining's binary_logloss: 0.408031\n",
      "[1574]\ttraining's binary_error: 0.187316\ttraining's binary_logloss: 0.408015\n",
      "[1575]\ttraining's binary_error: 0.187312\ttraining's binary_logloss: 0.407997\n",
      "[1576]\ttraining's binary_error: 0.187291\ttraining's binary_logloss: 0.407976\n",
      "[1577]\ttraining's binary_error: 0.187241\ttraining's binary_logloss: 0.407871\n",
      "[1578]\ttraining's binary_error: 0.187199\ttraining's binary_logloss: 0.407825\n",
      "[1579]\ttraining's binary_error: 0.187159\ttraining's binary_logloss: 0.407788\n",
      "[1580]\ttraining's binary_error: 0.187165\ttraining's binary_logloss: 0.40778\n",
      "[1581]\ttraining's binary_error: 0.187125\ttraining's binary_logloss: 0.407609\n",
      "[1582]\ttraining's binary_error: 0.187105\ttraining's binary_logloss: 0.407587\n",
      "[1583]\ttraining's binary_error: 0.187065\ttraining's binary_logloss: 0.40754\n",
      "[1584]\ttraining's binary_error: 0.187048\ttraining's binary_logloss: 0.40752\n",
      "[1585]\ttraining's binary_error: 0.187013\ttraining's binary_logloss: 0.40744\n",
      "[1586]\ttraining's binary_error: 0.186979\ttraining's binary_logloss: 0.407352\n",
      "[1587]\ttraining's binary_error: 0.18696\ttraining's binary_logloss: 0.407331\n",
      "[1588]\ttraining's binary_error: 0.186905\ttraining's binary_logloss: 0.407239\n",
      "[1589]\ttraining's binary_error: 0.186889\ttraining's binary_logloss: 0.407221\n",
      "[1590]\ttraining's binary_error: 0.186923\ttraining's binary_logloss: 0.407166\n",
      "[1591]\ttraining's binary_error: 0.186825\ttraining's binary_logloss: 0.407083\n",
      "[1592]\ttraining's binary_error: 0.186798\ttraining's binary_logloss: 0.407062\n",
      "[1593]\ttraining's binary_error: 0.186797\ttraining's binary_logloss: 0.407048\n",
      "[1594]\ttraining's binary_error: 0.186787\ttraining's binary_logloss: 0.407028\n",
      "[1595]\ttraining's binary_error: 0.186792\ttraining's binary_logloss: 0.406982\n",
      "[1596]\ttraining's binary_error: 0.186793\ttraining's binary_logloss: 0.406957\n",
      "[1597]\ttraining's binary_error: 0.186809\ttraining's binary_logloss: 0.406943\n",
      "[1598]\ttraining's binary_error: 0.186793\ttraining's binary_logloss: 0.406927\n",
      "[1599]\ttraining's binary_error: 0.18679\ttraining's binary_logloss: 0.406903\n",
      "[1600]\ttraining's binary_error: 0.186763\ttraining's binary_logloss: 0.406829\n",
      "[1601]\ttraining's binary_error: 0.186748\ttraining's binary_logloss: 0.4068\n",
      "[1602]\ttraining's binary_error: 0.186753\ttraining's binary_logloss: 0.406771\n",
      "[1603]\ttraining's binary_error: 0.186742\ttraining's binary_logloss: 0.406746\n",
      "[1604]\ttraining's binary_error: 0.186656\ttraining's binary_logloss: 0.406667\n",
      "[1605]\ttraining's binary_error: 0.186638\ttraining's binary_logloss: 0.406642\n",
      "[1606]\ttraining's binary_error: 0.186637\ttraining's binary_logloss: 0.406621\n",
      "[1607]\ttraining's binary_error: 0.186612\ttraining's binary_logloss: 0.4066\n",
      "[1608]\ttraining's binary_error: 0.186559\ttraining's binary_logloss: 0.406563\n",
      "[1609]\ttraining's binary_error: 0.186545\ttraining's binary_logloss: 0.406517\n",
      "[1610]\ttraining's binary_error: 0.186506\ttraining's binary_logloss: 0.406495\n",
      "[1611]\ttraining's binary_error: 0.186503\ttraining's binary_logloss: 0.406465\n",
      "[1612]\ttraining's binary_error: 0.186504\ttraining's binary_logloss: 0.406445\n",
      "[1613]\ttraining's binary_error: 0.186489\ttraining's binary_logloss: 0.406373\n",
      "[1614]\ttraining's binary_error: 0.186469\ttraining's binary_logloss: 0.406351\n",
      "[1615]\ttraining's binary_error: 0.186453\ttraining's binary_logloss: 0.406309\n",
      "[1616]\ttraining's binary_error: 0.186428\ttraining's binary_logloss: 0.406268\n",
      "[1617]\ttraining's binary_error: 0.18637\ttraining's binary_logloss: 0.406178\n",
      "[1618]\ttraining's binary_error: 0.186345\ttraining's binary_logloss: 0.406137\n",
      "[1619]\ttraining's binary_error: 0.18634\ttraining's binary_logloss: 0.406119\n",
      "[1620]\ttraining's binary_error: 0.186267\ttraining's binary_logloss: 0.406037\n",
      "[1621]\ttraining's binary_error: 0.186238\ttraining's binary_logloss: 0.405996\n",
      "[1622]\ttraining's binary_error: 0.186237\ttraining's binary_logloss: 0.405955\n",
      "[1623]\ttraining's binary_error: 0.186261\ttraining's binary_logloss: 0.405921\n",
      "[1624]\ttraining's binary_error: 0.186198\ttraining's binary_logloss: 0.405834\n",
      "[1625]\ttraining's binary_error: 0.186178\ttraining's binary_logloss: 0.405754\n",
      "[1626]\ttraining's binary_error: 0.186094\ttraining's binary_logloss: 0.405649\n",
      "[1627]\ttraining's binary_error: 0.186062\ttraining's binary_logloss: 0.4056\n",
      "[1628]\ttraining's binary_error: 0.186023\ttraining's binary_logloss: 0.405528\n",
      "[1629]\ttraining's binary_error: 0.186005\ttraining's binary_logloss: 0.405506\n",
      "[1630]\ttraining's binary_error: 0.185988\ttraining's binary_logloss: 0.405489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1631]\ttraining's binary_error: 0.185976\ttraining's binary_logloss: 0.405471\n",
      "[1632]\ttraining's binary_error: 0.185976\ttraining's binary_logloss: 0.405431\n",
      "[1633]\ttraining's binary_error: 0.185977\ttraining's binary_logloss: 0.405402\n",
      "[1634]\ttraining's binary_error: 0.185946\ttraining's binary_logloss: 0.405383\n",
      "[1635]\ttraining's binary_error: 0.185848\ttraining's binary_logloss: 0.40523\n",
      "[1636]\ttraining's binary_error: 0.1858\ttraining's binary_logloss: 0.405179\n",
      "[1637]\ttraining's binary_error: 0.185795\ttraining's binary_logloss: 0.405166\n",
      "[1638]\ttraining's binary_error: 0.185764\ttraining's binary_logloss: 0.405144\n",
      "[1639]\ttraining's binary_error: 0.185743\ttraining's binary_logloss: 0.405111\n",
      "[1640]\ttraining's binary_error: 0.18572\ttraining's binary_logloss: 0.405071\n",
      "[1641]\ttraining's binary_error: 0.185669\ttraining's binary_logloss: 0.404981\n",
      "[1642]\ttraining's binary_error: 0.185641\ttraining's binary_logloss: 0.404954\n",
      "[1643]\ttraining's binary_error: 0.185642\ttraining's binary_logloss: 0.404939\n",
      "[1644]\ttraining's binary_error: 0.185646\ttraining's binary_logloss: 0.404915\n",
      "[1645]\ttraining's binary_error: 0.185623\ttraining's binary_logloss: 0.404876\n",
      "[1646]\ttraining's binary_error: 0.185587\ttraining's binary_logloss: 0.40479\n",
      "[1647]\ttraining's binary_error: 0.185574\ttraining's binary_logloss: 0.40476\n",
      "[1648]\ttraining's binary_error: 0.185546\ttraining's binary_logloss: 0.404748\n",
      "[1649]\ttraining's binary_error: 0.185517\ttraining's binary_logloss: 0.404668\n",
      "[1650]\ttraining's binary_error: 0.1855\ttraining's binary_logloss: 0.404635\n",
      "[1651]\ttraining's binary_error: 0.185507\ttraining's binary_logloss: 0.404607\n",
      "[1652]\ttraining's binary_error: 0.185409\ttraining's binary_logloss: 0.404494\n",
      "[1653]\ttraining's binary_error: 0.185407\ttraining's binary_logloss: 0.404457\n",
      "[1654]\ttraining's binary_error: 0.185384\ttraining's binary_logloss: 0.404414\n",
      "[1655]\ttraining's binary_error: 0.185365\ttraining's binary_logloss: 0.404377\n",
      "[1656]\ttraining's binary_error: 0.18535\ttraining's binary_logloss: 0.404349\n",
      "[1657]\ttraining's binary_error: 0.185317\ttraining's binary_logloss: 0.404317\n",
      "[1658]\ttraining's binary_error: 0.185292\ttraining's binary_logloss: 0.404285\n",
      "[1659]\ttraining's binary_error: 0.185227\ttraining's binary_logloss: 0.404202\n",
      "[1660]\ttraining's binary_error: 0.1852\ttraining's binary_logloss: 0.404171\n",
      "[1661]\ttraining's binary_error: 0.185199\ttraining's binary_logloss: 0.404159\n",
      "[1662]\ttraining's binary_error: 0.185156\ttraining's binary_logloss: 0.404138\n",
      "[1663]\ttraining's binary_error: 0.185125\ttraining's binary_logloss: 0.404102\n",
      "[1664]\ttraining's binary_error: 0.185061\ttraining's binary_logloss: 0.404033\n",
      "[1665]\ttraining's binary_error: 0.185045\ttraining's binary_logloss: 0.404016\n",
      "[1666]\ttraining's binary_error: 0.185046\ttraining's binary_logloss: 0.404007\n",
      "[1667]\ttraining's binary_error: 0.185049\ttraining's binary_logloss: 0.403972\n",
      "[1668]\ttraining's binary_error: 0.185035\ttraining's binary_logloss: 0.403955\n",
      "[1669]\ttraining's binary_error: 0.185038\ttraining's binary_logloss: 0.40393\n",
      "[1670]\ttraining's binary_error: 0.185034\ttraining's binary_logloss: 0.40391\n",
      "[1671]\ttraining's binary_error: 0.185023\ttraining's binary_logloss: 0.403883\n",
      "[1672]\ttraining's binary_error: 0.184996\ttraining's binary_logloss: 0.403861\n",
      "[1673]\ttraining's binary_error: 0.184943\ttraining's binary_logloss: 0.403804\n",
      "[1674]\ttraining's binary_error: 0.184913\ttraining's binary_logloss: 0.403776\n",
      "[1675]\ttraining's binary_error: 0.18485\ttraining's binary_logloss: 0.40367\n",
      "[1676]\ttraining's binary_error: 0.184834\ttraining's binary_logloss: 0.403619\n",
      "[1677]\ttraining's binary_error: 0.184742\ttraining's binary_logloss: 0.403597\n",
      "[1678]\ttraining's binary_error: 0.184689\ttraining's binary_logloss: 0.403444\n",
      "[1679]\ttraining's binary_error: 0.184689\ttraining's binary_logloss: 0.40342\n",
      "[1680]\ttraining's binary_error: 0.184656\ttraining's binary_logloss: 0.403395\n",
      "[1681]\ttraining's binary_error: 0.18465\ttraining's binary_logloss: 0.403351\n",
      "[1682]\ttraining's binary_error: 0.184603\ttraining's binary_logloss: 0.403281\n",
      "[1683]\ttraining's binary_error: 0.184587\ttraining's binary_logloss: 0.40327\n",
      "[1684]\ttraining's binary_error: 0.184557\ttraining's binary_logloss: 0.403228\n",
      "[1685]\ttraining's binary_error: 0.184533\ttraining's binary_logloss: 0.403189\n",
      "[1686]\ttraining's binary_error: 0.184502\ttraining's binary_logloss: 0.403144\n",
      "[1687]\ttraining's binary_error: 0.184476\ttraining's binary_logloss: 0.403085\n",
      "[1688]\ttraining's binary_error: 0.184473\ttraining's binary_logloss: 0.403078\n",
      "[1689]\ttraining's binary_error: 0.184454\ttraining's binary_logloss: 0.403053\n",
      "[1690]\ttraining's binary_error: 0.184448\ttraining's binary_logloss: 0.403042\n",
      "[1691]\ttraining's binary_error: 0.184435\ttraining's binary_logloss: 0.403016\n",
      "[1692]\ttraining's binary_error: 0.184417\ttraining's binary_logloss: 0.40297\n",
      "[1693]\ttraining's binary_error: 0.184413\ttraining's binary_logloss: 0.402959\n",
      "[1694]\ttraining's binary_error: 0.184409\ttraining's binary_logloss: 0.402947\n",
      "[1695]\ttraining's binary_error: 0.184366\ttraining's binary_logloss: 0.402877\n",
      "[1696]\ttraining's binary_error: 0.18437\ttraining's binary_logloss: 0.402863\n",
      "[1697]\ttraining's binary_error: 0.184363\ttraining's binary_logloss: 0.402849\n",
      "[1698]\ttraining's binary_error: 0.184337\ttraining's binary_logloss: 0.402816\n",
      "[1699]\ttraining's binary_error: 0.184354\ttraining's binary_logloss: 0.402794\n",
      "[1700]\ttraining's binary_error: 0.184332\ttraining's binary_logloss: 0.402764\n",
      "[1701]\ttraining's binary_error: 0.184322\ttraining's binary_logloss: 0.402747\n",
      "[1702]\ttraining's binary_error: 0.184312\ttraining's binary_logloss: 0.402732\n",
      "[1703]\ttraining's binary_error: 0.184291\ttraining's binary_logloss: 0.402687\n",
      "[1704]\ttraining's binary_error: 0.184264\ttraining's binary_logloss: 0.402664\n",
      "[1705]\ttraining's binary_error: 0.184243\ttraining's binary_logloss: 0.402638\n",
      "[1706]\ttraining's binary_error: 0.184252\ttraining's binary_logloss: 0.40262\n",
      "[1707]\ttraining's binary_error: 0.184244\ttraining's binary_logloss: 0.4026\n",
      "[1708]\ttraining's binary_error: 0.184174\ttraining's binary_logloss: 0.402514\n",
      "[1709]\ttraining's binary_error: 0.184133\ttraining's binary_logloss: 0.402492\n",
      "[1710]\ttraining's binary_error: 0.184029\ttraining's binary_logloss: 0.402447\n",
      "[1711]\ttraining's binary_error: 0.183967\ttraining's binary_logloss: 0.402374\n",
      "[1712]\ttraining's binary_error: 0.183949\ttraining's binary_logloss: 0.402351\n",
      "[1713]\ttraining's binary_error: 0.18394\ttraining's binary_logloss: 0.402327\n",
      "[1714]\ttraining's binary_error: 0.183893\ttraining's binary_logloss: 0.402318\n",
      "[1715]\ttraining's binary_error: 0.183914\ttraining's binary_logloss: 0.402292\n",
      "[1716]\ttraining's binary_error: 0.183859\ttraining's binary_logloss: 0.402206\n",
      "[1717]\ttraining's binary_error: 0.183838\ttraining's binary_logloss: 0.402177\n",
      "[1718]\ttraining's binary_error: 0.183805\ttraining's binary_logloss: 0.402131\n",
      "[1719]\ttraining's binary_error: 0.183781\ttraining's binary_logloss: 0.402115\n",
      "[1720]\ttraining's binary_error: 0.183777\ttraining's binary_logloss: 0.4021\n",
      "[1721]\ttraining's binary_error: 0.183779\ttraining's binary_logloss: 0.402084\n",
      "[1722]\ttraining's binary_error: 0.183786\ttraining's binary_logloss: 0.402064\n",
      "[1723]\ttraining's binary_error: 0.183773\ttraining's binary_logloss: 0.402051\n",
      "[1724]\ttraining's binary_error: 0.183746\ttraining's binary_logloss: 0.402008\n",
      "[1725]\ttraining's binary_error: 0.183738\ttraining's binary_logloss: 0.401983\n",
      "[1726]\ttraining's binary_error: 0.183723\ttraining's binary_logloss: 0.401969\n",
      "[1727]\ttraining's binary_error: 0.183724\ttraining's binary_logloss: 0.401957\n",
      "[1728]\ttraining's binary_error: 0.183699\ttraining's binary_logloss: 0.401917\n",
      "[1729]\ttraining's binary_error: 0.183666\ttraining's binary_logloss: 0.401859\n",
      "[1730]\ttraining's binary_error: 0.18367\ttraining's binary_logloss: 0.401822\n",
      "[1731]\ttraining's binary_error: 0.183666\ttraining's binary_logloss: 0.40181\n",
      "[1732]\ttraining's binary_error: 0.183627\ttraining's binary_logloss: 0.401775\n",
      "[1733]\ttraining's binary_error: 0.183595\ttraining's binary_logloss: 0.401748\n",
      "[1734]\ttraining's binary_error: 0.183543\ttraining's binary_logloss: 0.401708\n",
      "[1735]\ttraining's binary_error: 0.183503\ttraining's binary_logloss: 0.40164\n",
      "[1736]\ttraining's binary_error: 0.183489\ttraining's binary_logloss: 0.401611\n",
      "[1737]\ttraining's binary_error: 0.18348\ttraining's binary_logloss: 0.401545\n",
      "[1738]\ttraining's binary_error: 0.183462\ttraining's binary_logloss: 0.401532\n",
      "[1739]\ttraining's binary_error: 0.183443\ttraining's binary_logloss: 0.401503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1740]\ttraining's binary_error: 0.183471\ttraining's binary_logloss: 0.401474\n",
      "[1741]\ttraining's binary_error: 0.183456\ttraining's binary_logloss: 0.401457\n",
      "[1742]\ttraining's binary_error: 0.183453\ttraining's binary_logloss: 0.401438\n",
      "[1743]\ttraining's binary_error: 0.183447\ttraining's binary_logloss: 0.401421\n",
      "[1744]\ttraining's binary_error: 0.18345\ttraining's binary_logloss: 0.401408\n",
      "[1745]\ttraining's binary_error: 0.18344\ttraining's binary_logloss: 0.401399\n",
      "[1746]\ttraining's binary_error: 0.183431\ttraining's binary_logloss: 0.401382\n",
      "[1747]\ttraining's binary_error: 0.183426\ttraining's binary_logloss: 0.401321\n",
      "[1748]\ttraining's binary_error: 0.183405\ttraining's binary_logloss: 0.401261\n",
      "[1749]\ttraining's binary_error: 0.183356\ttraining's binary_logloss: 0.401229\n",
      "[1750]\ttraining's binary_error: 0.183336\ttraining's binary_logloss: 0.401196\n",
      "[1751]\ttraining's binary_error: 0.183325\ttraining's binary_logloss: 0.40116\n",
      "[1752]\ttraining's binary_error: 0.18331\ttraining's binary_logloss: 0.401136\n",
      "[1753]\ttraining's binary_error: 0.183266\ttraining's binary_logloss: 0.401114\n",
      "[1754]\ttraining's binary_error: 0.183255\ttraining's binary_logloss: 0.401101\n",
      "[1755]\ttraining's binary_error: 0.183256\ttraining's binary_logloss: 0.401093\n",
      "[1756]\ttraining's binary_error: 0.183255\ttraining's binary_logloss: 0.401081\n",
      "[1757]\ttraining's binary_error: 0.183233\ttraining's binary_logloss: 0.401025\n",
      "[1758]\ttraining's binary_error: 0.183201\ttraining's binary_logloss: 0.400989\n",
      "[1759]\ttraining's binary_error: 0.183173\ttraining's binary_logloss: 0.400947\n",
      "[1760]\ttraining's binary_error: 0.1831\ttraining's binary_logloss: 0.400889\n",
      "[1761]\ttraining's binary_error: 0.183086\ttraining's binary_logloss: 0.400859\n",
      "[1762]\ttraining's binary_error: 0.183095\ttraining's binary_logloss: 0.400833\n",
      "[1763]\ttraining's binary_error: 0.183082\ttraining's binary_logloss: 0.400806\n",
      "[1764]\ttraining's binary_error: 0.183029\ttraining's binary_logloss: 0.400741\n",
      "[1765]\ttraining's binary_error: 0.182973\ttraining's binary_logloss: 0.400706\n",
      "[1766]\ttraining's binary_error: 0.182988\ttraining's binary_logloss: 0.400677\n",
      "[1767]\ttraining's binary_error: 0.182967\ttraining's binary_logloss: 0.400626\n",
      "[1768]\ttraining's binary_error: 0.182925\ttraining's binary_logloss: 0.400574\n",
      "[1769]\ttraining's binary_error: 0.182876\ttraining's binary_logloss: 0.400514\n",
      "[1770]\ttraining's binary_error: 0.182842\ttraining's binary_logloss: 0.400466\n",
      "[1771]\ttraining's binary_error: 0.182792\ttraining's binary_logloss: 0.4004\n",
      "[1772]\ttraining's binary_error: 0.182765\ttraining's binary_logloss: 0.40038\n",
      "[1773]\ttraining's binary_error: 0.182731\ttraining's binary_logloss: 0.400325\n",
      "[1774]\ttraining's binary_error: 0.182759\ttraining's binary_logloss: 0.400303\n",
      "[1775]\ttraining's binary_error: 0.182761\ttraining's binary_logloss: 0.400287\n",
      "[1776]\ttraining's binary_error: 0.182754\ttraining's binary_logloss: 0.400267\n",
      "[1777]\ttraining's binary_error: 0.182691\ttraining's binary_logloss: 0.400174\n",
      "[1778]\ttraining's binary_error: 0.182678\ttraining's binary_logloss: 0.40007\n",
      "[1779]\ttraining's binary_error: 0.182602\ttraining's binary_logloss: 0.399981\n",
      "[1780]\ttraining's binary_error: 0.18257\ttraining's binary_logloss: 0.399933\n",
      "[1781]\ttraining's binary_error: 0.182531\ttraining's binary_logloss: 0.399915\n",
      "[1782]\ttraining's binary_error: 0.182526\ttraining's binary_logloss: 0.399896\n",
      "[1783]\ttraining's binary_error: 0.182523\ttraining's binary_logloss: 0.399865\n",
      "[1784]\ttraining's binary_error: 0.182448\ttraining's binary_logloss: 0.39977\n",
      "[1785]\ttraining's binary_error: 0.182427\ttraining's binary_logloss: 0.399733\n",
      "[1786]\ttraining's binary_error: 0.182394\ttraining's binary_logloss: 0.399713\n",
      "[1787]\ttraining's binary_error: 0.182379\ttraining's binary_logloss: 0.399699\n",
      "[1788]\ttraining's binary_error: 0.182373\ttraining's binary_logloss: 0.399659\n",
      "[1789]\ttraining's binary_error: 0.182383\ttraining's binary_logloss: 0.399614\n",
      "[1790]\ttraining's binary_error: 0.182289\ttraining's binary_logloss: 0.399525\n",
      "[1791]\ttraining's binary_error: 0.182302\ttraining's binary_logloss: 0.399506\n",
      "[1792]\ttraining's binary_error: 0.182258\ttraining's binary_logloss: 0.39949\n",
      "[1793]\ttraining's binary_error: 0.182251\ttraining's binary_logloss: 0.399455\n",
      "[1794]\ttraining's binary_error: 0.182256\ttraining's binary_logloss: 0.399419\n",
      "[1795]\ttraining's binary_error: 0.182255\ttraining's binary_logloss: 0.399389\n",
      "[1796]\ttraining's binary_error: 0.182271\ttraining's binary_logloss: 0.399367\n",
      "[1797]\ttraining's binary_error: 0.182257\ttraining's binary_logloss: 0.399329\n",
      "[1798]\ttraining's binary_error: 0.182236\ttraining's binary_logloss: 0.399287\n",
      "[1799]\ttraining's binary_error: 0.182231\ttraining's binary_logloss: 0.399257\n",
      "[1800]\ttraining's binary_error: 0.18215\ttraining's binary_logloss: 0.399205\n",
      "[1801]\ttraining's binary_error: 0.182127\ttraining's binary_logloss: 0.399185\n",
      "[1802]\ttraining's binary_error: 0.182112\ttraining's binary_logloss: 0.399166\n",
      "[1803]\ttraining's binary_error: 0.182077\ttraining's binary_logloss: 0.399118\n",
      "[1804]\ttraining's binary_error: 0.182081\ttraining's binary_logloss: 0.399099\n",
      "[1805]\ttraining's binary_error: 0.182081\ttraining's binary_logloss: 0.399064\n",
      "[1806]\ttraining's binary_error: 0.182076\ttraining's binary_logloss: 0.399044\n",
      "[1807]\ttraining's binary_error: 0.182064\ttraining's binary_logloss: 0.399004\n",
      "[1808]\ttraining's binary_error: 0.182067\ttraining's binary_logloss: 0.398985\n",
      "[1809]\ttraining's binary_error: 0.182026\ttraining's binary_logloss: 0.398938\n",
      "[1810]\ttraining's binary_error: 0.182002\ttraining's binary_logloss: 0.398907\n",
      "[1811]\ttraining's binary_error: 0.181978\ttraining's binary_logloss: 0.398865\n",
      "[1812]\ttraining's binary_error: 0.181968\ttraining's binary_logloss: 0.398822\n",
      "[1813]\ttraining's binary_error: 0.181943\ttraining's binary_logloss: 0.398809\n",
      "[1814]\ttraining's binary_error: 0.181919\ttraining's binary_logloss: 0.398794\n",
      "[1815]\ttraining's binary_error: 0.181921\ttraining's binary_logloss: 0.398785\n",
      "[1816]\ttraining's binary_error: 0.181895\ttraining's binary_logloss: 0.398681\n",
      "[1817]\ttraining's binary_error: 0.181861\ttraining's binary_logloss: 0.398647\n",
      "[1818]\ttraining's binary_error: 0.181851\ttraining's binary_logloss: 0.398616\n",
      "[1819]\ttraining's binary_error: 0.181833\ttraining's binary_logloss: 0.398586\n",
      "[1820]\ttraining's binary_error: 0.18177\ttraining's binary_logloss: 0.39854\n",
      "[1821]\ttraining's binary_error: 0.181763\ttraining's binary_logloss: 0.398511\n",
      "[1822]\ttraining's binary_error: 0.181722\ttraining's binary_logloss: 0.398456\n",
      "[1823]\ttraining's binary_error: 0.181668\ttraining's binary_logloss: 0.39839\n",
      "[1824]\ttraining's binary_error: 0.181681\ttraining's binary_logloss: 0.398353\n",
      "[1825]\ttraining's binary_error: 0.181619\ttraining's binary_logloss: 0.39828\n",
      "[1826]\ttraining's binary_error: 0.181585\ttraining's binary_logloss: 0.398244\n",
      "[1827]\ttraining's binary_error: 0.181525\ttraining's binary_logloss: 0.398168\n",
      "[1828]\ttraining's binary_error: 0.181558\ttraining's binary_logloss: 0.398144\n",
      "[1829]\ttraining's binary_error: 0.18153\ttraining's binary_logloss: 0.398105\n",
      "[1830]\ttraining's binary_error: 0.181494\ttraining's binary_logloss: 0.398036\n",
      "[1831]\ttraining's binary_error: 0.18146\ttraining's binary_logloss: 0.398012\n",
      "[1832]\ttraining's binary_error: 0.181445\ttraining's binary_logloss: 0.397981\n",
      "[1833]\ttraining's binary_error: 0.181457\ttraining's binary_logloss: 0.397957\n",
      "[1834]\ttraining's binary_error: 0.181454\ttraining's binary_logloss: 0.397942\n",
      "[1835]\ttraining's binary_error: 0.181444\ttraining's binary_logloss: 0.397875\n",
      "[1836]\ttraining's binary_error: 0.181428\ttraining's binary_logloss: 0.397859\n",
      "[1837]\ttraining's binary_error: 0.181416\ttraining's binary_logloss: 0.397826\n",
      "[1838]\ttraining's binary_error: 0.181404\ttraining's binary_logloss: 0.397808\n",
      "[1839]\ttraining's binary_error: 0.181382\ttraining's binary_logloss: 0.397793\n",
      "[1840]\ttraining's binary_error: 0.181392\ttraining's binary_logloss: 0.397747\n",
      "[1841]\ttraining's binary_error: 0.181372\ttraining's binary_logloss: 0.397702\n",
      "[1842]\ttraining's binary_error: 0.181363\ttraining's binary_logloss: 0.397691\n",
      "[1843]\ttraining's binary_error: 0.181338\ttraining's binary_logloss: 0.397606\n",
      "[1844]\ttraining's binary_error: 0.181313\ttraining's binary_logloss: 0.397535\n",
      "[1845]\ttraining's binary_error: 0.181296\ttraining's binary_logloss: 0.397495\n",
      "[1846]\ttraining's binary_error: 0.181241\ttraining's binary_logloss: 0.397468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1847]\ttraining's binary_error: 0.181228\ttraining's binary_logloss: 0.397455\n",
      "[1848]\ttraining's binary_error: 0.181237\ttraining's binary_logloss: 0.397432\n",
      "[1849]\ttraining's binary_error: 0.181202\ttraining's binary_logloss: 0.397369\n",
      "[1850]\ttraining's binary_error: 0.181153\ttraining's binary_logloss: 0.397304\n",
      "[1851]\ttraining's binary_error: 0.181127\ttraining's binary_logloss: 0.397285\n",
      "[1852]\ttraining's binary_error: 0.181115\ttraining's binary_logloss: 0.397266\n",
      "[1853]\ttraining's binary_error: 0.18111\ttraining's binary_logloss: 0.397252\n",
      "[1854]\ttraining's binary_error: 0.181088\ttraining's binary_logloss: 0.397238\n",
      "[1855]\ttraining's binary_error: 0.181008\ttraining's binary_logloss: 0.39717\n",
      "[1856]\ttraining's binary_error: 0.180996\ttraining's binary_logloss: 0.397151\n",
      "[1857]\ttraining's binary_error: 0.180955\ttraining's binary_logloss: 0.397103\n",
      "[1858]\ttraining's binary_error: 0.180909\ttraining's binary_logloss: 0.396979\n",
      "[1859]\ttraining's binary_error: 0.180918\ttraining's binary_logloss: 0.396949\n",
      "[1860]\ttraining's binary_error: 0.180879\ttraining's binary_logloss: 0.396931\n",
      "[1861]\ttraining's binary_error: 0.180824\ttraining's binary_logloss: 0.396806\n",
      "[1862]\ttraining's binary_error: 0.18085\ttraining's binary_logloss: 0.396773\n",
      "[1863]\ttraining's binary_error: 0.180807\ttraining's binary_logloss: 0.396744\n",
      "[1864]\ttraining's binary_error: 0.180787\ttraining's binary_logloss: 0.396729\n",
      "[1865]\ttraining's binary_error: 0.180746\ttraining's binary_logloss: 0.396675\n",
      "[1866]\ttraining's binary_error: 0.180758\ttraining's binary_logloss: 0.39664\n",
      "[1867]\ttraining's binary_error: 0.180739\ttraining's binary_logloss: 0.396619\n",
      "[1868]\ttraining's binary_error: 0.180709\ttraining's binary_logloss: 0.396603\n",
      "[1869]\ttraining's binary_error: 0.180705\ttraining's binary_logloss: 0.396579\n",
      "[1870]\ttraining's binary_error: 0.180711\ttraining's binary_logloss: 0.396559\n",
      "[1871]\ttraining's binary_error: 0.180651\ttraining's binary_logloss: 0.396494\n",
      "[1872]\ttraining's binary_error: 0.180609\ttraining's binary_logloss: 0.396419\n",
      "[1873]\ttraining's binary_error: 0.180592\ttraining's binary_logloss: 0.396405\n",
      "[1874]\ttraining's binary_error: 0.180581\ttraining's binary_logloss: 0.396373\n",
      "[1875]\ttraining's binary_error: 0.18054\ttraining's binary_logloss: 0.396336\n",
      "[1876]\ttraining's binary_error: 0.180537\ttraining's binary_logloss: 0.396316\n",
      "[1877]\ttraining's binary_error: 0.180484\ttraining's binary_logloss: 0.396294\n",
      "[1878]\ttraining's binary_error: 0.180487\ttraining's binary_logloss: 0.396247\n",
      "[1879]\ttraining's binary_error: 0.180466\ttraining's binary_logloss: 0.396229\n",
      "[1880]\ttraining's binary_error: 0.1804\ttraining's binary_logloss: 0.396196\n",
      "[1881]\ttraining's binary_error: 0.180433\ttraining's binary_logloss: 0.396147\n",
      "[1882]\ttraining's binary_error: 0.180431\ttraining's binary_logloss: 0.39613\n",
      "[1883]\ttraining's binary_error: 0.180421\ttraining's binary_logloss: 0.396119\n",
      "[1884]\ttraining's binary_error: 0.18042\ttraining's binary_logloss: 0.396098\n",
      "[1885]\ttraining's binary_error: 0.180406\ttraining's binary_logloss: 0.396076\n",
      "[1886]\ttraining's binary_error: 0.180382\ttraining's binary_logloss: 0.395989\n",
      "[1887]\ttraining's binary_error: 0.180358\ttraining's binary_logloss: 0.395925\n",
      "[1888]\ttraining's binary_error: 0.180291\ttraining's binary_logloss: 0.395873\n",
      "[1889]\ttraining's binary_error: 0.180296\ttraining's binary_logloss: 0.395856\n",
      "[1890]\ttraining's binary_error: 0.180273\ttraining's binary_logloss: 0.395821\n",
      "[1891]\ttraining's binary_error: 0.180284\ttraining's binary_logloss: 0.395793\n",
      "[1892]\ttraining's binary_error: 0.180281\ttraining's binary_logloss: 0.39575\n",
      "[1893]\ttraining's binary_error: 0.180287\ttraining's binary_logloss: 0.395731\n",
      "[1894]\ttraining's binary_error: 0.18028\ttraining's binary_logloss: 0.395718\n",
      "[1895]\ttraining's binary_error: 0.18026\ttraining's binary_logloss: 0.395695\n",
      "[1896]\ttraining's binary_error: 0.180241\ttraining's binary_logloss: 0.395676\n",
      "[1897]\ttraining's binary_error: 0.180143\ttraining's binary_logloss: 0.395611\n",
      "[1898]\ttraining's binary_error: 0.180135\ttraining's binary_logloss: 0.395597\n",
      "[1899]\ttraining's binary_error: 0.180123\ttraining's binary_logloss: 0.395585\n",
      "[1900]\ttraining's binary_error: 0.180128\ttraining's binary_logloss: 0.395571\n",
      "[1901]\ttraining's binary_error: 0.18011\ttraining's binary_logloss: 0.395546\n",
      "[1902]\ttraining's binary_error: 0.180102\ttraining's binary_logloss: 0.395527\n",
      "[1903]\ttraining's binary_error: 0.180033\ttraining's binary_logloss: 0.395438\n",
      "[1904]\ttraining's binary_error: 0.180016\ttraining's binary_logloss: 0.395398\n",
      "[1905]\ttraining's binary_error: 0.180016\ttraining's binary_logloss: 0.395335\n",
      "[1906]\ttraining's binary_error: 0.180035\ttraining's binary_logloss: 0.395317\n",
      "[1907]\ttraining's binary_error: 0.180028\ttraining's binary_logloss: 0.395306\n",
      "[1908]\ttraining's binary_error: 0.180009\ttraining's binary_logloss: 0.395268\n",
      "[1909]\ttraining's binary_error: 0.18\ttraining's binary_logloss: 0.395252\n",
      "[1910]\ttraining's binary_error: 0.179942\ttraining's binary_logloss: 0.395152\n",
      "[1911]\ttraining's binary_error: 0.179937\ttraining's binary_logloss: 0.395136\n",
      "[1912]\ttraining's binary_error: 0.179933\ttraining's binary_logloss: 0.395119\n",
      "[1913]\ttraining's binary_error: 0.179912\ttraining's binary_logloss: 0.395102\n",
      "[1914]\ttraining's binary_error: 0.17992\ttraining's binary_logloss: 0.395088\n",
      "[1915]\ttraining's binary_error: 0.179885\ttraining's binary_logloss: 0.395063\n",
      "[1916]\ttraining's binary_error: 0.179882\ttraining's binary_logloss: 0.395055\n",
      "[1917]\ttraining's binary_error: 0.179781\ttraining's binary_logloss: 0.394934\n",
      "[1918]\ttraining's binary_error: 0.179795\ttraining's binary_logloss: 0.394869\n",
      "[1919]\ttraining's binary_error: 0.179722\ttraining's binary_logloss: 0.394768\n",
      "[1920]\ttraining's binary_error: 0.179698\ttraining's binary_logloss: 0.394714\n",
      "[1921]\ttraining's binary_error: 0.179659\ttraining's binary_logloss: 0.394629\n",
      "[1922]\ttraining's binary_error: 0.179663\ttraining's binary_logloss: 0.39459\n",
      "[1923]\ttraining's binary_error: 0.179671\ttraining's binary_logloss: 0.394566\n",
      "[1924]\ttraining's binary_error: 0.179673\ttraining's binary_logloss: 0.394552\n",
      "[1925]\ttraining's binary_error: 0.179654\ttraining's binary_logloss: 0.394542\n",
      "[1926]\ttraining's binary_error: 0.179654\ttraining's binary_logloss: 0.394521\n",
      "[1927]\ttraining's binary_error: 0.179657\ttraining's binary_logloss: 0.39449\n",
      "[1928]\ttraining's binary_error: 0.179664\ttraining's binary_logloss: 0.394477\n",
      "[1929]\ttraining's binary_error: 0.179655\ttraining's binary_logloss: 0.394444\n",
      "[1930]\ttraining's binary_error: 0.179635\ttraining's binary_logloss: 0.394415\n",
      "[1931]\ttraining's binary_error: 0.179617\ttraining's binary_logloss: 0.394376\n",
      "[1932]\ttraining's binary_error: 0.179633\ttraining's binary_logloss: 0.394348\n",
      "[1933]\ttraining's binary_error: 0.179638\ttraining's binary_logloss: 0.394331\n",
      "[1934]\ttraining's binary_error: 0.179615\ttraining's binary_logloss: 0.394317\n",
      "[1935]\ttraining's binary_error: 0.179584\ttraining's binary_logloss: 0.394249\n",
      "[1936]\ttraining's binary_error: 0.179598\ttraining's binary_logloss: 0.394225\n",
      "[1937]\ttraining's binary_error: 0.179579\ttraining's binary_logloss: 0.394196\n",
      "[1938]\ttraining's binary_error: 0.179549\ttraining's binary_logloss: 0.394167\n",
      "[1939]\ttraining's binary_error: 0.179545\ttraining's binary_logloss: 0.394157\n",
      "[1940]\ttraining's binary_error: 0.179538\ttraining's binary_logloss: 0.394141\n",
      "[1941]\ttraining's binary_error: 0.179513\ttraining's binary_logloss: 0.394113\n",
      "[1942]\ttraining's binary_error: 0.179496\ttraining's binary_logloss: 0.394097\n",
      "[1943]\ttraining's binary_error: 0.179479\ttraining's binary_logloss: 0.394078\n",
      "[1944]\ttraining's binary_error: 0.179468\ttraining's binary_logloss: 0.394059\n",
      "[1945]\ttraining's binary_error: 0.179457\ttraining's binary_logloss: 0.394037\n",
      "[1946]\ttraining's binary_error: 0.17944\ttraining's binary_logloss: 0.393979\n",
      "[1947]\ttraining's binary_error: 0.179432\ttraining's binary_logloss: 0.393969\n",
      "[1948]\ttraining's binary_error: 0.179463\ttraining's binary_logloss: 0.393899\n",
      "[1949]\ttraining's binary_error: 0.179409\ttraining's binary_logloss: 0.393832\n",
      "[1950]\ttraining's binary_error: 0.179367\ttraining's binary_logloss: 0.393792\n",
      "[1951]\ttraining's binary_error: 0.179324\ttraining's binary_logloss: 0.393714\n",
      "[1952]\ttraining's binary_error: 0.179334\ttraining's binary_logloss: 0.393666\n",
      "[1953]\ttraining's binary_error: 0.179308\ttraining's binary_logloss: 0.393637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1954]\ttraining's binary_error: 0.179286\ttraining's binary_logloss: 0.393601\n",
      "[1955]\ttraining's binary_error: 0.179259\ttraining's binary_logloss: 0.393544\n",
      "[1956]\ttraining's binary_error: 0.179227\ttraining's binary_logloss: 0.393505\n",
      "[1957]\ttraining's binary_error: 0.179204\ttraining's binary_logloss: 0.393491\n",
      "[1958]\ttraining's binary_error: 0.179203\ttraining's binary_logloss: 0.39346\n",
      "[1959]\ttraining's binary_error: 0.179189\ttraining's binary_logloss: 0.393437\n",
      "[1960]\ttraining's binary_error: 0.179152\ttraining's binary_logloss: 0.393377\n",
      "[1961]\ttraining's binary_error: 0.179143\ttraining's binary_logloss: 0.393357\n",
      "[1962]\ttraining's binary_error: 0.179144\ttraining's binary_logloss: 0.39334\n",
      "[1963]\ttraining's binary_error: 0.179111\ttraining's binary_logloss: 0.393292\n",
      "[1964]\ttraining's binary_error: 0.179108\ttraining's binary_logloss: 0.393264\n",
      "[1965]\ttraining's binary_error: 0.179084\ttraining's binary_logloss: 0.393224\n",
      "[1966]\ttraining's binary_error: 0.179074\ttraining's binary_logloss: 0.39321\n",
      "[1967]\ttraining's binary_error: 0.179038\ttraining's binary_logloss: 0.393171\n",
      "[1968]\ttraining's binary_error: 0.179026\ttraining's binary_logloss: 0.393154\n",
      "[1969]\ttraining's binary_error: 0.179025\ttraining's binary_logloss: 0.393135\n",
      "[1970]\ttraining's binary_error: 0.179004\ttraining's binary_logloss: 0.393093\n",
      "[1971]\ttraining's binary_error: 0.178924\ttraining's binary_logloss: 0.393048\n",
      "[1972]\ttraining's binary_error: 0.178898\ttraining's binary_logloss: 0.392985\n",
      "[1973]\ttraining's binary_error: 0.178865\ttraining's binary_logloss: 0.392968\n",
      "[1974]\ttraining's binary_error: 0.178857\ttraining's binary_logloss: 0.392936\n",
      "[1975]\ttraining's binary_error: 0.178854\ttraining's binary_logloss: 0.392917\n",
      "[1976]\ttraining's binary_error: 0.178823\ttraining's binary_logloss: 0.392884\n",
      "[1977]\ttraining's binary_error: 0.178784\ttraining's binary_logloss: 0.392785\n",
      "[1978]\ttraining's binary_error: 0.178815\ttraining's binary_logloss: 0.392763\n",
      "[1979]\ttraining's binary_error: 0.17881\ttraining's binary_logloss: 0.392738\n",
      "[1980]\ttraining's binary_error: 0.178809\ttraining's binary_logloss: 0.39271\n",
      "[1981]\ttraining's binary_error: 0.178718\ttraining's binary_logloss: 0.392574\n",
      "[1982]\ttraining's binary_error: 0.178704\ttraining's binary_logloss: 0.392561\n",
      "[1983]\ttraining's binary_error: 0.178657\ttraining's binary_logloss: 0.392443\n",
      "[1984]\ttraining's binary_error: 0.178616\ttraining's binary_logloss: 0.392322\n",
      "[1985]\ttraining's binary_error: 0.178606\ttraining's binary_logloss: 0.39225\n",
      "[1986]\ttraining's binary_error: 0.178568\ttraining's binary_logloss: 0.392188\n",
      "[1987]\ttraining's binary_error: 0.178555\ttraining's binary_logloss: 0.392149\n",
      "[1988]\ttraining's binary_error: 0.178521\ttraining's binary_logloss: 0.3921\n",
      "[1989]\ttraining's binary_error: 0.178513\ttraining's binary_logloss: 0.391949\n",
      "[1990]\ttraining's binary_error: 0.178466\ttraining's binary_logloss: 0.391922\n",
      "[1991]\ttraining's binary_error: 0.178438\ttraining's binary_logloss: 0.391881\n",
      "[1992]\ttraining's binary_error: 0.178413\ttraining's binary_logloss: 0.39187\n",
      "[1993]\ttraining's binary_error: 0.178398\ttraining's binary_logloss: 0.391855\n",
      "[1994]\ttraining's binary_error: 0.178347\ttraining's binary_logloss: 0.391804\n",
      "[1995]\ttraining's binary_error: 0.178331\ttraining's binary_logloss: 0.391787\n",
      "[1996]\ttraining's binary_error: 0.178315\ttraining's binary_logloss: 0.39177\n",
      "[1997]\ttraining's binary_error: 0.178308\ttraining's binary_logloss: 0.391757\n",
      "[1998]\ttraining's binary_error: 0.178295\ttraining's binary_logloss: 0.39174\n",
      "[1999]\ttraining's binary_error: 0.178279\ttraining's binary_logloss: 0.391705\n",
      "[2000]\ttraining's binary_error: 0.178289\ttraining's binary_logloss: 0.391685\n",
      "[2001]\ttraining's binary_error: 0.178285\ttraining's binary_logloss: 0.391666\n",
      "[2002]\ttraining's binary_error: 0.178269\ttraining's binary_logloss: 0.391653\n",
      "[2003]\ttraining's binary_error: 0.178274\ttraining's binary_logloss: 0.391641\n",
      "[2004]\ttraining's binary_error: 0.178201\ttraining's binary_logloss: 0.391521\n",
      "[2005]\ttraining's binary_error: 0.178201\ttraining's binary_logloss: 0.391506\n",
      "[2006]\ttraining's binary_error: 0.178192\ttraining's binary_logloss: 0.391486\n",
      "[2007]\ttraining's binary_error: 0.178156\ttraining's binary_logloss: 0.391431\n",
      "[2008]\ttraining's binary_error: 0.178149\ttraining's binary_logloss: 0.39142\n",
      "[2009]\ttraining's binary_error: 0.178162\ttraining's binary_logloss: 0.391382\n",
      "[2010]\ttraining's binary_error: 0.178113\ttraining's binary_logloss: 0.391296\n",
      "[2011]\ttraining's binary_error: 0.178092\ttraining's binary_logloss: 0.391282\n",
      "[2012]\ttraining's binary_error: 0.178039\ttraining's binary_logloss: 0.391252\n",
      "[2013]\ttraining's binary_error: 0.177999\ttraining's binary_logloss: 0.391219\n",
      "[2014]\ttraining's binary_error: 0.177985\ttraining's binary_logloss: 0.39119\n",
      "[2015]\ttraining's binary_error: 0.177916\ttraining's binary_logloss: 0.391107\n",
      "[2016]\ttraining's binary_error: 0.177909\ttraining's binary_logloss: 0.391082\n",
      "[2017]\ttraining's binary_error: 0.177883\ttraining's binary_logloss: 0.391064\n",
      "[2018]\ttraining's binary_error: 0.177835\ttraining's binary_logloss: 0.390962\n",
      "[2019]\ttraining's binary_error: 0.177805\ttraining's binary_logloss: 0.390932\n",
      "[2020]\ttraining's binary_error: 0.177809\ttraining's binary_logloss: 0.390902\n",
      "[2021]\ttraining's binary_error: 0.177791\ttraining's binary_logloss: 0.390887\n",
      "[2022]\ttraining's binary_error: 0.177772\ttraining's binary_logloss: 0.390873\n",
      "[2023]\ttraining's binary_error: 0.177752\ttraining's binary_logloss: 0.39086\n",
      "[2024]\ttraining's binary_error: 0.177739\ttraining's binary_logloss: 0.390847\n",
      "[2025]\ttraining's binary_error: 0.177733\ttraining's binary_logloss: 0.390814\n",
      "[2026]\ttraining's binary_error: 0.177737\ttraining's binary_logloss: 0.390798\n",
      "[2027]\ttraining's binary_error: 0.177739\ttraining's binary_logloss: 0.390774\n",
      "[2028]\ttraining's binary_error: 0.177721\ttraining's binary_logloss: 0.390756\n",
      "[2029]\ttraining's binary_error: 0.177698\ttraining's binary_logloss: 0.390738\n",
      "[2030]\ttraining's binary_error: 0.177694\ttraining's binary_logloss: 0.390724\n",
      "[2031]\ttraining's binary_error: 0.177675\ttraining's binary_logloss: 0.390699\n",
      "[2032]\ttraining's binary_error: 0.177615\ttraining's binary_logloss: 0.390628\n",
      "[2033]\ttraining's binary_error: 0.177633\ttraining's binary_logloss: 0.390609\n",
      "[2034]\ttraining's binary_error: 0.177629\ttraining's binary_logloss: 0.3906\n",
      "[2035]\ttraining's binary_error: 0.177607\ttraining's binary_logloss: 0.390588\n",
      "[2036]\ttraining's binary_error: 0.177595\ttraining's binary_logloss: 0.390523\n",
      "[2037]\ttraining's binary_error: 0.177581\ttraining's binary_logloss: 0.390489\n",
      "[2038]\ttraining's binary_error: 0.177548\ttraining's binary_logloss: 0.390448\n",
      "[2039]\ttraining's binary_error: 0.177551\ttraining's binary_logloss: 0.390381\n",
      "[2040]\ttraining's binary_error: 0.177497\ttraining's binary_logloss: 0.390333\n",
      "[2041]\ttraining's binary_error: 0.177464\ttraining's binary_logloss: 0.390276\n",
      "[2042]\ttraining's binary_error: 0.177434\ttraining's binary_logloss: 0.390188\n",
      "[2043]\ttraining's binary_error: 0.17742\ttraining's binary_logloss: 0.390173\n",
      "[2044]\ttraining's binary_error: 0.177341\ttraining's binary_logloss: 0.390086\n",
      "[2045]\ttraining's binary_error: 0.17732\ttraining's binary_logloss: 0.390058\n",
      "[2046]\ttraining's binary_error: 0.177323\ttraining's binary_logloss: 0.39004\n",
      "[2047]\ttraining's binary_error: 0.177306\ttraining's binary_logloss: 0.390021\n",
      "[2048]\ttraining's binary_error: 0.177313\ttraining's binary_logloss: 0.390012\n",
      "[2049]\ttraining's binary_error: 0.177336\ttraining's binary_logloss: 0.389997\n",
      "[2050]\ttraining's binary_error: 0.177289\ttraining's binary_logloss: 0.389911\n",
      "[2051]\ttraining's binary_error: 0.17727\ttraining's binary_logloss: 0.389886\n",
      "[2052]\ttraining's binary_error: 0.177234\ttraining's binary_logloss: 0.389842\n",
      "[2053]\ttraining's binary_error: 0.177194\ttraining's binary_logloss: 0.389781\n",
      "[2054]\ttraining's binary_error: 0.177177\ttraining's binary_logloss: 0.389761\n",
      "[2055]\ttraining's binary_error: 0.177167\ttraining's binary_logloss: 0.389748\n",
      "[2056]\ttraining's binary_error: 0.177105\ttraining's binary_logloss: 0.389674\n",
      "[2057]\ttraining's binary_error: 0.177049\ttraining's binary_logloss: 0.389617\n",
      "[2058]\ttraining's binary_error: 0.176964\ttraining's binary_logloss: 0.389516\n",
      "[2059]\ttraining's binary_error: 0.176944\ttraining's binary_logloss: 0.389499\n",
      "[2060]\ttraining's binary_error: 0.176928\ttraining's binary_logloss: 0.389488\n",
      "[2061]\ttraining's binary_error: 0.176915\ttraining's binary_logloss: 0.389476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2062]\ttraining's binary_error: 0.176897\ttraining's binary_logloss: 0.389459\n",
      "[2063]\ttraining's binary_error: 0.176863\ttraining's binary_logloss: 0.389374\n",
      "[2064]\ttraining's binary_error: 0.176838\ttraining's binary_logloss: 0.389348\n",
      "[2065]\ttraining's binary_error: 0.176841\ttraining's binary_logloss: 0.389332\n",
      "[2066]\ttraining's binary_error: 0.176841\ttraining's binary_logloss: 0.389317\n",
      "[2067]\ttraining's binary_error: 0.176847\ttraining's binary_logloss: 0.389298\n",
      "[2068]\ttraining's binary_error: 0.176856\ttraining's binary_logloss: 0.389288\n",
      "[2069]\ttraining's binary_error: 0.176848\ttraining's binary_logloss: 0.389276\n",
      "[2070]\ttraining's binary_error: 0.176806\ttraining's binary_logloss: 0.389233\n",
      "[2071]\ttraining's binary_error: 0.17677\ttraining's binary_logloss: 0.389159\n",
      "[2072]\ttraining's binary_error: 0.176766\ttraining's binary_logloss: 0.389145\n",
      "[2073]\ttraining's binary_error: 0.176734\ttraining's binary_logloss: 0.389135\n",
      "[2074]\ttraining's binary_error: 0.17671\ttraining's binary_logloss: 0.38909\n",
      "[2075]\ttraining's binary_error: 0.176702\ttraining's binary_logloss: 0.389071\n",
      "[2076]\ttraining's binary_error: 0.176657\ttraining's binary_logloss: 0.388972\n",
      "[2077]\ttraining's binary_error: 0.176628\ttraining's binary_logloss: 0.388922\n",
      "[2078]\ttraining's binary_error: 0.176607\ttraining's binary_logloss: 0.388894\n",
      "[2079]\ttraining's binary_error: 0.176535\ttraining's binary_logloss: 0.388806\n",
      "[2080]\ttraining's binary_error: 0.176476\ttraining's binary_logloss: 0.388748\n",
      "[2081]\ttraining's binary_error: 0.176454\ttraining's binary_logloss: 0.388733\n",
      "[2082]\ttraining's binary_error: 0.176432\ttraining's binary_logloss: 0.388716\n",
      "[2083]\ttraining's binary_error: 0.176413\ttraining's binary_logloss: 0.388701\n",
      "[2084]\ttraining's binary_error: 0.176423\ttraining's binary_logloss: 0.388686\n",
      "[2085]\ttraining's binary_error: 0.176386\ttraining's binary_logloss: 0.388663\n",
      "[2086]\ttraining's binary_error: 0.176364\ttraining's binary_logloss: 0.388644\n",
      "[2087]\ttraining's binary_error: 0.17633\ttraining's binary_logloss: 0.388589\n",
      "[2088]\ttraining's binary_error: 0.176317\ttraining's binary_logloss: 0.38857\n",
      "[2089]\ttraining's binary_error: 0.17628\ttraining's binary_logloss: 0.388522\n",
      "[2090]\ttraining's binary_error: 0.176229\ttraining's binary_logloss: 0.388425\n",
      "[2091]\ttraining's binary_error: 0.176186\ttraining's binary_logloss: 0.38836\n",
      "[2092]\ttraining's binary_error: 0.176181\ttraining's binary_logloss: 0.388341\n",
      "[2093]\ttraining's binary_error: 0.176206\ttraining's binary_logloss: 0.388329\n",
      "[2094]\ttraining's binary_error: 0.176195\ttraining's binary_logloss: 0.388282\n",
      "[2095]\ttraining's binary_error: 0.176115\ttraining's binary_logloss: 0.388228\n",
      "[2096]\ttraining's binary_error: 0.176103\ttraining's binary_logloss: 0.388211\n",
      "[2097]\ttraining's binary_error: 0.176019\ttraining's binary_logloss: 0.38812\n",
      "[2098]\ttraining's binary_error: 0.176028\ttraining's binary_logloss: 0.388102\n",
      "[2099]\ttraining's binary_error: 0.17602\ttraining's binary_logloss: 0.388086\n",
      "[2100]\ttraining's binary_error: 0.175995\ttraining's binary_logloss: 0.388072\n",
      "[2101]\ttraining's binary_error: 0.175988\ttraining's binary_logloss: 0.38806\n",
      "[2102]\ttraining's binary_error: 0.175979\ttraining's binary_logloss: 0.388044\n",
      "[2103]\ttraining's binary_error: 0.175975\ttraining's binary_logloss: 0.388029\n",
      "[2104]\ttraining's binary_error: 0.175927\ttraining's binary_logloss: 0.38797\n",
      "[2105]\ttraining's binary_error: 0.175905\ttraining's binary_logloss: 0.387918\n",
      "[2106]\ttraining's binary_error: 0.175906\ttraining's binary_logloss: 0.387898\n",
      "[2107]\ttraining's binary_error: 0.175897\ttraining's binary_logloss: 0.387885\n",
      "[2108]\ttraining's binary_error: 0.175882\ttraining's binary_logloss: 0.38786\n",
      "[2109]\ttraining's binary_error: 0.175879\ttraining's binary_logloss: 0.387849\n",
      "[2110]\ttraining's binary_error: 0.175865\ttraining's binary_logloss: 0.387822\n",
      "[2111]\ttraining's binary_error: 0.175848\ttraining's binary_logloss: 0.387788\n",
      "[2112]\ttraining's binary_error: 0.175816\ttraining's binary_logloss: 0.387759\n",
      "[2113]\ttraining's binary_error: 0.175807\ttraining's binary_logloss: 0.387713\n",
      "[2114]\ttraining's binary_error: 0.175782\ttraining's binary_logloss: 0.38767\n",
      "[2115]\ttraining's binary_error: 0.175761\ttraining's binary_logloss: 0.387656\n",
      "[2116]\ttraining's binary_error: 0.175719\ttraining's binary_logloss: 0.38764\n",
      "[2117]\ttraining's binary_error: 0.175707\ttraining's binary_logloss: 0.387621\n",
      "[2118]\ttraining's binary_error: 0.175671\ttraining's binary_logloss: 0.387592\n",
      "[2119]\ttraining's binary_error: 0.175672\ttraining's binary_logloss: 0.387568\n",
      "[2120]\ttraining's binary_error: 0.175675\ttraining's binary_logloss: 0.387553\n",
      "[2121]\ttraining's binary_error: 0.175632\ttraining's binary_logloss: 0.387504\n",
      "[2122]\ttraining's binary_error: 0.175624\ttraining's binary_logloss: 0.387493\n",
      "[2123]\ttraining's binary_error: 0.175564\ttraining's binary_logloss: 0.387412\n",
      "[2124]\ttraining's binary_error: 0.175559\ttraining's binary_logloss: 0.387401\n",
      "[2125]\ttraining's binary_error: 0.175546\ttraining's binary_logloss: 0.387386\n",
      "[2126]\ttraining's binary_error: 0.175536\ttraining's binary_logloss: 0.387373\n",
      "[2127]\ttraining's binary_error: 0.175496\ttraining's binary_logloss: 0.387329\n",
      "[2128]\ttraining's binary_error: 0.175497\ttraining's binary_logloss: 0.387308\n",
      "[2129]\ttraining's binary_error: 0.175499\ttraining's binary_logloss: 0.387293\n",
      "[2130]\ttraining's binary_error: 0.175501\ttraining's binary_logloss: 0.387269\n",
      "[2131]\ttraining's binary_error: 0.17553\ttraining's binary_logloss: 0.387245\n",
      "[2132]\ttraining's binary_error: 0.175468\ttraining's binary_logloss: 0.387176\n",
      "[2133]\ttraining's binary_error: 0.175464\ttraining's binary_logloss: 0.387142\n",
      "[2134]\ttraining's binary_error: 0.175432\ttraining's binary_logloss: 0.387104\n",
      "[2135]\ttraining's binary_error: 0.175418\ttraining's binary_logloss: 0.387045\n",
      "[2136]\ttraining's binary_error: 0.175333\ttraining's binary_logloss: 0.386938\n",
      "[2137]\ttraining's binary_error: 0.175302\ttraining's binary_logloss: 0.386848\n",
      "[2138]\ttraining's binary_error: 0.175293\ttraining's binary_logloss: 0.386834\n",
      "[2139]\ttraining's binary_error: 0.175277\ttraining's binary_logloss: 0.386786\n",
      "[2140]\ttraining's binary_error: 0.175219\ttraining's binary_logloss: 0.386747\n",
      "[2141]\ttraining's binary_error: 0.175253\ttraining's binary_logloss: 0.386718\n",
      "[2142]\ttraining's binary_error: 0.175239\ttraining's binary_logloss: 0.386682\n",
      "[2143]\ttraining's binary_error: 0.175252\ttraining's binary_logloss: 0.386669\n",
      "[2144]\ttraining's binary_error: 0.175244\ttraining's binary_logloss: 0.386635\n",
      "[2145]\ttraining's binary_error: 0.175235\ttraining's binary_logloss: 0.38662\n",
      "[2146]\ttraining's binary_error: 0.175219\ttraining's binary_logloss: 0.386607\n",
      "[2147]\ttraining's binary_error: 0.175215\ttraining's binary_logloss: 0.386596\n",
      "[2148]\ttraining's binary_error: 0.175202\ttraining's binary_logloss: 0.386573\n",
      "[2149]\ttraining's binary_error: 0.175151\ttraining's binary_logloss: 0.386521\n",
      "[2150]\ttraining's binary_error: 0.175139\ttraining's binary_logloss: 0.386502\n",
      "[2151]\ttraining's binary_error: 0.175112\ttraining's binary_logloss: 0.386465\n",
      "[2152]\ttraining's binary_error: 0.175115\ttraining's binary_logloss: 0.386457\n",
      "[2153]\ttraining's binary_error: 0.174987\ttraining's binary_logloss: 0.386416\n",
      "[2154]\ttraining's binary_error: 0.174952\ttraining's binary_logloss: 0.386371\n",
      "[2155]\ttraining's binary_error: 0.174912\ttraining's binary_logloss: 0.386305\n",
      "[2156]\ttraining's binary_error: 0.174903\ttraining's binary_logloss: 0.386287\n",
      "[2157]\ttraining's binary_error: 0.174892\ttraining's binary_logloss: 0.386262\n",
      "[2158]\ttraining's binary_error: 0.174882\ttraining's binary_logloss: 0.386248\n",
      "[2159]\ttraining's binary_error: 0.174868\ttraining's binary_logloss: 0.386225\n",
      "[2160]\ttraining's binary_error: 0.174846\ttraining's binary_logloss: 0.386208\n",
      "[2161]\ttraining's binary_error: 0.174832\ttraining's binary_logloss: 0.386155\n",
      "[2162]\ttraining's binary_error: 0.17483\ttraining's binary_logloss: 0.386147\n",
      "[2163]\ttraining's binary_error: 0.174808\ttraining's binary_logloss: 0.386122\n",
      "[2164]\ttraining's binary_error: 0.174792\ttraining's binary_logloss: 0.386107\n",
      "[2165]\ttraining's binary_error: 0.174773\ttraining's binary_logloss: 0.386085\n",
      "[2166]\ttraining's binary_error: 0.174792\ttraining's binary_logloss: 0.386058\n",
      "[2167]\ttraining's binary_error: 0.174763\ttraining's binary_logloss: 0.38604\n",
      "[2168]\ttraining's binary_error: 0.174743\ttraining's binary_logloss: 0.386023\n",
      "[2169]\ttraining's binary_error: 0.174726\ttraining's binary_logloss: 0.386005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2170]\ttraining's binary_error: 0.17472\ttraining's binary_logloss: 0.385989\n",
      "[2171]\ttraining's binary_error: 0.174732\ttraining's binary_logloss: 0.385964\n",
      "[2172]\ttraining's binary_error: 0.174718\ttraining's binary_logloss: 0.385932\n",
      "[2173]\ttraining's binary_error: 0.174708\ttraining's binary_logloss: 0.385876\n",
      "[2174]\ttraining's binary_error: 0.174683\ttraining's binary_logloss: 0.385867\n",
      "[2175]\ttraining's binary_error: 0.17463\ttraining's binary_logloss: 0.385832\n",
      "[2176]\ttraining's binary_error: 0.174635\ttraining's binary_logloss: 0.385819\n",
      "[2177]\ttraining's binary_error: 0.17464\ttraining's binary_logloss: 0.385794\n",
      "[2178]\ttraining's binary_error: 0.174647\ttraining's binary_logloss: 0.385774\n",
      "[2179]\ttraining's binary_error: 0.17459\ttraining's binary_logloss: 0.385703\n",
      "[2180]\ttraining's binary_error: 0.174571\ttraining's binary_logloss: 0.38569\n",
      "[2181]\ttraining's binary_error: 0.174569\ttraining's binary_logloss: 0.385647\n",
      "[2182]\ttraining's binary_error: 0.174537\ttraining's binary_logloss: 0.385628\n",
      "[2183]\ttraining's binary_error: 0.174558\ttraining's binary_logloss: 0.385612\n",
      "[2184]\ttraining's binary_error: 0.174534\ttraining's binary_logloss: 0.385602\n",
      "[2185]\ttraining's binary_error: 0.174525\ttraining's binary_logloss: 0.385584\n",
      "[2186]\ttraining's binary_error: 0.174497\ttraining's binary_logloss: 0.385557\n",
      "[2187]\ttraining's binary_error: 0.174489\ttraining's binary_logloss: 0.385546\n",
      "[2188]\ttraining's binary_error: 0.174479\ttraining's binary_logloss: 0.385531\n",
      "[2189]\ttraining's binary_error: 0.174504\ttraining's binary_logloss: 0.385523\n",
      "[2190]\ttraining's binary_error: 0.174473\ttraining's binary_logloss: 0.385482\n",
      "[2191]\ttraining's binary_error: 0.174454\ttraining's binary_logloss: 0.385454\n",
      "[2192]\ttraining's binary_error: 0.174438\ttraining's binary_logloss: 0.385439\n",
      "[2193]\ttraining's binary_error: 0.174436\ttraining's binary_logloss: 0.385426\n",
      "[2194]\ttraining's binary_error: 0.174419\ttraining's binary_logloss: 0.385409\n",
      "[2195]\ttraining's binary_error: 0.174417\ttraining's binary_logloss: 0.385404\n",
      "[2196]\ttraining's binary_error: 0.174392\ttraining's binary_logloss: 0.38536\n",
      "[2197]\ttraining's binary_error: 0.174384\ttraining's binary_logloss: 0.385348\n",
      "[2198]\ttraining's binary_error: 0.174372\ttraining's binary_logloss: 0.385329\n",
      "[2199]\ttraining's binary_error: 0.174361\ttraining's binary_logloss: 0.385308\n",
      "[2200]\ttraining's binary_error: 0.174337\ttraining's binary_logloss: 0.385287\n",
      "[2201]\ttraining's binary_error: 0.174321\ttraining's binary_logloss: 0.385275\n",
      "[2202]\ttraining's binary_error: 0.174319\ttraining's binary_logloss: 0.385261\n",
      "[2203]\ttraining's binary_error: 0.174301\ttraining's binary_logloss: 0.385239\n",
      "[2204]\ttraining's binary_error: 0.174285\ttraining's binary_logloss: 0.385183\n",
      "[2205]\ttraining's binary_error: 0.174273\ttraining's binary_logloss: 0.385163\n",
      "[2206]\ttraining's binary_error: 0.174247\ttraining's binary_logloss: 0.385141\n",
      "[2207]\ttraining's binary_error: 0.174256\ttraining's binary_logloss: 0.385112\n",
      "[2208]\ttraining's binary_error: 0.17424\ttraining's binary_logloss: 0.385066\n",
      "[2209]\ttraining's binary_error: 0.174205\ttraining's binary_logloss: 0.384996\n",
      "[2210]\ttraining's binary_error: 0.174166\ttraining's binary_logloss: 0.384929\n",
      "[2211]\ttraining's binary_error: 0.174174\ttraining's binary_logloss: 0.384884\n",
      "[2212]\ttraining's binary_error: 0.174155\ttraining's binary_logloss: 0.384862\n",
      "[2213]\ttraining's binary_error: 0.174103\ttraining's binary_logloss: 0.384807\n",
      "[2214]\ttraining's binary_error: 0.174084\ttraining's binary_logloss: 0.384772\n",
      "[2215]\ttraining's binary_error: 0.174067\ttraining's binary_logloss: 0.384753\n",
      "[2216]\ttraining's binary_error: 0.174064\ttraining's binary_logloss: 0.38474\n",
      "[2217]\ttraining's binary_error: 0.174053\ttraining's binary_logloss: 0.384716\n",
      "[2218]\ttraining's binary_error: 0.17403\ttraining's binary_logloss: 0.384697\n",
      "[2219]\ttraining's binary_error: 0.174019\ttraining's binary_logloss: 0.384663\n",
      "[2220]\ttraining's binary_error: 0.174019\ttraining's binary_logloss: 0.384638\n",
      "[2221]\ttraining's binary_error: 0.17401\ttraining's binary_logloss: 0.384609\n",
      "[2222]\ttraining's binary_error: 0.173981\ttraining's binary_logloss: 0.384571\n",
      "[2223]\ttraining's binary_error: 0.173953\ttraining's binary_logloss: 0.384528\n",
      "[2224]\ttraining's binary_error: 0.173945\ttraining's binary_logloss: 0.38449\n",
      "[2225]\ttraining's binary_error: 0.173914\ttraining's binary_logloss: 0.384453\n",
      "[2226]\ttraining's binary_error: 0.173911\ttraining's binary_logloss: 0.384437\n",
      "[2227]\ttraining's binary_error: 0.173902\ttraining's binary_logloss: 0.38442\n",
      "[2228]\ttraining's binary_error: 0.173902\ttraining's binary_logloss: 0.384408\n",
      "[2229]\ttraining's binary_error: 0.173881\ttraining's binary_logloss: 0.384362\n",
      "[2230]\ttraining's binary_error: 0.17385\ttraining's binary_logloss: 0.384315\n",
      "[2231]\ttraining's binary_error: 0.173843\ttraining's binary_logloss: 0.3843\n",
      "[2232]\ttraining's binary_error: 0.173805\ttraining's binary_logloss: 0.384215\n",
      "[2233]\ttraining's binary_error: 0.173803\ttraining's binary_logloss: 0.384204\n",
      "[2234]\ttraining's binary_error: 0.173792\ttraining's binary_logloss: 0.384162\n",
      "[2235]\ttraining's binary_error: 0.17377\ttraining's binary_logloss: 0.384153\n",
      "[2236]\ttraining's binary_error: 0.173776\ttraining's binary_logloss: 0.384134\n",
      "[2237]\ttraining's binary_error: 0.173754\ttraining's binary_logloss: 0.384116\n",
      "[2238]\ttraining's binary_error: 0.173701\ttraining's binary_logloss: 0.384017\n",
      "[2239]\ttraining's binary_error: 0.173742\ttraining's binary_logloss: 0.383994\n",
      "[2240]\ttraining's binary_error: 0.173743\ttraining's binary_logloss: 0.383979\n",
      "[2241]\ttraining's binary_error: 0.173721\ttraining's binary_logloss: 0.383937\n",
      "[2242]\ttraining's binary_error: 0.173659\ttraining's binary_logloss: 0.383873\n",
      "[2243]\ttraining's binary_error: 0.173626\ttraining's binary_logloss: 0.383854\n",
      "[2244]\ttraining's binary_error: 0.17363\ttraining's binary_logloss: 0.383841\n",
      "[2245]\ttraining's binary_error: 0.173618\ttraining's binary_logloss: 0.383811\n",
      "[2246]\ttraining's binary_error: 0.173606\ttraining's binary_logloss: 0.383801\n",
      "[2247]\ttraining's binary_error: 0.173581\ttraining's binary_logloss: 0.383785\n",
      "[2248]\ttraining's binary_error: 0.173589\ttraining's binary_logloss: 0.383758\n",
      "[2249]\ttraining's binary_error: 0.173578\ttraining's binary_logloss: 0.383746\n",
      "[2250]\ttraining's binary_error: 0.173564\ttraining's binary_logloss: 0.383723\n",
      "[2251]\ttraining's binary_error: 0.173573\ttraining's binary_logloss: 0.383711\n",
      "[2252]\ttraining's binary_error: 0.173574\ttraining's binary_logloss: 0.383687\n",
      "[2253]\ttraining's binary_error: 0.173553\ttraining's binary_logloss: 0.383668\n",
      "[2254]\ttraining's binary_error: 0.173545\ttraining's binary_logloss: 0.383655\n",
      "[2255]\ttraining's binary_error: 0.173538\ttraining's binary_logloss: 0.383644\n",
      "[2256]\ttraining's binary_error: 0.173543\ttraining's binary_logloss: 0.383621\n",
      "[2257]\ttraining's binary_error: 0.173529\ttraining's binary_logloss: 0.38358\n",
      "[2258]\ttraining's binary_error: 0.173511\ttraining's binary_logloss: 0.383562\n",
      "[2259]\ttraining's binary_error: 0.173502\ttraining's binary_logloss: 0.38354\n",
      "[2260]\ttraining's binary_error: 0.173477\ttraining's binary_logloss: 0.383508\n",
      "[2261]\ttraining's binary_error: 0.173446\ttraining's binary_logloss: 0.383492\n",
      "[2262]\ttraining's binary_error: 0.173421\ttraining's binary_logloss: 0.383422\n",
      "[2263]\ttraining's binary_error: 0.173402\ttraining's binary_logloss: 0.383388\n",
      "[2264]\ttraining's binary_error: 0.173395\ttraining's binary_logloss: 0.383378\n",
      "[2265]\ttraining's binary_error: 0.173395\ttraining's binary_logloss: 0.383363\n",
      "[2266]\ttraining's binary_error: 0.173386\ttraining's binary_logloss: 0.383352\n",
      "[2267]\ttraining's binary_error: 0.173382\ttraining's binary_logloss: 0.383345\n",
      "[2268]\ttraining's binary_error: 0.173361\ttraining's binary_logloss: 0.383297\n",
      "[2269]\ttraining's binary_error: 0.173332\ttraining's binary_logloss: 0.383279\n",
      "[2270]\ttraining's binary_error: 0.173296\ttraining's binary_logloss: 0.383227\n",
      "[2271]\ttraining's binary_error: 0.17327\ttraining's binary_logloss: 0.383196\n",
      "[2272]\ttraining's binary_error: 0.173252\ttraining's binary_logloss: 0.383177\n",
      "[2273]\ttraining's binary_error: 0.173252\ttraining's binary_logloss: 0.383169\n",
      "[2274]\ttraining's binary_error: 0.17323\ttraining's binary_logloss: 0.383148\n",
      "[2275]\ttraining's binary_error: 0.173223\ttraining's binary_logloss: 0.383139\n",
      "[2276]\ttraining's binary_error: 0.173172\ttraining's binary_logloss: 0.383095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2277]\ttraining's binary_error: 0.173155\ttraining's binary_logloss: 0.383071\n",
      "[2278]\ttraining's binary_error: 0.173116\ttraining's binary_logloss: 0.383008\n",
      "[2279]\ttraining's binary_error: 0.173102\ttraining's binary_logloss: 0.382971\n",
      "[2280]\ttraining's binary_error: 0.173024\ttraining's binary_logloss: 0.382892\n",
      "[2281]\ttraining's binary_error: 0.173017\ttraining's binary_logloss: 0.382861\n",
      "[2282]\ttraining's binary_error: 0.173014\ttraining's binary_logloss: 0.38285\n",
      "[2283]\ttraining's binary_error: 0.172983\ttraining's binary_logloss: 0.382818\n",
      "[2284]\ttraining's binary_error: 0.172927\ttraining's binary_logloss: 0.382744\n",
      "[2285]\ttraining's binary_error: 0.172934\ttraining's binary_logloss: 0.382725\n",
      "[2286]\ttraining's binary_error: 0.172893\ttraining's binary_logloss: 0.382651\n",
      "[2287]\ttraining's binary_error: 0.172865\ttraining's binary_logloss: 0.382606\n",
      "[2288]\ttraining's binary_error: 0.172816\ttraining's binary_logloss: 0.382537\n",
      "[2289]\ttraining's binary_error: 0.172799\ttraining's binary_logloss: 0.382501\n",
      "[2290]\ttraining's binary_error: 0.172798\ttraining's binary_logloss: 0.382477\n",
      "[2291]\ttraining's binary_error: 0.17278\ttraining's binary_logloss: 0.382467\n",
      "[2292]\ttraining's binary_error: 0.172792\ttraining's binary_logloss: 0.382456\n",
      "[2293]\ttraining's binary_error: 0.172796\ttraining's binary_logloss: 0.382445\n",
      "[2294]\ttraining's binary_error: 0.172791\ttraining's binary_logloss: 0.382431\n",
      "[2295]\ttraining's binary_error: 0.172773\ttraining's binary_logloss: 0.382374\n",
      "[2296]\ttraining's binary_error: 0.172773\ttraining's binary_logloss: 0.382344\n",
      "[2297]\ttraining's binary_error: 0.172767\ttraining's binary_logloss: 0.382317\n",
      "[2298]\ttraining's binary_error: 0.172764\ttraining's binary_logloss: 0.382305\n",
      "[2299]\ttraining's binary_error: 0.172731\ttraining's binary_logloss: 0.382238\n",
      "[2300]\ttraining's binary_error: 0.172725\ttraining's binary_logloss: 0.38222\n",
      "[2301]\ttraining's binary_error: 0.17272\ttraining's binary_logloss: 0.382201\n",
      "[2302]\ttraining's binary_error: 0.172695\ttraining's binary_logloss: 0.382187\n",
      "[2303]\ttraining's binary_error: 0.172694\ttraining's binary_logloss: 0.382172\n",
      "[2304]\ttraining's binary_error: 0.172678\ttraining's binary_logloss: 0.382159\n",
      "[2305]\ttraining's binary_error: 0.172676\ttraining's binary_logloss: 0.382143\n",
      "[2306]\ttraining's binary_error: 0.172661\ttraining's binary_logloss: 0.382124\n",
      "[2307]\ttraining's binary_error: 0.172657\ttraining's binary_logloss: 0.382104\n",
      "[2308]\ttraining's binary_error: 0.172664\ttraining's binary_logloss: 0.382051\n",
      "[2309]\ttraining's binary_error: 0.172623\ttraining's binary_logloss: 0.382032\n",
      "[2310]\ttraining's binary_error: 0.172577\ttraining's binary_logloss: 0.381994\n",
      "[2311]\ttraining's binary_error: 0.172557\ttraining's binary_logloss: 0.38197\n",
      "[2312]\ttraining's binary_error: 0.172532\ttraining's binary_logloss: 0.38195\n",
      "[2313]\ttraining's binary_error: 0.172527\ttraining's binary_logloss: 0.381936\n",
      "[2314]\ttraining's binary_error: 0.172521\ttraining's binary_logloss: 0.38192\n",
      "[2315]\ttraining's binary_error: 0.172485\ttraining's binary_logloss: 0.381903\n",
      "[2316]\ttraining's binary_error: 0.17247\ttraining's binary_logloss: 0.381864\n",
      "[2317]\ttraining's binary_error: 0.172459\ttraining's binary_logloss: 0.381849\n",
      "[2318]\ttraining's binary_error: 0.172357\ttraining's binary_logloss: 0.381729\n",
      "[2319]\ttraining's binary_error: 0.172328\ttraining's binary_logloss: 0.381641\n",
      "[2320]\ttraining's binary_error: 0.17229\ttraining's binary_logloss: 0.381575\n",
      "[2321]\ttraining's binary_error: 0.172291\ttraining's binary_logloss: 0.381553\n",
      "[2322]\ttraining's binary_error: 0.172285\ttraining's binary_logloss: 0.381545\n",
      "[2323]\ttraining's binary_error: 0.172282\ttraining's binary_logloss: 0.381507\n",
      "[2324]\ttraining's binary_error: 0.172264\ttraining's binary_logloss: 0.381491\n",
      "[2325]\ttraining's binary_error: 0.172274\ttraining's binary_logloss: 0.381477\n",
      "[2326]\ttraining's binary_error: 0.172261\ttraining's binary_logloss: 0.381444\n",
      "[2327]\ttraining's binary_error: 0.172253\ttraining's binary_logloss: 0.381429\n",
      "[2328]\ttraining's binary_error: 0.172245\ttraining's binary_logloss: 0.38142\n",
      "[2329]\ttraining's binary_error: 0.172249\ttraining's binary_logloss: 0.381398\n",
      "[2330]\ttraining's binary_error: 0.172259\ttraining's binary_logloss: 0.381383\n",
      "[2331]\ttraining's binary_error: 0.172256\ttraining's binary_logloss: 0.381369\n",
      "[2332]\ttraining's binary_error: 0.172258\ttraining's binary_logloss: 0.381358\n",
      "[2333]\ttraining's binary_error: 0.17225\ttraining's binary_logloss: 0.381349\n",
      "[2334]\ttraining's binary_error: 0.172241\ttraining's binary_logloss: 0.381331\n",
      "[2335]\ttraining's binary_error: 0.172231\ttraining's binary_logloss: 0.381319\n",
      "[2336]\ttraining's binary_error: 0.17221\ttraining's binary_logloss: 0.381261\n",
      "[2337]\ttraining's binary_error: 0.172216\ttraining's binary_logloss: 0.381239\n",
      "[2338]\ttraining's binary_error: 0.172201\ttraining's binary_logloss: 0.381225\n",
      "[2339]\ttraining's binary_error: 0.172197\ttraining's binary_logloss: 0.381214\n",
      "[2340]\ttraining's binary_error: 0.172193\ttraining's binary_logloss: 0.381193\n",
      "[2341]\ttraining's binary_error: 0.172167\ttraining's binary_logloss: 0.381186\n",
      "[2342]\ttraining's binary_error: 0.172168\ttraining's binary_logloss: 0.381169\n",
      "[2343]\ttraining's binary_error: 0.172168\ttraining's binary_logloss: 0.381128\n",
      "[2344]\ttraining's binary_error: 0.172159\ttraining's binary_logloss: 0.381114\n",
      "[2345]\ttraining's binary_error: 0.172151\ttraining's binary_logloss: 0.3811\n",
      "[2346]\ttraining's binary_error: 0.172148\ttraining's binary_logloss: 0.381086\n",
      "[2347]\ttraining's binary_error: 0.172152\ttraining's binary_logloss: 0.381067\n",
      "[2348]\ttraining's binary_error: 0.172132\ttraining's binary_logloss: 0.381048\n",
      "[2349]\ttraining's binary_error: 0.172129\ttraining's binary_logloss: 0.381039\n",
      "[2350]\ttraining's binary_error: 0.172146\ttraining's binary_logloss: 0.381024\n",
      "[2351]\ttraining's binary_error: 0.172132\ttraining's binary_logloss: 0.381009\n",
      "[2352]\ttraining's binary_error: 0.172093\ttraining's binary_logloss: 0.380966\n",
      "[2353]\ttraining's binary_error: 0.172091\ttraining's binary_logloss: 0.380955\n",
      "[2354]\ttraining's binary_error: 0.172027\ttraining's binary_logloss: 0.380911\n",
      "[2355]\ttraining's binary_error: 0.172022\ttraining's binary_logloss: 0.38089\n",
      "[2356]\ttraining's binary_error: 0.172\ttraining's binary_logloss: 0.380871\n",
      "[2357]\ttraining's binary_error: 0.171978\ttraining's binary_logloss: 0.380855\n",
      "[2358]\ttraining's binary_error: 0.171979\ttraining's binary_logloss: 0.380843\n",
      "[2359]\ttraining's binary_error: 0.171925\ttraining's binary_logloss: 0.380798\n",
      "[2360]\ttraining's binary_error: 0.171913\ttraining's binary_logloss: 0.380783\n",
      "[2361]\ttraining's binary_error: 0.171914\ttraining's binary_logloss: 0.380774\n",
      "[2362]\ttraining's binary_error: 0.171914\ttraining's binary_logloss: 0.380757\n",
      "[2363]\ttraining's binary_error: 0.1719\ttraining's binary_logloss: 0.380726\n",
      "[2364]\ttraining's binary_error: 0.171879\ttraining's binary_logloss: 0.380685\n",
      "[2365]\ttraining's binary_error: 0.171828\ttraining's binary_logloss: 0.38065\n",
      "[2366]\ttraining's binary_error: 0.171844\ttraining's binary_logloss: 0.38064\n",
      "[2367]\ttraining's binary_error: 0.171836\ttraining's binary_logloss: 0.380632\n",
      "[2368]\ttraining's binary_error: 0.171833\ttraining's binary_logloss: 0.380622\n",
      "[2369]\ttraining's binary_error: 0.171852\ttraining's binary_logloss: 0.38059\n",
      "[2370]\ttraining's binary_error: 0.171861\ttraining's binary_logloss: 0.380575\n",
      "[2371]\ttraining's binary_error: 0.171831\ttraining's binary_logloss: 0.380558\n",
      "[2372]\ttraining's binary_error: 0.171827\ttraining's binary_logloss: 0.380546\n",
      "[2373]\ttraining's binary_error: 0.171816\ttraining's binary_logloss: 0.380517\n",
      "[2374]\ttraining's binary_error: 0.171803\ttraining's binary_logloss: 0.380503\n",
      "[2375]\ttraining's binary_error: 0.171802\ttraining's binary_logloss: 0.380493\n",
      "[2376]\ttraining's binary_error: 0.171801\ttraining's binary_logloss: 0.380457\n",
      "[2377]\ttraining's binary_error: 0.171772\ttraining's binary_logloss: 0.380403\n",
      "[2378]\ttraining's binary_error: 0.171769\ttraining's binary_logloss: 0.380372\n",
      "[2379]\ttraining's binary_error: 0.171744\ttraining's binary_logloss: 0.380329\n",
      "[2380]\ttraining's binary_error: 0.171736\ttraining's binary_logloss: 0.380305\n",
      "[2381]\ttraining's binary_error: 0.171727\ttraining's binary_logloss: 0.380282\n",
      "[2382]\ttraining's binary_error: 0.171722\ttraining's binary_logloss: 0.380252\n",
      "[2383]\ttraining's binary_error: 0.171714\ttraining's binary_logloss: 0.380226\n",
      "[2384]\ttraining's binary_error: 0.171709\ttraining's binary_logloss: 0.380209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2385]\ttraining's binary_error: 0.171715\ttraining's binary_logloss: 0.380195\n",
      "[2386]\ttraining's binary_error: 0.171699\ttraining's binary_logloss: 0.380163\n",
      "[2387]\ttraining's binary_error: 0.171678\ttraining's binary_logloss: 0.380126\n",
      "[2388]\ttraining's binary_error: 0.171648\ttraining's binary_logloss: 0.380091\n",
      "[2389]\ttraining's binary_error: 0.171643\ttraining's binary_logloss: 0.380074\n",
      "[2390]\ttraining's binary_error: 0.171607\ttraining's binary_logloss: 0.380053\n",
      "[2391]\ttraining's binary_error: 0.171609\ttraining's binary_logloss: 0.380038\n",
      "[2392]\ttraining's binary_error: 0.171583\ttraining's binary_logloss: 0.38002\n",
      "[2393]\ttraining's binary_error: 0.171601\ttraining's binary_logloss: 0.379983\n",
      "[2394]\ttraining's binary_error: 0.171595\ttraining's binary_logloss: 0.37996\n",
      "[2395]\ttraining's binary_error: 0.171562\ttraining's binary_logloss: 0.379933\n",
      "[2396]\ttraining's binary_error: 0.171563\ttraining's binary_logloss: 0.379904\n",
      "[2397]\ttraining's binary_error: 0.171564\ttraining's binary_logloss: 0.379885\n",
      "[2398]\ttraining's binary_error: 0.171551\ttraining's binary_logloss: 0.37987\n",
      "[2399]\ttraining's binary_error: 0.171555\ttraining's binary_logloss: 0.379857\n",
      "[2400]\ttraining's binary_error: 0.171554\ttraining's binary_logloss: 0.379839\n",
      "[2401]\ttraining's binary_error: 0.171572\ttraining's binary_logloss: 0.379799\n",
      "[2402]\ttraining's binary_error: 0.171553\ttraining's binary_logloss: 0.37975\n",
      "[2403]\ttraining's binary_error: 0.171528\ttraining's binary_logloss: 0.379727\n",
      "[2404]\ttraining's binary_error: 0.171508\ttraining's binary_logloss: 0.379689\n",
      "[2405]\ttraining's binary_error: 0.171491\ttraining's binary_logloss: 0.379666\n",
      "[2406]\ttraining's binary_error: 0.171493\ttraining's binary_logloss: 0.379651\n",
      "[2407]\ttraining's binary_error: 0.171476\ttraining's binary_logloss: 0.379603\n",
      "[2408]\ttraining's binary_error: 0.171355\ttraining's binary_logloss: 0.37942\n",
      "[2409]\ttraining's binary_error: 0.171333\ttraining's binary_logloss: 0.379397\n",
      "[2410]\ttraining's binary_error: 0.171304\ttraining's binary_logloss: 0.379326\n",
      "[2411]\ttraining's binary_error: 0.171305\ttraining's binary_logloss: 0.379317\n",
      "[2412]\ttraining's binary_error: 0.171295\ttraining's binary_logloss: 0.379286\n",
      "[2413]\ttraining's binary_error: 0.171286\ttraining's binary_logloss: 0.379276\n",
      "[2414]\ttraining's binary_error: 0.171284\ttraining's binary_logloss: 0.379248\n",
      "[2415]\ttraining's binary_error: 0.171267\ttraining's binary_logloss: 0.379238\n",
      "[2416]\ttraining's binary_error: 0.171284\ttraining's binary_logloss: 0.379186\n",
      "[2417]\ttraining's binary_error: 0.171292\ttraining's binary_logloss: 0.379178\n",
      "[2418]\ttraining's binary_error: 0.171266\ttraining's binary_logloss: 0.379167\n",
      "[2419]\ttraining's binary_error: 0.171238\ttraining's binary_logloss: 0.379153\n",
      "[2420]\ttraining's binary_error: 0.171258\ttraining's binary_logloss: 0.379125\n",
      "[2421]\ttraining's binary_error: 0.171258\ttraining's binary_logloss: 0.379112\n",
      "[2422]\ttraining's binary_error: 0.171242\ttraining's binary_logloss: 0.379101\n",
      "[2423]\ttraining's binary_error: 0.171238\ttraining's binary_logloss: 0.379077\n",
      "[2424]\ttraining's binary_error: 0.171226\ttraining's binary_logloss: 0.379064\n",
      "[2425]\ttraining's binary_error: 0.171206\ttraining's binary_logloss: 0.379055\n",
      "[2426]\ttraining's binary_error: 0.171207\ttraining's binary_logloss: 0.379036\n",
      "[2427]\ttraining's binary_error: 0.171178\ttraining's binary_logloss: 0.378982\n",
      "[2428]\ttraining's binary_error: 0.17118\ttraining's binary_logloss: 0.378933\n",
      "[2429]\ttraining's binary_error: 0.171159\ttraining's binary_logloss: 0.378916\n",
      "[2430]\ttraining's binary_error: 0.171102\ttraining's binary_logloss: 0.378869\n",
      "[2431]\ttraining's binary_error: 0.17109\ttraining's binary_logloss: 0.37886\n",
      "[2432]\ttraining's binary_error: 0.171083\ttraining's binary_logloss: 0.37883\n",
      "[2433]\ttraining's binary_error: 0.171077\ttraining's binary_logloss: 0.378819\n",
      "[2434]\ttraining's binary_error: 0.171057\ttraining's binary_logloss: 0.378807\n",
      "[2435]\ttraining's binary_error: 0.171053\ttraining's binary_logloss: 0.378796\n",
      "[2436]\ttraining's binary_error: 0.171022\ttraining's binary_logloss: 0.378762\n",
      "[2437]\ttraining's binary_error: 0.170991\ttraining's binary_logloss: 0.378735\n",
      "[2438]\ttraining's binary_error: 0.170928\ttraining's binary_logloss: 0.378666\n",
      "[2439]\ttraining's binary_error: 0.170901\ttraining's binary_logloss: 0.378613\n",
      "[2440]\ttraining's binary_error: 0.170895\ttraining's binary_logloss: 0.378597\n",
      "[2441]\ttraining's binary_error: 0.170911\ttraining's binary_logloss: 0.378581\n",
      "[2442]\ttraining's binary_error: 0.170906\ttraining's binary_logloss: 0.378571\n",
      "[2443]\ttraining's binary_error: 0.170895\ttraining's binary_logloss: 0.378552\n",
      "[2444]\ttraining's binary_error: 0.170883\ttraining's binary_logloss: 0.378548\n",
      "[2445]\ttraining's binary_error: 0.170857\ttraining's binary_logloss: 0.378499\n",
      "[2446]\ttraining's binary_error: 0.170847\ttraining's binary_logloss: 0.378489\n",
      "[2447]\ttraining's binary_error: 0.170849\ttraining's binary_logloss: 0.378476\n",
      "[2448]\ttraining's binary_error: 0.170844\ttraining's binary_logloss: 0.378466\n",
      "[2449]\ttraining's binary_error: 0.170835\ttraining's binary_logloss: 0.378452\n",
      "[2450]\ttraining's binary_error: 0.170833\ttraining's binary_logloss: 0.378431\n",
      "[2451]\ttraining's binary_error: 0.170835\ttraining's binary_logloss: 0.378412\n",
      "[2452]\ttraining's binary_error: 0.17079\ttraining's binary_logloss: 0.378348\n",
      "[2453]\ttraining's binary_error: 0.170752\ttraining's binary_logloss: 0.378327\n",
      "[2454]\ttraining's binary_error: 0.170744\ttraining's binary_logloss: 0.378287\n",
      "[2455]\ttraining's binary_error: 0.170749\ttraining's binary_logloss: 0.378233\n",
      "[2456]\ttraining's binary_error: 0.170737\ttraining's binary_logloss: 0.378196\n",
      "[2457]\ttraining's binary_error: 0.170741\ttraining's binary_logloss: 0.378182\n",
      "[2458]\ttraining's binary_error: 0.170734\ttraining's binary_logloss: 0.37817\n",
      "[2459]\ttraining's binary_error: 0.170685\ttraining's binary_logloss: 0.378126\n",
      "[2460]\ttraining's binary_error: 0.170613\ttraining's binary_logloss: 0.378069\n",
      "[2461]\ttraining's binary_error: 0.170562\ttraining's binary_logloss: 0.378018\n",
      "[2462]\ttraining's binary_error: 0.170521\ttraining's binary_logloss: 0.377953\n",
      "[2463]\ttraining's binary_error: 0.170529\ttraining's binary_logloss: 0.377931\n",
      "[2464]\ttraining's binary_error: 0.170514\ttraining's binary_logloss: 0.377866\n",
      "[2465]\ttraining's binary_error: 0.170488\ttraining's binary_logloss: 0.377848\n",
      "[2466]\ttraining's binary_error: 0.170476\ttraining's binary_logloss: 0.377835\n",
      "[2467]\ttraining's binary_error: 0.170455\ttraining's binary_logloss: 0.37781\n",
      "[2468]\ttraining's binary_error: 0.170409\ttraining's binary_logloss: 0.377743\n",
      "[2469]\ttraining's binary_error: 0.170397\ttraining's binary_logloss: 0.377731\n",
      "[2470]\ttraining's binary_error: 0.170416\ttraining's binary_logloss: 0.377716\n",
      "[2471]\ttraining's binary_error: 0.170409\ttraining's binary_logloss: 0.377703\n",
      "[2472]\ttraining's binary_error: 0.170401\ttraining's binary_logloss: 0.377683\n",
      "[2473]\ttraining's binary_error: 0.170401\ttraining's binary_logloss: 0.377662\n",
      "[2474]\ttraining's binary_error: 0.170402\ttraining's binary_logloss: 0.377638\n",
      "[2475]\ttraining's binary_error: 0.170379\ttraining's binary_logloss: 0.377611\n",
      "[2476]\ttraining's binary_error: 0.170355\ttraining's binary_logloss: 0.377567\n",
      "[2477]\ttraining's binary_error: 0.170313\ttraining's binary_logloss: 0.377547\n",
      "[2478]\ttraining's binary_error: 0.170297\ttraining's binary_logloss: 0.377531\n",
      "[2479]\ttraining's binary_error: 0.170303\ttraining's binary_logloss: 0.377523\n",
      "[2480]\ttraining's binary_error: 0.170295\ttraining's binary_logloss: 0.377513\n",
      "[2481]\ttraining's binary_error: 0.170297\ttraining's binary_logloss: 0.377504\n",
      "[2482]\ttraining's binary_error: 0.170297\ttraining's binary_logloss: 0.377493\n",
      "[2483]\ttraining's binary_error: 0.170275\ttraining's binary_logloss: 0.377467\n",
      "[2484]\ttraining's binary_error: 0.170214\ttraining's binary_logloss: 0.377402\n",
      "[2485]\ttraining's binary_error: 0.170176\ttraining's binary_logloss: 0.377366\n",
      "[2486]\ttraining's binary_error: 0.17017\ttraining's binary_logloss: 0.377355\n",
      "[2487]\ttraining's binary_error: 0.170152\ttraining's binary_logloss: 0.377333\n",
      "[2488]\ttraining's binary_error: 0.17011\ttraining's binary_logloss: 0.377273\n",
      "[2489]\ttraining's binary_error: 0.170082\ttraining's binary_logloss: 0.377243\n",
      "[2490]\ttraining's binary_error: 0.170069\ttraining's binary_logloss: 0.37721\n",
      "[2491]\ttraining's binary_error: 0.170044\ttraining's binary_logloss: 0.377173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2492]\ttraining's binary_error: 0.170043\ttraining's binary_logloss: 0.377152\n",
      "[2493]\ttraining's binary_error: 0.170035\ttraining's binary_logloss: 0.37714\n",
      "[2494]\ttraining's binary_error: 0.170004\ttraining's binary_logloss: 0.377114\n",
      "[2495]\ttraining's binary_error: 0.169996\ttraining's binary_logloss: 0.377108\n",
      "[2496]\ttraining's binary_error: 0.169989\ttraining's binary_logloss: 0.377094\n",
      "[2497]\ttraining's binary_error: 0.169983\ttraining's binary_logloss: 0.37707\n",
      "[2498]\ttraining's binary_error: 0.169973\ttraining's binary_logloss: 0.377064\n",
      "[2499]\ttraining's binary_error: 0.169957\ttraining's binary_logloss: 0.377053\n",
      "[2500]\ttraining's binary_error: 0.169934\ttraining's binary_logloss: 0.37704\n",
      "[2501]\ttraining's binary_error: 0.1699\ttraining's binary_logloss: 0.377\n",
      "[2502]\ttraining's binary_error: 0.16989\ttraining's binary_logloss: 0.376988\n",
      "[2503]\ttraining's binary_error: 0.169809\ttraining's binary_logloss: 0.37688\n",
      "[2504]\ttraining's binary_error: 0.169795\ttraining's binary_logloss: 0.376833\n",
      "[2505]\ttraining's binary_error: 0.169773\ttraining's binary_logloss: 0.376822\n",
      "[2506]\ttraining's binary_error: 0.169749\ttraining's binary_logloss: 0.376784\n",
      "[2507]\ttraining's binary_error: 0.169698\ttraining's binary_logloss: 0.376726\n",
      "[2508]\ttraining's binary_error: 0.169696\ttraining's binary_logloss: 0.376712\n",
      "[2509]\ttraining's binary_error: 0.169656\ttraining's binary_logloss: 0.376684\n",
      "[2510]\ttraining's binary_error: 0.169642\ttraining's binary_logloss: 0.376667\n",
      "[2511]\ttraining's binary_error: 0.169629\ttraining's binary_logloss: 0.376646\n",
      "[2512]\ttraining's binary_error: 0.169605\ttraining's binary_logloss: 0.376584\n",
      "[2513]\ttraining's binary_error: 0.169541\ttraining's binary_logloss: 0.376518\n",
      "[2514]\ttraining's binary_error: 0.169534\ttraining's binary_logloss: 0.376483\n",
      "[2515]\ttraining's binary_error: 0.169482\ttraining's binary_logloss: 0.376451\n",
      "[2516]\ttraining's binary_error: 0.169469\ttraining's binary_logloss: 0.376429\n",
      "[2517]\ttraining's binary_error: 0.169456\ttraining's binary_logloss: 0.37638\n",
      "[2518]\ttraining's binary_error: 0.169414\ttraining's binary_logloss: 0.376332\n",
      "[2519]\ttraining's binary_error: 0.169409\ttraining's binary_logloss: 0.376312\n",
      "[2520]\ttraining's binary_error: 0.169397\ttraining's binary_logloss: 0.376255\n",
      "[2521]\ttraining's binary_error: 0.169385\ttraining's binary_logloss: 0.376242\n",
      "[2522]\ttraining's binary_error: 0.16937\ttraining's binary_logloss: 0.376215\n",
      "[2523]\ttraining's binary_error: 0.169355\ttraining's binary_logloss: 0.376186\n",
      "[2524]\ttraining's binary_error: 0.169359\ttraining's binary_logloss: 0.376179\n",
      "[2525]\ttraining's binary_error: 0.169353\ttraining's binary_logloss: 0.376143\n",
      "[2526]\ttraining's binary_error: 0.169343\ttraining's binary_logloss: 0.376135\n",
      "[2527]\ttraining's binary_error: 0.169342\ttraining's binary_logloss: 0.376124\n",
      "[2528]\ttraining's binary_error: 0.169328\ttraining's binary_logloss: 0.376113\n",
      "[2529]\ttraining's binary_error: 0.169324\ttraining's binary_logloss: 0.3761\n",
      "[2530]\ttraining's binary_error: 0.169301\ttraining's binary_logloss: 0.376079\n",
      "[2531]\ttraining's binary_error: 0.169309\ttraining's binary_logloss: 0.376061\n",
      "[2532]\ttraining's binary_error: 0.169275\ttraining's binary_logloss: 0.376029\n",
      "[2533]\ttraining's binary_error: 0.169249\ttraining's binary_logloss: 0.375996\n",
      "[2534]\ttraining's binary_error: 0.16924\ttraining's binary_logloss: 0.375986\n",
      "[2535]\ttraining's binary_error: 0.169234\ttraining's binary_logloss: 0.375971\n",
      "[2536]\ttraining's binary_error: 0.169241\ttraining's binary_logloss: 0.375955\n",
      "[2537]\ttraining's binary_error: 0.169186\ttraining's binary_logloss: 0.375901\n",
      "[2538]\ttraining's binary_error: 0.169143\ttraining's binary_logloss: 0.375842\n",
      "[2539]\ttraining's binary_error: 0.169127\ttraining's binary_logloss: 0.375769\n",
      "[2540]\ttraining's binary_error: 0.169129\ttraining's binary_logloss: 0.375753\n",
      "[2541]\ttraining's binary_error: 0.16911\ttraining's binary_logloss: 0.375743\n",
      "[2542]\ttraining's binary_error: 0.169104\ttraining's binary_logloss: 0.375736\n",
      "[2543]\ttraining's binary_error: 0.169081\ttraining's binary_logloss: 0.375703\n",
      "[2544]\ttraining's binary_error: 0.169058\ttraining's binary_logloss: 0.375675\n",
      "[2545]\ttraining's binary_error: 0.16905\ttraining's binary_logloss: 0.375658\n",
      "[2546]\ttraining's binary_error: 0.169051\ttraining's binary_logloss: 0.375648\n",
      "[2547]\ttraining's binary_error: 0.169041\ttraining's binary_logloss: 0.375625\n",
      "[2548]\ttraining's binary_error: 0.169039\ttraining's binary_logloss: 0.375612\n",
      "[2549]\ttraining's binary_error: 0.16903\ttraining's binary_logloss: 0.375604\n",
      "[2550]\ttraining's binary_error: 0.169019\ttraining's binary_logloss: 0.375595\n",
      "[2551]\ttraining's binary_error: 0.169029\ttraining's binary_logloss: 0.375575\n",
      "[2552]\ttraining's binary_error: 0.168984\ttraining's binary_logloss: 0.375553\n",
      "[2553]\ttraining's binary_error: 0.16897\ttraining's binary_logloss: 0.37551\n",
      "[2554]\ttraining's binary_error: 0.168969\ttraining's binary_logloss: 0.3755\n",
      "[2555]\ttraining's binary_error: 0.168981\ttraining's binary_logloss: 0.375489\n",
      "[2556]\ttraining's binary_error: 0.168951\ttraining's binary_logloss: 0.37547\n",
      "[2557]\ttraining's binary_error: 0.168967\ttraining's binary_logloss: 0.375442\n",
      "[2558]\ttraining's binary_error: 0.168957\ttraining's binary_logloss: 0.375419\n",
      "[2559]\ttraining's binary_error: 0.168958\ttraining's binary_logloss: 0.375404\n",
      "[2560]\ttraining's binary_error: 0.16895\ttraining's binary_logloss: 0.375393\n",
      "[2561]\ttraining's binary_error: 0.168953\ttraining's binary_logloss: 0.375383\n",
      "[2562]\ttraining's binary_error: 0.168951\ttraining's binary_logloss: 0.375359\n",
      "[2563]\ttraining's binary_error: 0.168941\ttraining's binary_logloss: 0.375308\n",
      "[2564]\ttraining's binary_error: 0.168923\ttraining's binary_logloss: 0.375297\n",
      "[2565]\ttraining's binary_error: 0.168889\ttraining's binary_logloss: 0.375255\n",
      "[2566]\ttraining's binary_error: 0.168886\ttraining's binary_logloss: 0.375234\n",
      "[2567]\ttraining's binary_error: 0.168807\ttraining's binary_logloss: 0.375178\n",
      "[2568]\ttraining's binary_error: 0.168804\ttraining's binary_logloss: 0.375165\n",
      "[2569]\ttraining's binary_error: 0.1688\ttraining's binary_logloss: 0.37515\n",
      "[2570]\ttraining's binary_error: 0.168796\ttraining's binary_logloss: 0.375113\n",
      "[2571]\ttraining's binary_error: 0.168766\ttraining's binary_logloss: 0.375098\n",
      "[2572]\ttraining's binary_error: 0.16879\ttraining's binary_logloss: 0.375066\n",
      "[2573]\ttraining's binary_error: 0.16879\ttraining's binary_logloss: 0.375058\n",
      "[2574]\ttraining's binary_error: 0.168782\ttraining's binary_logloss: 0.375045\n",
      "[2575]\ttraining's binary_error: 0.168807\ttraining's binary_logloss: 0.375027\n",
      "[2576]\ttraining's binary_error: 0.168805\ttraining's binary_logloss: 0.375013\n",
      "[2577]\ttraining's binary_error: 0.168804\ttraining's binary_logloss: 0.37497\n",
      "[2578]\ttraining's binary_error: 0.168778\ttraining's binary_logloss: 0.374932\n",
      "[2579]\ttraining's binary_error: 0.168764\ttraining's binary_logloss: 0.374907\n",
      "[2580]\ttraining's binary_error: 0.168775\ttraining's binary_logloss: 0.374895\n",
      "[2581]\ttraining's binary_error: 0.16877\ttraining's binary_logloss: 0.374883\n",
      "[2582]\ttraining's binary_error: 0.168785\ttraining's binary_logloss: 0.374872\n",
      "[2583]\ttraining's binary_error: 0.16877\ttraining's binary_logloss: 0.37485\n",
      "[2584]\ttraining's binary_error: 0.168734\ttraining's binary_logloss: 0.374803\n",
      "[2585]\ttraining's binary_error: 0.16872\ttraining's binary_logloss: 0.374778\n",
      "[2586]\ttraining's binary_error: 0.168714\ttraining's binary_logloss: 0.374756\n",
      "[2587]\ttraining's binary_error: 0.168705\ttraining's binary_logloss: 0.374743\n",
      "[2588]\ttraining's binary_error: 0.168695\ttraining's binary_logloss: 0.374732\n",
      "[2589]\ttraining's binary_error: 0.168557\ttraining's binary_logloss: 0.374573\n",
      "[2590]\ttraining's binary_error: 0.16856\ttraining's binary_logloss: 0.374551\n",
      "[2591]\ttraining's binary_error: 0.168557\ttraining's binary_logloss: 0.374509\n",
      "[2592]\ttraining's binary_error: 0.168517\ttraining's binary_logloss: 0.374488\n",
      "[2593]\ttraining's binary_error: 0.168487\ttraining's binary_logloss: 0.374439\n",
      "[2594]\ttraining's binary_error: 0.168478\ttraining's binary_logloss: 0.374405\n",
      "[2595]\ttraining's binary_error: 0.16847\ttraining's binary_logloss: 0.37439\n",
      "[2596]\ttraining's binary_error: 0.168456\ttraining's binary_logloss: 0.374367\n",
      "[2597]\ttraining's binary_error: 0.168462\ttraining's binary_logloss: 0.374355\n",
      "[2598]\ttraining's binary_error: 0.168443\ttraining's binary_logloss: 0.374339\n",
      "[2599]\ttraining's binary_error: 0.168438\ttraining's binary_logloss: 0.374329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2600]\ttraining's binary_error: 0.168394\ttraining's binary_logloss: 0.374301\n",
      "[2601]\ttraining's binary_error: 0.168378\ttraining's binary_logloss: 0.374284\n",
      "[2602]\ttraining's binary_error: 0.168372\ttraining's binary_logloss: 0.374271\n",
      "[2603]\ttraining's binary_error: 0.168376\ttraining's binary_logloss: 0.374257\n",
      "[2604]\ttraining's binary_error: 0.16828\ttraining's binary_logloss: 0.374151\n",
      "[2605]\ttraining's binary_error: 0.168284\ttraining's binary_logloss: 0.374106\n",
      "[2606]\ttraining's binary_error: 0.168255\ttraining's binary_logloss: 0.37408\n",
      "[2607]\ttraining's binary_error: 0.168245\ttraining's binary_logloss: 0.374045\n",
      "[2608]\ttraining's binary_error: 0.168243\ttraining's binary_logloss: 0.374029\n",
      "[2609]\ttraining's binary_error: 0.168197\ttraining's binary_logloss: 0.374003\n",
      "[2610]\ttraining's binary_error: 0.168194\ttraining's binary_logloss: 0.373994\n",
      "[2611]\ttraining's binary_error: 0.168201\ttraining's binary_logloss: 0.373974\n",
      "[2612]\ttraining's binary_error: 0.168195\ttraining's binary_logloss: 0.37396\n",
      "[2613]\ttraining's binary_error: 0.168183\ttraining's binary_logloss: 0.373947\n",
      "[2614]\ttraining's binary_error: 0.168179\ttraining's binary_logloss: 0.373938\n",
      "[2615]\ttraining's binary_error: 0.168155\ttraining's binary_logloss: 0.373904\n",
      "[2616]\ttraining's binary_error: 0.168123\ttraining's binary_logloss: 0.373874\n",
      "[2617]\ttraining's binary_error: 0.168119\ttraining's binary_logloss: 0.373827\n",
      "[2618]\ttraining's binary_error: 0.168088\ttraining's binary_logloss: 0.373797\n",
      "[2619]\ttraining's binary_error: 0.168079\ttraining's binary_logloss: 0.373766\n",
      "[2620]\ttraining's binary_error: 0.168065\ttraining's binary_logloss: 0.373747\n",
      "[2621]\ttraining's binary_error: 0.168059\ttraining's binary_logloss: 0.373723\n",
      "[2622]\ttraining's binary_error: 0.168008\ttraining's binary_logloss: 0.373675\n",
      "[2623]\ttraining's binary_error: 0.168014\ttraining's binary_logloss: 0.373635\n",
      "[2624]\ttraining's binary_error: 0.16799\ttraining's binary_logloss: 0.373602\n",
      "[2625]\ttraining's binary_error: 0.167992\ttraining's binary_logloss: 0.373595\n",
      "[2626]\ttraining's binary_error: 0.167993\ttraining's binary_logloss: 0.373576\n",
      "[2627]\ttraining's binary_error: 0.167999\ttraining's binary_logloss: 0.37355\n",
      "[2628]\ttraining's binary_error: 0.167939\ttraining's binary_logloss: 0.37348\n",
      "[2629]\ttraining's binary_error: 0.1679\ttraining's binary_logloss: 0.373452\n",
      "[2630]\ttraining's binary_error: 0.167868\ttraining's binary_logloss: 0.373423\n",
      "[2631]\ttraining's binary_error: 0.16784\ttraining's binary_logloss: 0.373404\n",
      "[2632]\ttraining's binary_error: 0.167851\ttraining's binary_logloss: 0.373393\n",
      "[2633]\ttraining's binary_error: 0.16785\ttraining's binary_logloss: 0.373374\n",
      "[2634]\ttraining's binary_error: 0.167833\ttraining's binary_logloss: 0.373346\n",
      "[2635]\ttraining's binary_error: 0.167827\ttraining's binary_logloss: 0.373319\n",
      "[2636]\ttraining's binary_error: 0.167792\ttraining's binary_logloss: 0.373286\n",
      "[2637]\ttraining's binary_error: 0.16776\ttraining's binary_logloss: 0.373254\n",
      "[2638]\ttraining's binary_error: 0.167747\ttraining's binary_logloss: 0.373243\n",
      "[2639]\ttraining's binary_error: 0.167764\ttraining's binary_logloss: 0.37323\n",
      "[2640]\ttraining's binary_error: 0.167745\ttraining's binary_logloss: 0.373204\n",
      "[2641]\ttraining's binary_error: 0.167737\ttraining's binary_logloss: 0.373195\n",
      "[2642]\ttraining's binary_error: 0.167734\ttraining's binary_logloss: 0.373184\n",
      "[2643]\ttraining's binary_error: 0.16772\ttraining's binary_logloss: 0.373174\n",
      "[2644]\ttraining's binary_error: 0.167759\ttraining's binary_logloss: 0.373148\n",
      "[2645]\ttraining's binary_error: 0.167751\ttraining's binary_logloss: 0.373138\n",
      "[2646]\ttraining's binary_error: 0.167736\ttraining's binary_logloss: 0.373129\n",
      "[2647]\ttraining's binary_error: 0.167728\ttraining's binary_logloss: 0.373107\n",
      "[2648]\ttraining's binary_error: 0.167701\ttraining's binary_logloss: 0.373077\n",
      "[2649]\ttraining's binary_error: 0.167675\ttraining's binary_logloss: 0.373045\n",
      "[2650]\ttraining's binary_error: 0.167679\ttraining's binary_logloss: 0.373026\n",
      "[2651]\ttraining's binary_error: 0.16766\ttraining's binary_logloss: 0.373009\n",
      "[2652]\ttraining's binary_error: 0.16765\ttraining's binary_logloss: 0.372998\n",
      "[2653]\ttraining's binary_error: 0.167619\ttraining's binary_logloss: 0.372941\n",
      "[2654]\ttraining's binary_error: 0.167615\ttraining's binary_logloss: 0.372926\n",
      "[2655]\ttraining's binary_error: 0.167634\ttraining's binary_logloss: 0.372914\n",
      "[2656]\ttraining's binary_error: 0.167632\ttraining's binary_logloss: 0.372903\n",
      "[2657]\ttraining's binary_error: 0.167596\ttraining's binary_logloss: 0.372858\n",
      "[2658]\ttraining's binary_error: 0.16757\ttraining's binary_logloss: 0.37281\n",
      "[2659]\ttraining's binary_error: 0.16754\ttraining's binary_logloss: 0.372774\n",
      "[2660]\ttraining's binary_error: 0.167549\ttraining's binary_logloss: 0.372766\n",
      "[2661]\ttraining's binary_error: 0.16754\ttraining's binary_logloss: 0.372754\n",
      "[2662]\ttraining's binary_error: 0.167543\ttraining's binary_logloss: 0.372738\n",
      "[2663]\ttraining's binary_error: 0.167527\ttraining's binary_logloss: 0.372718\n",
      "[2664]\ttraining's binary_error: 0.167505\ttraining's binary_logloss: 0.372672\n",
      "[2665]\ttraining's binary_error: 0.167502\ttraining's binary_logloss: 0.372661\n",
      "[2666]\ttraining's binary_error: 0.16749\ttraining's binary_logloss: 0.372643\n",
      "[2667]\ttraining's binary_error: 0.167484\ttraining's binary_logloss: 0.372634\n",
      "[2668]\ttraining's binary_error: 0.167439\ttraining's binary_logloss: 0.372576\n",
      "[2669]\ttraining's binary_error: 0.167365\ttraining's binary_logloss: 0.372534\n",
      "[2670]\ttraining's binary_error: 0.167326\ttraining's binary_logloss: 0.372455\n",
      "[2671]\ttraining's binary_error: 0.167338\ttraining's binary_logloss: 0.372439\n",
      "[2672]\ttraining's binary_error: 0.167296\ttraining's binary_logloss: 0.372377\n",
      "[2673]\ttraining's binary_error: 0.167251\ttraining's binary_logloss: 0.372336\n",
      "[2674]\ttraining's binary_error: 0.167228\ttraining's binary_logloss: 0.372298\n",
      "[2675]\ttraining's binary_error: 0.16723\ttraining's binary_logloss: 0.372263\n",
      "[2676]\ttraining's binary_error: 0.167228\ttraining's binary_logloss: 0.372243\n",
      "[2677]\ttraining's binary_error: 0.167204\ttraining's binary_logloss: 0.372196\n",
      "[2678]\ttraining's binary_error: 0.167196\ttraining's binary_logloss: 0.372182\n",
      "[2679]\ttraining's binary_error: 0.167189\ttraining's binary_logloss: 0.372172\n",
      "[2680]\ttraining's binary_error: 0.167161\ttraining's binary_logloss: 0.372145\n",
      "[2681]\ttraining's binary_error: 0.167156\ttraining's binary_logloss: 0.372132\n",
      "[2682]\ttraining's binary_error: 0.167136\ttraining's binary_logloss: 0.372095\n",
      "[2683]\ttraining's binary_error: 0.16712\ttraining's binary_logloss: 0.372073\n",
      "[2684]\ttraining's binary_error: 0.167121\ttraining's binary_logloss: 0.372059\n",
      "[2685]\ttraining's binary_error: 0.167102\ttraining's binary_logloss: 0.37204\n",
      "[2686]\ttraining's binary_error: 0.167075\ttraining's binary_logloss: 0.372029\n",
      "[2687]\ttraining's binary_error: 0.167095\ttraining's binary_logloss: 0.371996\n",
      "[2688]\ttraining's binary_error: 0.167076\ttraining's binary_logloss: 0.371979\n",
      "[2689]\ttraining's binary_error: 0.16708\ttraining's binary_logloss: 0.371947\n",
      "[2690]\ttraining's binary_error: 0.167102\ttraining's binary_logloss: 0.371931\n",
      "[2691]\ttraining's binary_error: 0.167064\ttraining's binary_logloss: 0.371921\n",
      "[2692]\ttraining's binary_error: 0.167056\ttraining's binary_logloss: 0.37188\n",
      "[2693]\ttraining's binary_error: 0.167067\ttraining's binary_logloss: 0.371869\n",
      "[2694]\ttraining's binary_error: 0.167054\ttraining's binary_logloss: 0.371854\n",
      "[2695]\ttraining's binary_error: 0.167057\ttraining's binary_logloss: 0.371841\n",
      "[2696]\ttraining's binary_error: 0.167055\ttraining's binary_logloss: 0.371833\n",
      "[2697]\ttraining's binary_error: 0.167041\ttraining's binary_logloss: 0.371797\n",
      "[2698]\ttraining's binary_error: 0.167028\ttraining's binary_logloss: 0.371784\n",
      "[2699]\ttraining's binary_error: 0.167013\ttraining's binary_logloss: 0.371768\n",
      "[2700]\ttraining's binary_error: 0.167012\ttraining's binary_logloss: 0.371758\n",
      "[2701]\ttraining's binary_error: 0.166985\ttraining's binary_logloss: 0.371699\n",
      "[2702]\ttraining's binary_error: 0.166978\ttraining's binary_logloss: 0.371655\n",
      "[2703]\ttraining's binary_error: 0.166934\ttraining's binary_logloss: 0.37162\n",
      "[2704]\ttraining's binary_error: 0.166921\ttraining's binary_logloss: 0.371608\n",
      "[2705]\ttraining's binary_error: 0.166922\ttraining's binary_logloss: 0.371593\n",
      "[2706]\ttraining's binary_error: 0.166888\ttraining's binary_logloss: 0.371576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2707]\ttraining's binary_error: 0.166807\ttraining's binary_logloss: 0.371516\n",
      "[2708]\ttraining's binary_error: 0.166806\ttraining's binary_logloss: 0.371487\n",
      "[2709]\ttraining's binary_error: 0.166779\ttraining's binary_logloss: 0.371454\n",
      "[2710]\ttraining's binary_error: 0.166767\ttraining's binary_logloss: 0.371414\n",
      "[2711]\ttraining's binary_error: 0.166744\ttraining's binary_logloss: 0.371371\n",
      "[2712]\ttraining's binary_error: 0.166724\ttraining's binary_logloss: 0.371343\n",
      "[2713]\ttraining's binary_error: 0.166718\ttraining's binary_logloss: 0.371314\n",
      "[2714]\ttraining's binary_error: 0.166733\ttraining's binary_logloss: 0.371302\n",
      "[2715]\ttraining's binary_error: 0.166718\ttraining's binary_logloss: 0.371274\n",
      "[2716]\ttraining's binary_error: 0.166679\ttraining's binary_logloss: 0.371257\n",
      "[2717]\ttraining's binary_error: 0.166667\ttraining's binary_logloss: 0.371244\n",
      "[2718]\ttraining's binary_error: 0.166675\ttraining's binary_logloss: 0.371221\n",
      "[2719]\ttraining's binary_error: 0.166653\ttraining's binary_logloss: 0.371185\n",
      "[2720]\ttraining's binary_error: 0.166594\ttraining's binary_logloss: 0.371155\n",
      "[2721]\ttraining's binary_error: 0.1666\ttraining's binary_logloss: 0.371144\n",
      "[2722]\ttraining's binary_error: 0.166591\ttraining's binary_logloss: 0.371115\n",
      "[2723]\ttraining's binary_error: 0.166579\ttraining's binary_logloss: 0.371107\n",
      "[2724]\ttraining's binary_error: 0.16657\ttraining's binary_logloss: 0.371091\n",
      "[2725]\ttraining's binary_error: 0.166559\ttraining's binary_logloss: 0.37105\n",
      "[2726]\ttraining's binary_error: 0.16655\ttraining's binary_logloss: 0.37102\n",
      "[2727]\ttraining's binary_error: 0.166523\ttraining's binary_logloss: 0.371007\n",
      "[2728]\ttraining's binary_error: 0.166521\ttraining's binary_logloss: 0.370994\n",
      "[2729]\ttraining's binary_error: 0.166475\ttraining's binary_logloss: 0.370947\n",
      "[2730]\ttraining's binary_error: 0.166461\ttraining's binary_logloss: 0.37092\n",
      "[2731]\ttraining's binary_error: 0.166461\ttraining's binary_logloss: 0.370911\n",
      "[2732]\ttraining's binary_error: 0.166405\ttraining's binary_logloss: 0.370894\n",
      "[2733]\ttraining's binary_error: 0.166391\ttraining's binary_logloss: 0.370863\n",
      "[2734]\ttraining's binary_error: 0.166379\ttraining's binary_logloss: 0.370853\n",
      "[2735]\ttraining's binary_error: 0.166359\ttraining's binary_logloss: 0.370807\n",
      "[2736]\ttraining's binary_error: 0.166342\ttraining's binary_logloss: 0.370795\n",
      "[2737]\ttraining's binary_error: 0.166333\ttraining's binary_logloss: 0.370752\n",
      "[2738]\ttraining's binary_error: 0.166284\ttraining's binary_logloss: 0.370671\n",
      "[2739]\ttraining's binary_error: 0.166267\ttraining's binary_logloss: 0.370637\n",
      "[2740]\ttraining's binary_error: 0.166248\ttraining's binary_logloss: 0.370597\n",
      "[2741]\ttraining's binary_error: 0.166257\ttraining's binary_logloss: 0.370574\n",
      "[2742]\ttraining's binary_error: 0.166242\ttraining's binary_logloss: 0.370564\n",
      "[2743]\ttraining's binary_error: 0.16624\ttraining's binary_logloss: 0.370539\n",
      "[2744]\ttraining's binary_error: 0.166257\ttraining's binary_logloss: 0.370508\n",
      "[2745]\ttraining's binary_error: 0.166227\ttraining's binary_logloss: 0.370484\n",
      "[2746]\ttraining's binary_error: 0.166232\ttraining's binary_logloss: 0.370471\n",
      "[2747]\ttraining's binary_error: 0.166188\ttraining's binary_logloss: 0.37041\n",
      "[2748]\ttraining's binary_error: 0.166177\ttraining's binary_logloss: 0.370393\n",
      "[2749]\ttraining's binary_error: 0.16618\ttraining's binary_logloss: 0.370335\n",
      "[2750]\ttraining's binary_error: 0.166166\ttraining's binary_logloss: 0.370322\n",
      "[2751]\ttraining's binary_error: 0.16615\ttraining's binary_logloss: 0.370311\n",
      "[2752]\ttraining's binary_error: 0.166126\ttraining's binary_logloss: 0.370274\n",
      "[2753]\ttraining's binary_error: 0.166128\ttraining's binary_logloss: 0.370255\n",
      "[2754]\ttraining's binary_error: 0.166104\ttraining's binary_logloss: 0.370242\n",
      "[2755]\ttraining's binary_error: 0.16608\ttraining's binary_logloss: 0.370227\n",
      "[2756]\ttraining's binary_error: 0.166051\ttraining's binary_logloss: 0.370177\n",
      "[2757]\ttraining's binary_error: 0.166068\ttraining's binary_logloss: 0.370138\n",
      "[2758]\ttraining's binary_error: 0.166047\ttraining's binary_logloss: 0.370084\n",
      "[2759]\ttraining's binary_error: 0.166003\ttraining's binary_logloss: 0.370036\n",
      "[2760]\ttraining's binary_error: 0.165969\ttraining's binary_logloss: 0.369998\n",
      "[2761]\ttraining's binary_error: 0.165957\ttraining's binary_logloss: 0.3699\n",
      "[2762]\ttraining's binary_error: 0.165952\ttraining's binary_logloss: 0.369891\n",
      "[2763]\ttraining's binary_error: 0.165971\ttraining's binary_logloss: 0.369877\n",
      "[2764]\ttraining's binary_error: 0.165897\ttraining's binary_logloss: 0.369811\n",
      "[2765]\ttraining's binary_error: 0.165877\ttraining's binary_logloss: 0.369792\n",
      "[2766]\ttraining's binary_error: 0.1659\ttraining's binary_logloss: 0.369757\n",
      "[2767]\ttraining's binary_error: 0.165865\ttraining's binary_logloss: 0.369715\n",
      "[2768]\ttraining's binary_error: 0.165865\ttraining's binary_logloss: 0.369707\n",
      "[2769]\ttraining's binary_error: 0.16586\ttraining's binary_logloss: 0.369692\n",
      "[2770]\ttraining's binary_error: 0.165855\ttraining's binary_logloss: 0.369683\n",
      "[2771]\ttraining's binary_error: 0.165847\ttraining's binary_logloss: 0.369676\n",
      "[2772]\ttraining's binary_error: 0.165809\ttraining's binary_logloss: 0.369639\n",
      "[2773]\ttraining's binary_error: 0.165786\ttraining's binary_logloss: 0.369624\n",
      "[2774]\ttraining's binary_error: 0.165767\ttraining's binary_logloss: 0.369589\n",
      "[2775]\ttraining's binary_error: 0.165733\ttraining's binary_logloss: 0.36954\n",
      "[2776]\ttraining's binary_error: 0.165731\ttraining's binary_logloss: 0.369518\n",
      "[2777]\ttraining's binary_error: 0.16572\ttraining's binary_logloss: 0.369509\n",
      "[2778]\ttraining's binary_error: 0.16572\ttraining's binary_logloss: 0.369497\n",
      "[2779]\ttraining's binary_error: 0.165741\ttraining's binary_logloss: 0.369479\n",
      "[2780]\ttraining's binary_error: 0.165726\ttraining's binary_logloss: 0.369465\n",
      "[2781]\ttraining's binary_error: 0.165726\ttraining's binary_logloss: 0.369455\n",
      "[2782]\ttraining's binary_error: 0.165682\ttraining's binary_logloss: 0.369408\n",
      "[2783]\ttraining's binary_error: 0.165659\ttraining's binary_logloss: 0.369361\n",
      "[2784]\ttraining's binary_error: 0.165667\ttraining's binary_logloss: 0.369333\n",
      "[2785]\ttraining's binary_error: 0.165653\ttraining's binary_logloss: 0.369286\n",
      "[2786]\ttraining's binary_error: 0.165649\ttraining's binary_logloss: 0.369275\n",
      "[2787]\ttraining's binary_error: 0.165625\ttraining's binary_logloss: 0.369251\n",
      "[2788]\ttraining's binary_error: 0.165604\ttraining's binary_logloss: 0.369217\n",
      "[2789]\ttraining's binary_error: 0.165601\ttraining's binary_logloss: 0.369189\n",
      "[2790]\ttraining's binary_error: 0.165587\ttraining's binary_logloss: 0.369173\n",
      "[2791]\ttraining's binary_error: 0.165578\ttraining's binary_logloss: 0.369146\n",
      "[2792]\ttraining's binary_error: 0.16552\ttraining's binary_logloss: 0.369076\n",
      "[2793]\ttraining's binary_error: 0.165514\ttraining's binary_logloss: 0.369058\n",
      "[2794]\ttraining's binary_error: 0.165491\ttraining's binary_logloss: 0.369033\n",
      "[2795]\ttraining's binary_error: 0.16539\ttraining's binary_logloss: 0.369005\n",
      "[2796]\ttraining's binary_error: 0.165335\ttraining's binary_logloss: 0.368961\n",
      "[2797]\ttraining's binary_error: 0.165222\ttraining's binary_logloss: 0.368835\n",
      "[2798]\ttraining's binary_error: 0.165187\ttraining's binary_logloss: 0.368793\n",
      "[2799]\ttraining's binary_error: 0.165183\ttraining's binary_logloss: 0.368781\n",
      "[2800]\ttraining's binary_error: 0.165147\ttraining's binary_logloss: 0.368707\n",
      "[2801]\ttraining's binary_error: 0.165135\ttraining's binary_logloss: 0.368685\n",
      "[2802]\ttraining's binary_error: 0.165121\ttraining's binary_logloss: 0.368644\n",
      "[2803]\ttraining's binary_error: 0.165112\ttraining's binary_logloss: 0.368626\n",
      "[2804]\ttraining's binary_error: 0.1651\ttraining's binary_logloss: 0.368611\n",
      "[2805]\ttraining's binary_error: 0.165066\ttraining's binary_logloss: 0.368577\n",
      "[2806]\ttraining's binary_error: 0.165057\ttraining's binary_logloss: 0.368558\n",
      "[2807]\ttraining's binary_error: 0.165047\ttraining's binary_logloss: 0.368545\n",
      "[2808]\ttraining's binary_error: 0.165061\ttraining's binary_logloss: 0.368521\n",
      "[2809]\ttraining's binary_error: 0.165042\ttraining's binary_logloss: 0.368506\n",
      "[2810]\ttraining's binary_error: 0.16504\ttraining's binary_logloss: 0.36849\n",
      "[2811]\ttraining's binary_error: 0.165015\ttraining's binary_logloss: 0.368473\n",
      "[2812]\ttraining's binary_error: 0.16502\ttraining's binary_logloss: 0.368455\n",
      "[2813]\ttraining's binary_error: 0.165019\ttraining's binary_logloss: 0.368441\n",
      "[2814]\ttraining's binary_error: 0.165009\ttraining's binary_logloss: 0.368431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2815]\ttraining's binary_error: 0.164983\ttraining's binary_logloss: 0.368411\n",
      "[2816]\ttraining's binary_error: 0.164974\ttraining's binary_logloss: 0.36837\n",
      "[2817]\ttraining's binary_error: 0.164956\ttraining's binary_logloss: 0.368335\n",
      "[2818]\ttraining's binary_error: 0.16495\ttraining's binary_logloss: 0.368323\n",
      "[2819]\ttraining's binary_error: 0.164972\ttraining's binary_logloss: 0.368284\n",
      "[2820]\ttraining's binary_error: 0.164968\ttraining's binary_logloss: 0.368274\n",
      "[2821]\ttraining's binary_error: 0.164976\ttraining's binary_logloss: 0.368258\n",
      "[2822]\ttraining's binary_error: 0.164963\ttraining's binary_logloss: 0.368241\n",
      "[2823]\ttraining's binary_error: 0.164956\ttraining's binary_logloss: 0.368229\n",
      "[2824]\ttraining's binary_error: 0.16493\ttraining's binary_logloss: 0.368185\n",
      "[2825]\ttraining's binary_error: 0.164923\ttraining's binary_logloss: 0.368172\n",
      "[2826]\ttraining's binary_error: 0.164929\ttraining's binary_logloss: 0.368161\n",
      "[2827]\ttraining's binary_error: 0.16487\ttraining's binary_logloss: 0.36812\n",
      "[2828]\ttraining's binary_error: 0.164826\ttraining's binary_logloss: 0.368048\n",
      "[2829]\ttraining's binary_error: 0.164793\ttraining's binary_logloss: 0.367978\n",
      "[2830]\ttraining's binary_error: 0.164768\ttraining's binary_logloss: 0.367913\n",
      "[2831]\ttraining's binary_error: 0.164756\ttraining's binary_logloss: 0.367894\n",
      "[2832]\ttraining's binary_error: 0.164705\ttraining's binary_logloss: 0.367798\n",
      "[2833]\ttraining's binary_error: 0.164613\ttraining's binary_logloss: 0.367679\n",
      "[2834]\ttraining's binary_error: 0.164555\ttraining's binary_logloss: 0.36759\n",
      "[2835]\ttraining's binary_error: 0.164576\ttraining's binary_logloss: 0.367563\n",
      "[2836]\ttraining's binary_error: 0.164569\ttraining's binary_logloss: 0.367539\n",
      "[2837]\ttraining's binary_error: 0.164568\ttraining's binary_logloss: 0.367523\n",
      "[2838]\ttraining's binary_error: 0.164535\ttraining's binary_logloss: 0.367501\n",
      "[2839]\ttraining's binary_error: 0.164511\ttraining's binary_logloss: 0.367476\n",
      "[2840]\ttraining's binary_error: 0.164504\ttraining's binary_logloss: 0.367464\n",
      "[2841]\ttraining's binary_error: 0.164516\ttraining's binary_logloss: 0.367451\n",
      "[2842]\ttraining's binary_error: 0.164512\ttraining's binary_logloss: 0.367435\n",
      "[2843]\ttraining's binary_error: 0.164526\ttraining's binary_logloss: 0.367413\n",
      "[2844]\ttraining's binary_error: 0.164511\ttraining's binary_logloss: 0.367346\n",
      "[2845]\ttraining's binary_error: 0.164448\ttraining's binary_logloss: 0.367268\n",
      "[2846]\ttraining's binary_error: 0.164439\ttraining's binary_logloss: 0.367251\n",
      "[2847]\ttraining's binary_error: 0.164411\ttraining's binary_logloss: 0.36723\n",
      "[2848]\ttraining's binary_error: 0.164397\ttraining's binary_logloss: 0.367218\n",
      "[2849]\ttraining's binary_error: 0.164369\ttraining's binary_logloss: 0.367203\n",
      "[2850]\ttraining's binary_error: 0.164383\ttraining's binary_logloss: 0.367182\n",
      "[2851]\ttraining's binary_error: 0.164384\ttraining's binary_logloss: 0.367169\n",
      "[2852]\ttraining's binary_error: 0.164359\ttraining's binary_logloss: 0.367146\n",
      "[2853]\ttraining's binary_error: 0.164356\ttraining's binary_logloss: 0.367139\n",
      "[2854]\ttraining's binary_error: 0.164357\ttraining's binary_logloss: 0.367126\n",
      "[2855]\ttraining's binary_error: 0.164346\ttraining's binary_logloss: 0.367084\n",
      "[2856]\ttraining's binary_error: 0.164329\ttraining's binary_logloss: 0.367062\n",
      "[2857]\ttraining's binary_error: 0.164314\ttraining's binary_logloss: 0.36705\n",
      "[2858]\ttraining's binary_error: 0.164316\ttraining's binary_logloss: 0.367038\n",
      "[2859]\ttraining's binary_error: 0.164274\ttraining's binary_logloss: 0.367007\n",
      "[2860]\ttraining's binary_error: 0.164254\ttraining's binary_logloss: 0.366936\n",
      "[2861]\ttraining's binary_error: 0.164266\ttraining's binary_logloss: 0.366929\n",
      "[2862]\ttraining's binary_error: 0.164256\ttraining's binary_logloss: 0.366918\n",
      "[2863]\ttraining's binary_error: 0.164251\ttraining's binary_logloss: 0.366884\n",
      "[2864]\ttraining's binary_error: 0.164245\ttraining's binary_logloss: 0.366865\n",
      "[2865]\ttraining's binary_error: 0.164207\ttraining's binary_logloss: 0.366826\n",
      "[2866]\ttraining's binary_error: 0.164199\ttraining's binary_logloss: 0.366809\n",
      "[2867]\ttraining's binary_error: 0.164209\ttraining's binary_logloss: 0.366801\n",
      "[2868]\ttraining's binary_error: 0.164203\ttraining's binary_logloss: 0.366776\n",
      "[2869]\ttraining's binary_error: 0.164164\ttraining's binary_logloss: 0.366735\n",
      "[2870]\ttraining's binary_error: 0.164145\ttraining's binary_logloss: 0.366713\n",
      "[2871]\ttraining's binary_error: 0.16411\ttraining's binary_logloss: 0.366695\n",
      "[2872]\ttraining's binary_error: 0.164108\ttraining's binary_logloss: 0.366682\n",
      "[2873]\ttraining's binary_error: 0.164122\ttraining's binary_logloss: 0.366667\n",
      "[2874]\ttraining's binary_error: 0.164097\ttraining's binary_logloss: 0.366643\n",
      "[2875]\ttraining's binary_error: 0.164082\ttraining's binary_logloss: 0.366628\n",
      "[2876]\ttraining's binary_error: 0.164075\ttraining's binary_logloss: 0.366603\n",
      "[2877]\ttraining's binary_error: 0.164062\ttraining's binary_logloss: 0.366586\n",
      "[2878]\ttraining's binary_error: 0.16405\ttraining's binary_logloss: 0.366572\n",
      "[2879]\ttraining's binary_error: 0.164042\ttraining's binary_logloss: 0.366549\n",
      "[2880]\ttraining's binary_error: 0.164023\ttraining's binary_logloss: 0.366524\n",
      "[2881]\ttraining's binary_error: 0.164022\ttraining's binary_logloss: 0.366511\n",
      "[2882]\ttraining's binary_error: 0.164035\ttraining's binary_logloss: 0.366474\n",
      "[2883]\ttraining's binary_error: 0.164009\ttraining's binary_logloss: 0.366447\n",
      "[2884]\ttraining's binary_error: 0.164\ttraining's binary_logloss: 0.366442\n",
      "[2885]\ttraining's binary_error: 0.163973\ttraining's binary_logloss: 0.366404\n",
      "[2886]\ttraining's binary_error: 0.163943\ttraining's binary_logloss: 0.366383\n",
      "[2887]\ttraining's binary_error: 0.163945\ttraining's binary_logloss: 0.366373\n",
      "[2888]\ttraining's binary_error: 0.163953\ttraining's binary_logloss: 0.366353\n",
      "[2889]\ttraining's binary_error: 0.163944\ttraining's binary_logloss: 0.366328\n",
      "[2890]\ttraining's binary_error: 0.163937\ttraining's binary_logloss: 0.366315\n",
      "[2891]\ttraining's binary_error: 0.163936\ttraining's binary_logloss: 0.36631\n",
      "[2892]\ttraining's binary_error: 0.16393\ttraining's binary_logloss: 0.366298\n",
      "[2893]\ttraining's binary_error: 0.163898\ttraining's binary_logloss: 0.36628\n",
      "[2894]\ttraining's binary_error: 0.163894\ttraining's binary_logloss: 0.366265\n",
      "[2895]\ttraining's binary_error: 0.163926\ttraining's binary_logloss: 0.366249\n",
      "[2896]\ttraining's binary_error: 0.163924\ttraining's binary_logloss: 0.366211\n",
      "[2897]\ttraining's binary_error: 0.163889\ttraining's binary_logloss: 0.36616\n",
      "[2898]\ttraining's binary_error: 0.163867\ttraining's binary_logloss: 0.366125\n",
      "[2899]\ttraining's binary_error: 0.163854\ttraining's binary_logloss: 0.366114\n",
      "[2900]\ttraining's binary_error: 0.163862\ttraining's binary_logloss: 0.366086\n",
      "[2901]\ttraining's binary_error: 0.163851\ttraining's binary_logloss: 0.366059\n",
      "[2902]\ttraining's binary_error: 0.163839\ttraining's binary_logloss: 0.366052\n",
      "[2903]\ttraining's binary_error: 0.163834\ttraining's binary_logloss: 0.36604\n",
      "[2904]\ttraining's binary_error: 0.16379\ttraining's binary_logloss: 0.365999\n",
      "[2905]\ttraining's binary_error: 0.163784\ttraining's binary_logloss: 0.365988\n",
      "[2906]\ttraining's binary_error: 0.163754\ttraining's binary_logloss: 0.36594\n",
      "[2907]\ttraining's binary_error: 0.163743\ttraining's binary_logloss: 0.365914\n",
      "[2908]\ttraining's binary_error: 0.163719\ttraining's binary_logloss: 0.36589\n",
      "[2909]\ttraining's binary_error: 0.163709\ttraining's binary_logloss: 0.365874\n",
      "[2910]\ttraining's binary_error: 0.163699\ttraining's binary_logloss: 0.365841\n",
      "[2911]\ttraining's binary_error: 0.163679\ttraining's binary_logloss: 0.365831\n",
      "[2912]\ttraining's binary_error: 0.163664\ttraining's binary_logloss: 0.365814\n",
      "[2913]\ttraining's binary_error: 0.16365\ttraining's binary_logloss: 0.3658\n",
      "[2914]\ttraining's binary_error: 0.163649\ttraining's binary_logloss: 0.365781\n",
      "[2915]\ttraining's binary_error: 0.163643\ttraining's binary_logloss: 0.365772\n",
      "[2916]\ttraining's binary_error: 0.163586\ttraining's binary_logloss: 0.365723\n",
      "[2917]\ttraining's binary_error: 0.163572\ttraining's binary_logloss: 0.365664\n",
      "[2918]\ttraining's binary_error: 0.163582\ttraining's binary_logloss: 0.365654\n",
      "[2919]\ttraining's binary_error: 0.163577\ttraining's binary_logloss: 0.365643\n",
      "[2920]\ttraining's binary_error: 0.163588\ttraining's binary_logloss: 0.365625\n",
      "[2921]\ttraining's binary_error: 0.163552\ttraining's binary_logloss: 0.365607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2922]\ttraining's binary_error: 0.16355\ttraining's binary_logloss: 0.365581\n",
      "[2923]\ttraining's binary_error: 0.163528\ttraining's binary_logloss: 0.365569\n",
      "[2924]\ttraining's binary_error: 0.163459\ttraining's binary_logloss: 0.365509\n",
      "[2925]\ttraining's binary_error: 0.163457\ttraining's binary_logloss: 0.365495\n",
      "[2926]\ttraining's binary_error: 0.163433\ttraining's binary_logloss: 0.365476\n",
      "[2927]\ttraining's binary_error: 0.163442\ttraining's binary_logloss: 0.365458\n",
      "[2928]\ttraining's binary_error: 0.163478\ttraining's binary_logloss: 0.365435\n",
      "[2929]\ttraining's binary_error: 0.163458\ttraining's binary_logloss: 0.365398\n",
      "[2930]\ttraining's binary_error: 0.16345\ttraining's binary_logloss: 0.365374\n",
      "[2931]\ttraining's binary_error: 0.163405\ttraining's binary_logloss: 0.365309\n",
      "[2932]\ttraining's binary_error: 0.163373\ttraining's binary_logloss: 0.365263\n",
      "[2933]\ttraining's binary_error: 0.163338\ttraining's binary_logloss: 0.365248\n",
      "[2934]\ttraining's binary_error: 0.163323\ttraining's binary_logloss: 0.365223\n",
      "[2935]\ttraining's binary_error: 0.163306\ttraining's binary_logloss: 0.365207\n",
      "[2936]\ttraining's binary_error: 0.163293\ttraining's binary_logloss: 0.365172\n",
      "[2937]\ttraining's binary_error: 0.163298\ttraining's binary_logloss: 0.365161\n",
      "[2938]\ttraining's binary_error: 0.16328\ttraining's binary_logloss: 0.365146\n",
      "[2939]\ttraining's binary_error: 0.163268\ttraining's binary_logloss: 0.36512\n",
      "[2940]\ttraining's binary_error: 0.163255\ttraining's binary_logloss: 0.365109\n",
      "[2941]\ttraining's binary_error: 0.163247\ttraining's binary_logloss: 0.365086\n",
      "[2942]\ttraining's binary_error: 0.163243\ttraining's binary_logloss: 0.365074\n",
      "[2943]\ttraining's binary_error: 0.163239\ttraining's binary_logloss: 0.365051\n",
      "[2944]\ttraining's binary_error: 0.16322\ttraining's binary_logloss: 0.365036\n",
      "[2945]\ttraining's binary_error: 0.163201\ttraining's binary_logloss: 0.365006\n",
      "[2946]\ttraining's binary_error: 0.16317\ttraining's binary_logloss: 0.364966\n",
      "[2947]\ttraining's binary_error: 0.163159\ttraining's binary_logloss: 0.364943\n",
      "[2948]\ttraining's binary_error: 0.16311\ttraining's binary_logloss: 0.364885\n",
      "[2949]\ttraining's binary_error: 0.163105\ttraining's binary_logloss: 0.364874\n",
      "[2950]\ttraining's binary_error: 0.163094\ttraining's binary_logloss: 0.364866\n",
      "[2951]\ttraining's binary_error: 0.163094\ttraining's binary_logloss: 0.36485\n",
      "[2952]\ttraining's binary_error: 0.163097\ttraining's binary_logloss: 0.364834\n",
      "[2953]\ttraining's binary_error: 0.163108\ttraining's binary_logloss: 0.364805\n",
      "[2954]\ttraining's binary_error: 0.1631\ttraining's binary_logloss: 0.364784\n",
      "[2955]\ttraining's binary_error: 0.16309\ttraining's binary_logloss: 0.364767\n",
      "[2956]\ttraining's binary_error: 0.163053\ttraining's binary_logloss: 0.364739\n",
      "[2957]\ttraining's binary_error: 0.163046\ttraining's binary_logloss: 0.364727\n",
      "[2958]\ttraining's binary_error: 0.163011\ttraining's binary_logloss: 0.364699\n",
      "[2959]\ttraining's binary_error: 0.163006\ttraining's binary_logloss: 0.364689\n",
      "[2960]\ttraining's binary_error: 0.163002\ttraining's binary_logloss: 0.364671\n",
      "[2961]\ttraining's binary_error: 0.162936\ttraining's binary_logloss: 0.364624\n",
      "[2962]\ttraining's binary_error: 0.162909\ttraining's binary_logloss: 0.364579\n",
      "[2963]\ttraining's binary_error: 0.162928\ttraining's binary_logloss: 0.364569\n",
      "[2964]\ttraining's binary_error: 0.162912\ttraining's binary_logloss: 0.364559\n",
      "[2965]\ttraining's binary_error: 0.162863\ttraining's binary_logloss: 0.364462\n",
      "[2966]\ttraining's binary_error: 0.162855\ttraining's binary_logloss: 0.364453\n",
      "[2967]\ttraining's binary_error: 0.162841\ttraining's binary_logloss: 0.36444\n",
      "[2968]\ttraining's binary_error: 0.16284\ttraining's binary_logloss: 0.364434\n",
      "[2969]\ttraining's binary_error: 0.162834\ttraining's binary_logloss: 0.364423\n",
      "[2970]\ttraining's binary_error: 0.162819\ttraining's binary_logloss: 0.364379\n",
      "[2971]\ttraining's binary_error: 0.16282\ttraining's binary_logloss: 0.364362\n",
      "[2972]\ttraining's binary_error: 0.162792\ttraining's binary_logloss: 0.364345\n",
      "[2973]\ttraining's binary_error: 0.162754\ttraining's binary_logloss: 0.364326\n",
      "[2974]\ttraining's binary_error: 0.162753\ttraining's binary_logloss: 0.364276\n",
      "[2975]\ttraining's binary_error: 0.162782\ttraining's binary_logloss: 0.364264\n",
      "[2976]\ttraining's binary_error: 0.162773\ttraining's binary_logloss: 0.364243\n",
      "[2977]\ttraining's binary_error: 0.16276\ttraining's binary_logloss: 0.364231\n",
      "[2978]\ttraining's binary_error: 0.162728\ttraining's binary_logloss: 0.364201\n",
      "[2979]\ttraining's binary_error: 0.162725\ttraining's binary_logloss: 0.364194\n",
      "[2980]\ttraining's binary_error: 0.16274\ttraining's binary_logloss: 0.364181\n",
      "[2981]\ttraining's binary_error: 0.162727\ttraining's binary_logloss: 0.364165\n",
      "[2982]\ttraining's binary_error: 0.162729\ttraining's binary_logloss: 0.364154\n",
      "[2983]\ttraining's binary_error: 0.162695\ttraining's binary_logloss: 0.364072\n",
      "[2984]\ttraining's binary_error: 0.162677\ttraining's binary_logloss: 0.364053\n",
      "[2985]\ttraining's binary_error: 0.162655\ttraining's binary_logloss: 0.364042\n",
      "[2986]\ttraining's binary_error: 0.162607\ttraining's binary_logloss: 0.363963\n",
      "[2987]\ttraining's binary_error: 0.16257\ttraining's binary_logloss: 0.363947\n",
      "[2988]\ttraining's binary_error: 0.162562\ttraining's binary_logloss: 0.363937\n",
      "[2989]\ttraining's binary_error: 0.162551\ttraining's binary_logloss: 0.363921\n",
      "[2990]\ttraining's binary_error: 0.162519\ttraining's binary_logloss: 0.363866\n",
      "[2991]\ttraining's binary_error: 0.162515\ttraining's binary_logloss: 0.363851\n",
      "[2992]\ttraining's binary_error: 0.162497\ttraining's binary_logloss: 0.363836\n",
      "[2993]\ttraining's binary_error: 0.162456\ttraining's binary_logloss: 0.363789\n",
      "[2994]\ttraining's binary_error: 0.162439\ttraining's binary_logloss: 0.363775\n",
      "[2995]\ttraining's binary_error: 0.162453\ttraining's binary_logloss: 0.363769\n",
      "[2996]\ttraining's binary_error: 0.16244\ttraining's binary_logloss: 0.363754\n",
      "[2997]\ttraining's binary_error: 0.162438\ttraining's binary_logloss: 0.363741\n",
      "[2998]\ttraining's binary_error: 0.16241\ttraining's binary_logloss: 0.363708\n",
      "[2999]\ttraining's binary_error: 0.162399\ttraining's binary_logloss: 0.363698\n",
      "[3000]\ttraining's binary_error: 0.162401\ttraining's binary_logloss: 0.363687\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's binary_error: 0.0606093\ttraining's binary_logloss: 0.253765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(categorical_column=['department', 'brand', 'commodity_desc',\n",
       "                                   'sub_commodity_desc', 'curr_size_of_product',\n",
       "                                   'age_desc', 'marital_status_code',\n",
       "                                   'income_desc', 'homeowner_desc',\n",
       "                                   'hh_comp_desc', 'household_size_desc',\n",
       "                                   'kid_category_desc', 'manufacturer'],\n",
       "               is_unbalance=True, learning_rate=0.15, max_depth=4,\n",
       "               n_estimators=3000, objective='binary', random_state=27,\n",
       "               verbose=1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "lgb_model.fit(X=X_train_,\n",
    "        y=y_train,\n",
    "        eval_set=[(X_train_, y_train)],\n",
    "        early_stopping_rounds=500,\n",
    "        eval_metric=['binary_error'],\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = lgb_model.predict_proba(X_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = train_preds[:,1]\n",
    "train_preds = pd.concat([X_train[['user_id','item_id' ]], pd.DataFrame(train_preds, columns=['probability'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top(df, user_id, top = 5):\n",
    "    train_preds_sorted = df[df.user_id == user_id].sort_values(\"probability\", axis = 0, ascending = False)\n",
    "    predictions = train_preds_sorted['item_id'][:top].values.tolist()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_2['lgbm_train'] = result_lvl_2['user_id'].apply(lambda x: get_top(train_preds, x, top=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17250348351137654"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_2.apply(lambda row: precision_at_k(row['lgbm_train'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = lgb_model.predict_proba(X_val_)\n",
    "val_preds = val_preds[:,1]\n",
    "val_preds = pd.concat([X_val[['user_id','item_id' ]], pd.DataFrame(val_preds, columns=['probability'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_2['lgbm_val'] = result_lvl_2['user_id'].apply(lambda x: get_top(val_preds, x, top=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16600092893636514"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_2.apply(lambda row: precision_at_k(row['lgbm_val'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>lgbm_train</th>\n",
       "      <th>lgbm_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[853529, 865456, 867607, 872137, 874905, 87524...</td>\n",
       "      <td>[979707, 1133018, 995242, 1058997, 862349]</td>\n",
       "      <td>[1055646, 995242, 979707, 995785, 862349]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[15830248, 838136, 839656, 861272, 866211, 870...</td>\n",
       "      <td>[1126899, 1106523, 1082185, 1106523, 1070820]</td>\n",
       "      <td>[1082185, 1106523, 1082185, 1126899, 1106523]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[883932, 970760, 1035676, 1055863, 1097610, 67...</td>\n",
       "      <td>[1029743, 1082185, 1126899, 1070820, 1082185]</td>\n",
       "      <td>[1106523, 1029743, 1070820, 1106523, 1126899]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[1024306, 1102949, 6548453, 835394, 940804, 96...</td>\n",
       "      <td>[1029743, 1082185, 1082185, 1106523, 1126899]</td>\n",
       "      <td>[1070820, 1029743, 1106523, 1126899, 1106523]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[836281, 843306, 845294, 914190, 920456, 93886...</td>\n",
       "      <td>[1082185, 995785, 916122, 1005186, 1404121]</td>\n",
       "      <td>[979707, 903325, 1082185, 1082185, 1404121]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual  \\\n",
       "0        1  [853529, 865456, 867607, 872137, 874905, 87524...   \n",
       "1        2  [15830248, 838136, 839656, 861272, 866211, 870...   \n",
       "2        4  [883932, 970760, 1035676, 1055863, 1097610, 67...   \n",
       "3        6  [1024306, 1102949, 6548453, 835394, 940804, 96...   \n",
       "4        7  [836281, 843306, 845294, 914190, 920456, 93886...   \n",
       "\n",
       "                                      lgbm_train  \\\n",
       "0     [979707, 1133018, 995242, 1058997, 862349]   \n",
       "1  [1126899, 1106523, 1082185, 1106523, 1070820]   \n",
       "2  [1029743, 1082185, 1126899, 1070820, 1082185]   \n",
       "3  [1029743, 1082185, 1082185, 1106523, 1126899]   \n",
       "4    [1082185, 995785, 916122, 1005186, 1404121]   \n",
       "\n",
       "                                        lgbm_val  \n",
       "0      [1055646, 995242, 979707, 995785, 862349]  \n",
       "1  [1082185, 1106523, 1082185, 1126899, 1106523]  \n",
       "2  [1106523, 1029743, 1070820, 1106523, 1126899]  \n",
       "3  [1070820, 1029743, 1106523, 1126899, 1106523]  \n",
       "4    [979707, 903325, 1082185, 1082185, 1404121]  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
